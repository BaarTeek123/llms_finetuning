{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.7319159045017223,
  "eval_steps": 500,
  "global_step": 23000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.001187789523696401,
      "grad_norm": 1.571284294128418,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.691,
      "step": 10
    },
    {
      "epoch": 0.002375579047392802,
      "grad_norm": 2.3712053298950195,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.7104,
      "step": 20
    },
    {
      "epoch": 0.003563368571089203,
      "grad_norm": 2.394946813583374,
      "learning_rate": 3e-06,
      "loss": 0.7076,
      "step": 30
    },
    {
      "epoch": 0.004751158094785604,
      "grad_norm": 3.6025919914245605,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.714,
      "step": 40
    },
    {
      "epoch": 0.005938947618482005,
      "grad_norm": 1.937501311302185,
      "learning_rate": 5e-06,
      "loss": 0.6987,
      "step": 50
    },
    {
      "epoch": 0.007126737142178406,
      "grad_norm": 3.3844287395477295,
      "learning_rate": 6e-06,
      "loss": 0.7021,
      "step": 60
    },
    {
      "epoch": 0.008314526665874808,
      "grad_norm": 3.468790054321289,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.699,
      "step": 70
    },
    {
      "epoch": 0.009502316189571208,
      "grad_norm": 1.6214921474456787,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.6835,
      "step": 80
    },
    {
      "epoch": 0.010690105713267608,
      "grad_norm": 1.8596107959747314,
      "learning_rate": 9e-06,
      "loss": 0.6895,
      "step": 90
    },
    {
      "epoch": 0.01187789523696401,
      "grad_norm": 2.3269872665405273,
      "learning_rate": 1e-05,
      "loss": 0.6835,
      "step": 100
    },
    {
      "epoch": 0.01306568476066041,
      "grad_norm": 4.275064945220947,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.6999,
      "step": 110
    },
    {
      "epoch": 0.014253474284356813,
      "grad_norm": 1.7505264282226562,
      "learning_rate": 1.2e-05,
      "loss": 0.6941,
      "step": 120
    },
    {
      "epoch": 0.015441263808053213,
      "grad_norm": 1.5032916069030762,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.6868,
      "step": 130
    },
    {
      "epoch": 0.016629053331749615,
      "grad_norm": 3.410565137863159,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.703,
      "step": 140
    },
    {
      "epoch": 0.017816842855446016,
      "grad_norm": 2.50521183013916,
      "learning_rate": 1.5e-05,
      "loss": 0.7025,
      "step": 150
    },
    {
      "epoch": 0.019004632379142416,
      "grad_norm": 3.892134428024292,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.6794,
      "step": 160
    },
    {
      "epoch": 0.020192421902838816,
      "grad_norm": 1.7042125463485718,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.6917,
      "step": 170
    },
    {
      "epoch": 0.021380211426535217,
      "grad_norm": 4.2205915451049805,
      "learning_rate": 1.8e-05,
      "loss": 0.6971,
      "step": 180
    },
    {
      "epoch": 0.02256800095023162,
      "grad_norm": 1.5046566724777222,
      "learning_rate": 1.9e-05,
      "loss": 0.6874,
      "step": 190
    },
    {
      "epoch": 0.02375579047392802,
      "grad_norm": 1.69389009475708,
      "learning_rate": 2e-05,
      "loss": 0.6692,
      "step": 200
    },
    {
      "epoch": 0.02494357999762442,
      "grad_norm": 1.7059226036071777,
      "learning_rate": 2.1e-05,
      "loss": 0.6717,
      "step": 210
    },
    {
      "epoch": 0.02613136952132082,
      "grad_norm": 1.818788766860962,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.6601,
      "step": 220
    },
    {
      "epoch": 0.02731915904501722,
      "grad_norm": 2.0799472332000732,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.6629,
      "step": 230
    },
    {
      "epoch": 0.028506948568713626,
      "grad_norm": 1.823838472366333,
      "learning_rate": 2.4e-05,
      "loss": 0.6681,
      "step": 240
    },
    {
      "epoch": 0.029694738092410026,
      "grad_norm": 2.8223283290863037,
      "learning_rate": 2.5e-05,
      "loss": 0.6993,
      "step": 250
    },
    {
      "epoch": 0.030882527616106426,
      "grad_norm": 2.522125244140625,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.7037,
      "step": 260
    },
    {
      "epoch": 0.03207031713980283,
      "grad_norm": 1.8430627584457397,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.6947,
      "step": 270
    },
    {
      "epoch": 0.03325810666349923,
      "grad_norm": 3.059164524078369,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.6869,
      "step": 280
    },
    {
      "epoch": 0.03444589618719563,
      "grad_norm": 1.9441590309143066,
      "learning_rate": 2.9e-05,
      "loss": 0.6886,
      "step": 290
    },
    {
      "epoch": 0.03563368571089203,
      "grad_norm": 1.770355224609375,
      "learning_rate": 3e-05,
      "loss": 0.6928,
      "step": 300
    },
    {
      "epoch": 0.03682147523458843,
      "grad_norm": 1.7763140201568604,
      "learning_rate": 3.1e-05,
      "loss": 0.6743,
      "step": 310
    },
    {
      "epoch": 0.03800926475828483,
      "grad_norm": 1.8267428874969482,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.6672,
      "step": 320
    },
    {
      "epoch": 0.03919705428198123,
      "grad_norm": 1.6273711919784546,
      "learning_rate": 3.3e-05,
      "loss": 0.6543,
      "step": 330
    },
    {
      "epoch": 0.04038484380567763,
      "grad_norm": 4.313201904296875,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.6706,
      "step": 340
    },
    {
      "epoch": 0.04157263332937403,
      "grad_norm": 4.140109062194824,
      "learning_rate": 3.5e-05,
      "loss": 0.6651,
      "step": 350
    },
    {
      "epoch": 0.04276042285307043,
      "grad_norm": 2.572695255279541,
      "learning_rate": 3.6e-05,
      "loss": 0.67,
      "step": 360
    },
    {
      "epoch": 0.04394821237676684,
      "grad_norm": 2.187011957168579,
      "learning_rate": 3.7e-05,
      "loss": 0.6432,
      "step": 370
    },
    {
      "epoch": 0.04513600190046324,
      "grad_norm": 4.77373743057251,
      "learning_rate": 3.8e-05,
      "loss": 0.671,
      "step": 380
    },
    {
      "epoch": 0.04632379142415964,
      "grad_norm": 2.0730113983154297,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.6803,
      "step": 390
    },
    {
      "epoch": 0.04751158094785604,
      "grad_norm": 3.850599765777588,
      "learning_rate": 4e-05,
      "loss": 0.6695,
      "step": 400
    },
    {
      "epoch": 0.04869937047155244,
      "grad_norm": 3.2260897159576416,
      "learning_rate": 4.1e-05,
      "loss": 0.6611,
      "step": 410
    },
    {
      "epoch": 0.04988715999524884,
      "grad_norm": 2.1476058959960938,
      "learning_rate": 4.2e-05,
      "loss": 0.6543,
      "step": 420
    },
    {
      "epoch": 0.05107494951894524,
      "grad_norm": 5.54133415222168,
      "learning_rate": 4.3e-05,
      "loss": 0.6637,
      "step": 430
    },
    {
      "epoch": 0.05226273904264164,
      "grad_norm": 3.140399932861328,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.6532,
      "step": 440
    },
    {
      "epoch": 0.05345052856633804,
      "grad_norm": 3.0184481143951416,
      "learning_rate": 4.5e-05,
      "loss": 0.613,
      "step": 450
    },
    {
      "epoch": 0.05463831809003444,
      "grad_norm": 3.482469320297241,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.6442,
      "step": 460
    },
    {
      "epoch": 0.055826107613730844,
      "grad_norm": 4.6692423820495605,
      "learning_rate": 4.7e-05,
      "loss": 0.6508,
      "step": 470
    },
    {
      "epoch": 0.05701389713742725,
      "grad_norm": 5.267462253570557,
      "learning_rate": 4.8e-05,
      "loss": 0.6357,
      "step": 480
    },
    {
      "epoch": 0.05820168666112365,
      "grad_norm": 5.792267322540283,
      "learning_rate": 4.9e-05,
      "loss": 0.6523,
      "step": 490
    },
    {
      "epoch": 0.05938947618482005,
      "grad_norm": 3.983430862426758,
      "learning_rate": 5e-05,
      "loss": 0.639,
      "step": 500
    },
    {
      "epoch": 0.06057726570851645,
      "grad_norm": 5.588817596435547,
      "learning_rate": 4.997980369188512e-05,
      "loss": 0.64,
      "step": 510
    },
    {
      "epoch": 0.06176505523221285,
      "grad_norm": 7.067869186401367,
      "learning_rate": 4.995960738377025e-05,
      "loss": 0.633,
      "step": 520
    },
    {
      "epoch": 0.06295284475590926,
      "grad_norm": 3.3713228702545166,
      "learning_rate": 4.993941107565537e-05,
      "loss": 0.6247,
      "step": 530
    },
    {
      "epoch": 0.06414063427960566,
      "grad_norm": 6.371031761169434,
      "learning_rate": 4.99192147675405e-05,
      "loss": 0.6461,
      "step": 540
    },
    {
      "epoch": 0.06532842380330206,
      "grad_norm": 2.8868744373321533,
      "learning_rate": 4.9899018459425616e-05,
      "loss": 0.5931,
      "step": 550
    },
    {
      "epoch": 0.06651621332699846,
      "grad_norm": 4.016470909118652,
      "learning_rate": 4.987882215131074e-05,
      "loss": 0.6165,
      "step": 560
    },
    {
      "epoch": 0.06770400285069486,
      "grad_norm": 4.354010105133057,
      "learning_rate": 4.985862584319587e-05,
      "loss": 0.6168,
      "step": 570
    },
    {
      "epoch": 0.06889179237439126,
      "grad_norm": 4.343535423278809,
      "learning_rate": 4.9838429535080985e-05,
      "loss": 0.6168,
      "step": 580
    },
    {
      "epoch": 0.07007958189808766,
      "grad_norm": 5.812617301940918,
      "learning_rate": 4.981823322696612e-05,
      "loss": 0.6248,
      "step": 590
    },
    {
      "epoch": 0.07126737142178406,
      "grad_norm": 5.959688663482666,
      "learning_rate": 4.9798036918851236e-05,
      "loss": 0.6154,
      "step": 600
    },
    {
      "epoch": 0.07245516094548046,
      "grad_norm": 4.963962554931641,
      "learning_rate": 4.977784061073636e-05,
      "loss": 0.6111,
      "step": 610
    },
    {
      "epoch": 0.07364295046917686,
      "grad_norm": 6.3539605140686035,
      "learning_rate": 4.975764430262148e-05,
      "loss": 0.6219,
      "step": 620
    },
    {
      "epoch": 0.07483073999287326,
      "grad_norm": 4.269138813018799,
      "learning_rate": 4.9737447994506606e-05,
      "loss": 0.5873,
      "step": 630
    },
    {
      "epoch": 0.07601852951656966,
      "grad_norm": 5.565948963165283,
      "learning_rate": 4.971725168639173e-05,
      "loss": 0.5671,
      "step": 640
    },
    {
      "epoch": 0.07720631904026606,
      "grad_norm": 9.216350555419922,
      "learning_rate": 4.969705537827685e-05,
      "loss": 0.5477,
      "step": 650
    },
    {
      "epoch": 0.07839410856396246,
      "grad_norm": 2.9129035472869873,
      "learning_rate": 4.9676859070161975e-05,
      "loss": 0.5838,
      "step": 660
    },
    {
      "epoch": 0.07958189808765886,
      "grad_norm": 13.75711727142334,
      "learning_rate": 4.96566627620471e-05,
      "loss": 0.5386,
      "step": 670
    },
    {
      "epoch": 0.08076968761135526,
      "grad_norm": 4.186140537261963,
      "learning_rate": 4.9636466453932226e-05,
      "loss": 0.6116,
      "step": 680
    },
    {
      "epoch": 0.08195747713505167,
      "grad_norm": 2.5830237865448,
      "learning_rate": 4.9616270145817344e-05,
      "loss": 0.54,
      "step": 690
    },
    {
      "epoch": 0.08314526665874807,
      "grad_norm": 8.397902488708496,
      "learning_rate": 4.959607383770247e-05,
      "loss": 0.6059,
      "step": 700
    },
    {
      "epoch": 0.08433305618244447,
      "grad_norm": 8.332036972045898,
      "learning_rate": 4.9575877529587595e-05,
      "loss": 0.5963,
      "step": 710
    },
    {
      "epoch": 0.08552084570614087,
      "grad_norm": 4.008006572723389,
      "learning_rate": 4.9555681221472714e-05,
      "loss": 0.4987,
      "step": 720
    },
    {
      "epoch": 0.08670863522983727,
      "grad_norm": 8.097256660461426,
      "learning_rate": 4.953548491335784e-05,
      "loss": 0.5773,
      "step": 730
    },
    {
      "epoch": 0.08789642475353368,
      "grad_norm": 6.3633551597595215,
      "learning_rate": 4.9515288605242965e-05,
      "loss": 0.5049,
      "step": 740
    },
    {
      "epoch": 0.08908421427723008,
      "grad_norm": 6.642234802246094,
      "learning_rate": 4.949509229712809e-05,
      "loss": 0.4989,
      "step": 750
    },
    {
      "epoch": 0.09027200380092648,
      "grad_norm": 6.825439453125,
      "learning_rate": 4.947489598901321e-05,
      "loss": 0.551,
      "step": 760
    },
    {
      "epoch": 0.09145979332462288,
      "grad_norm": 4.613224029541016,
      "learning_rate": 4.9454699680898334e-05,
      "loss": 0.4616,
      "step": 770
    },
    {
      "epoch": 0.09264758284831928,
      "grad_norm": 11.66037368774414,
      "learning_rate": 4.943450337278346e-05,
      "loss": 0.6176,
      "step": 780
    },
    {
      "epoch": 0.09383537237201568,
      "grad_norm": 8.434765815734863,
      "learning_rate": 4.941430706466858e-05,
      "loss": 0.4825,
      "step": 790
    },
    {
      "epoch": 0.09502316189571208,
      "grad_norm": 12.122628211975098,
      "learning_rate": 4.9394110756553704e-05,
      "loss": 0.5341,
      "step": 800
    },
    {
      "epoch": 0.09621095141940848,
      "grad_norm": 8.43961238861084,
      "learning_rate": 4.937391444843883e-05,
      "loss": 0.5171,
      "step": 810
    },
    {
      "epoch": 0.09739874094310488,
      "grad_norm": 7.21361780166626,
      "learning_rate": 4.9353718140323954e-05,
      "loss": 0.496,
      "step": 820
    },
    {
      "epoch": 0.09858653046680128,
      "grad_norm": 9.11520004272461,
      "learning_rate": 4.933352183220907e-05,
      "loss": 0.5466,
      "step": 830
    },
    {
      "epoch": 0.09977431999049768,
      "grad_norm": 6.771602153778076,
      "learning_rate": 4.93133255240942e-05,
      "loss": 0.4673,
      "step": 840
    },
    {
      "epoch": 0.10096210951419408,
      "grad_norm": 9.030261993408203,
      "learning_rate": 4.9293129215979324e-05,
      "loss": 0.5149,
      "step": 850
    },
    {
      "epoch": 0.10214989903789048,
      "grad_norm": 6.3041462898254395,
      "learning_rate": 4.927293290786444e-05,
      "loss": 0.446,
      "step": 860
    },
    {
      "epoch": 0.10333768856158689,
      "grad_norm": 8.052353858947754,
      "learning_rate": 4.925273659974957e-05,
      "loss": 0.4965,
      "step": 870
    },
    {
      "epoch": 0.10452547808528329,
      "grad_norm": 6.866906642913818,
      "learning_rate": 4.923254029163469e-05,
      "loss": 0.526,
      "step": 880
    },
    {
      "epoch": 0.10571326760897969,
      "grad_norm": 5.992532730102539,
      "learning_rate": 4.921234398351981e-05,
      "loss": 0.5709,
      "step": 890
    },
    {
      "epoch": 0.10690105713267609,
      "grad_norm": 9.69338607788086,
      "learning_rate": 4.919214767540494e-05,
      "loss": 0.4764,
      "step": 900
    },
    {
      "epoch": 0.10808884665637249,
      "grad_norm": 6.739308834075928,
      "learning_rate": 4.917195136729006e-05,
      "loss": 0.5039,
      "step": 910
    },
    {
      "epoch": 0.10927663618006889,
      "grad_norm": 6.0438408851623535,
      "learning_rate": 4.915175505917519e-05,
      "loss": 0.4738,
      "step": 920
    },
    {
      "epoch": 0.11046442570376529,
      "grad_norm": 14.130400657653809,
      "learning_rate": 4.913155875106031e-05,
      "loss": 0.4798,
      "step": 930
    },
    {
      "epoch": 0.11165221522746169,
      "grad_norm": 5.511341571807861,
      "learning_rate": 4.911136244294543e-05,
      "loss": 0.5008,
      "step": 940
    },
    {
      "epoch": 0.1128400047511581,
      "grad_norm": 13.602300643920898,
      "learning_rate": 4.909116613483056e-05,
      "loss": 0.5073,
      "step": 950
    },
    {
      "epoch": 0.1140277942748545,
      "grad_norm": 5.304278373718262,
      "learning_rate": 4.9070969826715676e-05,
      "loss": 0.4298,
      "step": 960
    },
    {
      "epoch": 0.1152155837985509,
      "grad_norm": 3.1956429481506348,
      "learning_rate": 4.90507735186008e-05,
      "loss": 0.442,
      "step": 970
    },
    {
      "epoch": 0.1164033733222473,
      "grad_norm": 14.201797485351562,
      "learning_rate": 4.903057721048592e-05,
      "loss": 0.5348,
      "step": 980
    },
    {
      "epoch": 0.1175911628459437,
      "grad_norm": 11.228254318237305,
      "learning_rate": 4.901038090237105e-05,
      "loss": 0.5108,
      "step": 990
    },
    {
      "epoch": 0.1187789523696401,
      "grad_norm": 11.285070419311523,
      "learning_rate": 4.899018459425617e-05,
      "loss": 0.5736,
      "step": 1000
    },
    {
      "epoch": 0.1199667418933365,
      "grad_norm": 4.430886745452881,
      "learning_rate": 4.8969988286141297e-05,
      "loss": 0.4655,
      "step": 1010
    },
    {
      "epoch": 0.1211545314170329,
      "grad_norm": 7.314514636993408,
      "learning_rate": 4.894979197802642e-05,
      "loss": 0.4665,
      "step": 1020
    },
    {
      "epoch": 0.1223423209407293,
      "grad_norm": 4.75882625579834,
      "learning_rate": 4.892959566991154e-05,
      "loss": 0.4779,
      "step": 1030
    },
    {
      "epoch": 0.1235301104644257,
      "grad_norm": 8.033220291137695,
      "learning_rate": 4.8909399361796666e-05,
      "loss": 0.5434,
      "step": 1040
    },
    {
      "epoch": 0.1247178999881221,
      "grad_norm": 12.560453414916992,
      "learning_rate": 4.8889203053681785e-05,
      "loss": 0.4601,
      "step": 1050
    },
    {
      "epoch": 0.12590568951181852,
      "grad_norm": 7.138411045074463,
      "learning_rate": 4.886900674556692e-05,
      "loss": 0.4404,
      "step": 1060
    },
    {
      "epoch": 0.1270934790355149,
      "grad_norm": 9.074617385864258,
      "learning_rate": 4.8848810437452035e-05,
      "loss": 0.5196,
      "step": 1070
    },
    {
      "epoch": 0.12828126855921132,
      "grad_norm": 9.30325984954834,
      "learning_rate": 4.882861412933716e-05,
      "loss": 0.3809,
      "step": 1080
    },
    {
      "epoch": 0.1294690580829077,
      "grad_norm": 9.668411254882812,
      "learning_rate": 4.8808417821222286e-05,
      "loss": 0.5434,
      "step": 1090
    },
    {
      "epoch": 0.13065684760660412,
      "grad_norm": 6.513296604156494,
      "learning_rate": 4.8788221513107405e-05,
      "loss": 0.4667,
      "step": 1100
    },
    {
      "epoch": 0.1318446371303005,
      "grad_norm": 12.994779586791992,
      "learning_rate": 4.876802520499253e-05,
      "loss": 0.5508,
      "step": 1110
    },
    {
      "epoch": 0.13303242665399692,
      "grad_norm": 6.9217848777771,
      "learning_rate": 4.874782889687765e-05,
      "loss": 0.4355,
      "step": 1120
    },
    {
      "epoch": 0.1342202161776933,
      "grad_norm": 6.177170753479004,
      "learning_rate": 4.872763258876278e-05,
      "loss": 0.4651,
      "step": 1130
    },
    {
      "epoch": 0.13540800570138972,
      "grad_norm": 9.289709091186523,
      "learning_rate": 4.87074362806479e-05,
      "loss": 0.528,
      "step": 1140
    },
    {
      "epoch": 0.1365957952250861,
      "grad_norm": 2.8235373497009277,
      "learning_rate": 4.8687239972533025e-05,
      "loss": 0.4242,
      "step": 1150
    },
    {
      "epoch": 0.13778358474878252,
      "grad_norm": 4.679508209228516,
      "learning_rate": 4.866704366441815e-05,
      "loss": 0.4134,
      "step": 1160
    },
    {
      "epoch": 0.1389713742724789,
      "grad_norm": 13.73006820678711,
      "learning_rate": 4.864684735630327e-05,
      "loss": 0.5172,
      "step": 1170
    },
    {
      "epoch": 0.14015916379617532,
      "grad_norm": 3.132460594177246,
      "learning_rate": 4.8626651048188395e-05,
      "loss": 0.49,
      "step": 1180
    },
    {
      "epoch": 0.1413469533198717,
      "grad_norm": 10.425761222839355,
      "learning_rate": 4.860645474007351e-05,
      "loss": 0.4173,
      "step": 1190
    },
    {
      "epoch": 0.14253474284356812,
      "grad_norm": 7.193592548370361,
      "learning_rate": 4.8586258431958645e-05,
      "loss": 0.4992,
      "step": 1200
    },
    {
      "epoch": 0.1437225323672645,
      "grad_norm": 2.1664464473724365,
      "learning_rate": 4.8566062123843764e-05,
      "loss": 0.4033,
      "step": 1210
    },
    {
      "epoch": 0.14491032189096092,
      "grad_norm": 13.453564643859863,
      "learning_rate": 4.854586581572888e-05,
      "loss": 0.5312,
      "step": 1220
    },
    {
      "epoch": 0.1460981114146573,
      "grad_norm": 13.485347747802734,
      "learning_rate": 4.852566950761401e-05,
      "loss": 0.4753,
      "step": 1230
    },
    {
      "epoch": 0.14728590093835373,
      "grad_norm": 13.25900936126709,
      "learning_rate": 4.8505473199499134e-05,
      "loss": 0.4944,
      "step": 1240
    },
    {
      "epoch": 0.1484736904620501,
      "grad_norm": 15.741289138793945,
      "learning_rate": 4.848527689138426e-05,
      "loss": 0.448,
      "step": 1250
    },
    {
      "epoch": 0.14966147998574653,
      "grad_norm": 5.608346462249756,
      "learning_rate": 4.846508058326938e-05,
      "loss": 0.4952,
      "step": 1260
    },
    {
      "epoch": 0.15084926950944294,
      "grad_norm": 7.130008697509766,
      "learning_rate": 4.84448842751545e-05,
      "loss": 0.4956,
      "step": 1270
    },
    {
      "epoch": 0.15203705903313933,
      "grad_norm": 9.327939987182617,
      "learning_rate": 4.842468796703963e-05,
      "loss": 0.4349,
      "step": 1280
    },
    {
      "epoch": 0.15322484855683574,
      "grad_norm": 3.7363126277923584,
      "learning_rate": 4.840449165892475e-05,
      "loss": 0.5283,
      "step": 1290
    },
    {
      "epoch": 0.15441263808053213,
      "grad_norm": 14.569894790649414,
      "learning_rate": 4.838429535080987e-05,
      "loss": 0.3612,
      "step": 1300
    },
    {
      "epoch": 0.15560042760422854,
      "grad_norm": 8.083725929260254,
      "learning_rate": 4.8364099042695e-05,
      "loss": 0.5067,
      "step": 1310
    },
    {
      "epoch": 0.15678821712792493,
      "grad_norm": 12.746700286865234,
      "learning_rate": 4.834390273458012e-05,
      "loss": 0.4559,
      "step": 1320
    },
    {
      "epoch": 0.15797600665162134,
      "grad_norm": 5.609346389770508,
      "learning_rate": 4.832370642646524e-05,
      "loss": 0.4844,
      "step": 1330
    },
    {
      "epoch": 0.15916379617531773,
      "grad_norm": 2.569969892501831,
      "learning_rate": 4.830351011835037e-05,
      "loss": 0.3494,
      "step": 1340
    },
    {
      "epoch": 0.16035158569901414,
      "grad_norm": 15.027949333190918,
      "learning_rate": 4.828331381023549e-05,
      "loss": 0.4443,
      "step": 1350
    },
    {
      "epoch": 0.16153937522271053,
      "grad_norm": 7.381288051605225,
      "learning_rate": 4.826311750212061e-05,
      "loss": 0.3741,
      "step": 1360
    },
    {
      "epoch": 0.16272716474640694,
      "grad_norm": 8.2087984085083,
      "learning_rate": 4.824292119400574e-05,
      "loss": 0.4046,
      "step": 1370
    },
    {
      "epoch": 0.16391495427010333,
      "grad_norm": 9.716196060180664,
      "learning_rate": 4.822272488589086e-05,
      "loss": 0.4667,
      "step": 1380
    },
    {
      "epoch": 0.16510274379379974,
      "grad_norm": 11.40641975402832,
      "learning_rate": 4.820252857777599e-05,
      "loss": 0.6322,
      "step": 1390
    },
    {
      "epoch": 0.16629053331749613,
      "grad_norm": 7.021626949310303,
      "learning_rate": 4.8182332269661106e-05,
      "loss": 0.4983,
      "step": 1400
    },
    {
      "epoch": 0.16747832284119255,
      "grad_norm": 9.936989784240723,
      "learning_rate": 4.816213596154623e-05,
      "loss": 0.3805,
      "step": 1410
    },
    {
      "epoch": 0.16866611236488893,
      "grad_norm": 7.261778831481934,
      "learning_rate": 4.814193965343136e-05,
      "loss": 0.3919,
      "step": 1420
    },
    {
      "epoch": 0.16985390188858535,
      "grad_norm": 7.500991344451904,
      "learning_rate": 4.8121743345316476e-05,
      "loss": 0.6191,
      "step": 1430
    },
    {
      "epoch": 0.17104169141228173,
      "grad_norm": 6.671547889709473,
      "learning_rate": 4.81015470372016e-05,
      "loss": 0.4216,
      "step": 1440
    },
    {
      "epoch": 0.17222948093597815,
      "grad_norm": 8.298477172851562,
      "learning_rate": 4.8081350729086726e-05,
      "loss": 0.5507,
      "step": 1450
    },
    {
      "epoch": 0.17341727045967453,
      "grad_norm": 3.7865095138549805,
      "learning_rate": 4.806115442097185e-05,
      "loss": 0.4875,
      "step": 1460
    },
    {
      "epoch": 0.17460505998337095,
      "grad_norm": 10.071208000183105,
      "learning_rate": 4.804095811285697e-05,
      "loss": 0.5597,
      "step": 1470
    },
    {
      "epoch": 0.17579284950706736,
      "grad_norm": 3.9404659271240234,
      "learning_rate": 4.8020761804742096e-05,
      "loss": 0.4932,
      "step": 1480
    },
    {
      "epoch": 0.17698063903076375,
      "grad_norm": 14.825315475463867,
      "learning_rate": 4.800056549662722e-05,
      "loss": 0.3966,
      "step": 1490
    },
    {
      "epoch": 0.17816842855446016,
      "grad_norm": 3.219564914703369,
      "learning_rate": 4.798036918851234e-05,
      "loss": 0.3166,
      "step": 1500
    },
    {
      "epoch": 0.17935621807815655,
      "grad_norm": 8.211339950561523,
      "learning_rate": 4.7960172880397465e-05,
      "loss": 0.4569,
      "step": 1510
    },
    {
      "epoch": 0.18054400760185296,
      "grad_norm": 28.574251174926758,
      "learning_rate": 4.793997657228259e-05,
      "loss": 0.4082,
      "step": 1520
    },
    {
      "epoch": 0.18173179712554935,
      "grad_norm": 9.549306869506836,
      "learning_rate": 4.7919780264167716e-05,
      "loss": 0.4462,
      "step": 1530
    },
    {
      "epoch": 0.18291958664924576,
      "grad_norm": 10.74986743927002,
      "learning_rate": 4.7899583956052835e-05,
      "loss": 0.5763,
      "step": 1540
    },
    {
      "epoch": 0.18410737617294215,
      "grad_norm": 18.05826187133789,
      "learning_rate": 4.7879387647937953e-05,
      "loss": 0.3571,
      "step": 1550
    },
    {
      "epoch": 0.18529516569663856,
      "grad_norm": 16.856159210205078,
      "learning_rate": 4.7859191339823086e-05,
      "loss": 0.5069,
      "step": 1560
    },
    {
      "epoch": 0.18648295522033495,
      "grad_norm": 9.720256805419922,
      "learning_rate": 4.7838995031708204e-05,
      "loss": 0.4871,
      "step": 1570
    },
    {
      "epoch": 0.18767074474403136,
      "grad_norm": 9.31482982635498,
      "learning_rate": 4.781879872359333e-05,
      "loss": 0.4513,
      "step": 1580
    },
    {
      "epoch": 0.18885853426772775,
      "grad_norm": 15.629776954650879,
      "learning_rate": 4.7798602415478455e-05,
      "loss": 0.4253,
      "step": 1590
    },
    {
      "epoch": 0.19004632379142417,
      "grad_norm": 13.192623138427734,
      "learning_rate": 4.7778406107363574e-05,
      "loss": 0.4643,
      "step": 1600
    },
    {
      "epoch": 0.19123411331512055,
      "grad_norm": 6.096563339233398,
      "learning_rate": 4.77582097992487e-05,
      "loss": 0.4526,
      "step": 1610
    },
    {
      "epoch": 0.19242190283881697,
      "grad_norm": 4.842116355895996,
      "learning_rate": 4.773801349113382e-05,
      "loss": 0.3882,
      "step": 1620
    },
    {
      "epoch": 0.19360969236251335,
      "grad_norm": 12.17288875579834,
      "learning_rate": 4.771781718301895e-05,
      "loss": 0.4722,
      "step": 1630
    },
    {
      "epoch": 0.19479748188620977,
      "grad_norm": 10.484006881713867,
      "learning_rate": 4.769762087490407e-05,
      "loss": 0.4494,
      "step": 1640
    },
    {
      "epoch": 0.19598527140990615,
      "grad_norm": 18.098337173461914,
      "learning_rate": 4.7677424566789194e-05,
      "loss": 0.3344,
      "step": 1650
    },
    {
      "epoch": 0.19717306093360257,
      "grad_norm": 3.5647261142730713,
      "learning_rate": 4.765722825867432e-05,
      "loss": 0.4355,
      "step": 1660
    },
    {
      "epoch": 0.19836085045729895,
      "grad_norm": 8.591007232666016,
      "learning_rate": 4.763703195055944e-05,
      "loss": 0.4566,
      "step": 1670
    },
    {
      "epoch": 0.19954863998099537,
      "grad_norm": 17.269392013549805,
      "learning_rate": 4.7616835642444563e-05,
      "loss": 0.3974,
      "step": 1680
    },
    {
      "epoch": 0.20073642950469178,
      "grad_norm": 15.745661735534668,
      "learning_rate": 4.759663933432968e-05,
      "loss": 0.4178,
      "step": 1690
    },
    {
      "epoch": 0.20192421902838817,
      "grad_norm": 11.832619667053223,
      "learning_rate": 4.7576443026214814e-05,
      "loss": 0.4294,
      "step": 1700
    },
    {
      "epoch": 0.20311200855208458,
      "grad_norm": 9.936813354492188,
      "learning_rate": 4.755624671809993e-05,
      "loss": 0.4479,
      "step": 1710
    },
    {
      "epoch": 0.20429979807578097,
      "grad_norm": 18.938295364379883,
      "learning_rate": 4.753605040998506e-05,
      "loss": 0.4331,
      "step": 1720
    },
    {
      "epoch": 0.20548758759947738,
      "grad_norm": 1.5995380878448486,
      "learning_rate": 4.7515854101870184e-05,
      "loss": 0.3973,
      "step": 1730
    },
    {
      "epoch": 0.20667537712317377,
      "grad_norm": 18.9797420501709,
      "learning_rate": 4.74956577937553e-05,
      "loss": 0.611,
      "step": 1740
    },
    {
      "epoch": 0.20786316664687018,
      "grad_norm": 8.75420093536377,
      "learning_rate": 4.747546148564043e-05,
      "loss": 0.3798,
      "step": 1750
    },
    {
      "epoch": 0.20905095617056657,
      "grad_norm": 6.259380340576172,
      "learning_rate": 4.7455265177525546e-05,
      "loss": 0.5,
      "step": 1760
    },
    {
      "epoch": 0.21023874569426299,
      "grad_norm": 10.076289176940918,
      "learning_rate": 4.743506886941068e-05,
      "loss": 0.493,
      "step": 1770
    },
    {
      "epoch": 0.21142653521795937,
      "grad_norm": 24.3170166015625,
      "learning_rate": 4.74148725612958e-05,
      "loss": 0.5387,
      "step": 1780
    },
    {
      "epoch": 0.21261432474165579,
      "grad_norm": 8.668848991394043,
      "learning_rate": 4.739467625318092e-05,
      "loss": 0.5339,
      "step": 1790
    },
    {
      "epoch": 0.21380211426535217,
      "grad_norm": 31.958791732788086,
      "learning_rate": 4.737447994506604e-05,
      "loss": 0.4081,
      "step": 1800
    },
    {
      "epoch": 0.2149899037890486,
      "grad_norm": 12.881916999816895,
      "learning_rate": 4.735428363695117e-05,
      "loss": 0.3624,
      "step": 1810
    },
    {
      "epoch": 0.21617769331274497,
      "grad_norm": 10.048140525817871,
      "learning_rate": 4.733408732883629e-05,
      "loss": 0.3082,
      "step": 1820
    },
    {
      "epoch": 0.2173654828364414,
      "grad_norm": 9.223479270935059,
      "learning_rate": 4.731389102072141e-05,
      "loss": 0.4794,
      "step": 1830
    },
    {
      "epoch": 0.21855327236013777,
      "grad_norm": 6.066252708435059,
      "learning_rate": 4.729369471260654e-05,
      "loss": 0.5793,
      "step": 1840
    },
    {
      "epoch": 0.2197410618838342,
      "grad_norm": 18.52729606628418,
      "learning_rate": 4.727349840449166e-05,
      "loss": 0.5252,
      "step": 1850
    },
    {
      "epoch": 0.22092885140753057,
      "grad_norm": 1.8465696573257446,
      "learning_rate": 4.725330209637679e-05,
      "loss": 0.3994,
      "step": 1860
    },
    {
      "epoch": 0.222116640931227,
      "grad_norm": 6.187740802764893,
      "learning_rate": 4.7233105788261906e-05,
      "loss": 0.4273,
      "step": 1870
    },
    {
      "epoch": 0.22330443045492337,
      "grad_norm": 10.340858459472656,
      "learning_rate": 4.721290948014703e-05,
      "loss": 0.322,
      "step": 1880
    },
    {
      "epoch": 0.2244922199786198,
      "grad_norm": 30.44989776611328,
      "learning_rate": 4.7192713172032156e-05,
      "loss": 0.4524,
      "step": 1890
    },
    {
      "epoch": 0.2256800095023162,
      "grad_norm": 19.412546157836914,
      "learning_rate": 4.7172516863917275e-05,
      "loss": 0.4389,
      "step": 1900
    },
    {
      "epoch": 0.2268677990260126,
      "grad_norm": 10.495121002197266,
      "learning_rate": 4.715232055580241e-05,
      "loss": 0.4439,
      "step": 1910
    },
    {
      "epoch": 0.228055588549709,
      "grad_norm": 6.538065433502197,
      "learning_rate": 4.7132124247687526e-05,
      "loss": 0.4181,
      "step": 1920
    },
    {
      "epoch": 0.2292433780734054,
      "grad_norm": 11.317536354064941,
      "learning_rate": 4.7111927939572644e-05,
      "loss": 0.3044,
      "step": 1930
    },
    {
      "epoch": 0.2304311675971018,
      "grad_norm": 12.072446823120117,
      "learning_rate": 4.709173163145777e-05,
      "loss": 0.3031,
      "step": 1940
    },
    {
      "epoch": 0.2316189571207982,
      "grad_norm": 7.378643035888672,
      "learning_rate": 4.7071535323342895e-05,
      "loss": 0.3866,
      "step": 1950
    },
    {
      "epoch": 0.2328067466444946,
      "grad_norm": 4.614828109741211,
      "learning_rate": 4.705133901522802e-05,
      "loss": 0.3214,
      "step": 1960
    },
    {
      "epoch": 0.233994536168191,
      "grad_norm": 18.714794158935547,
      "learning_rate": 4.703114270711314e-05,
      "loss": 0.3879,
      "step": 1970
    },
    {
      "epoch": 0.2351823256918874,
      "grad_norm": 15.207596778869629,
      "learning_rate": 4.7010946398998265e-05,
      "loss": 0.5226,
      "step": 1980
    },
    {
      "epoch": 0.2363701152155838,
      "grad_norm": 17.063119888305664,
      "learning_rate": 4.699075009088339e-05,
      "loss": 0.377,
      "step": 1990
    },
    {
      "epoch": 0.2375579047392802,
      "grad_norm": 15.8844575881958,
      "learning_rate": 4.697055378276851e-05,
      "loss": 0.4126,
      "step": 2000
    },
    {
      "epoch": 0.2387456942629766,
      "grad_norm": 12.60599136352539,
      "learning_rate": 4.6950357474653634e-05,
      "loss": 0.3159,
      "step": 2010
    },
    {
      "epoch": 0.239933483786673,
      "grad_norm": 1.9277938604354858,
      "learning_rate": 4.693016116653876e-05,
      "loss": 0.5723,
      "step": 2020
    },
    {
      "epoch": 0.2411212733103694,
      "grad_norm": 13.465182304382324,
      "learning_rate": 4.6909964858423885e-05,
      "loss": 0.4973,
      "step": 2030
    },
    {
      "epoch": 0.2423090628340658,
      "grad_norm": 12.744091987609863,
      "learning_rate": 4.6889768550309004e-05,
      "loss": 0.2987,
      "step": 2040
    },
    {
      "epoch": 0.2434968523577622,
      "grad_norm": 21.032520294189453,
      "learning_rate": 4.686957224219413e-05,
      "loss": 0.3695,
      "step": 2050
    },
    {
      "epoch": 0.2446846418814586,
      "grad_norm": 8.545729637145996,
      "learning_rate": 4.6849375934079254e-05,
      "loss": 0.4652,
      "step": 2060
    },
    {
      "epoch": 0.245872431405155,
      "grad_norm": 11.345853805541992,
      "learning_rate": 4.682917962596437e-05,
      "loss": 0.478,
      "step": 2070
    },
    {
      "epoch": 0.2470602209288514,
      "grad_norm": 4.2132086753845215,
      "learning_rate": 4.68089833178495e-05,
      "loss": 0.5556,
      "step": 2080
    },
    {
      "epoch": 0.2482480104525478,
      "grad_norm": 12.806997299194336,
      "learning_rate": 4.6788787009734624e-05,
      "loss": 0.4915,
      "step": 2090
    },
    {
      "epoch": 0.2494357999762442,
      "grad_norm": 12.168424606323242,
      "learning_rate": 4.676859070161975e-05,
      "loss": 0.3425,
      "step": 2100
    },
    {
      "epoch": 0.2506235894999406,
      "grad_norm": 12.227484703063965,
      "learning_rate": 4.674839439350487e-05,
      "loss": 0.4878,
      "step": 2110
    },
    {
      "epoch": 0.25181137902363704,
      "grad_norm": 6.092287063598633,
      "learning_rate": 4.672819808538999e-05,
      "loss": 0.3697,
      "step": 2120
    },
    {
      "epoch": 0.2529991685473334,
      "grad_norm": 19.45308494567871,
      "learning_rate": 4.670800177727512e-05,
      "loss": 0.3939,
      "step": 2130
    },
    {
      "epoch": 0.2541869580710298,
      "grad_norm": 13.067036628723145,
      "learning_rate": 4.668780546916024e-05,
      "loss": 0.4764,
      "step": 2140
    },
    {
      "epoch": 0.2553747475947262,
      "grad_norm": 10.887768745422363,
      "learning_rate": 4.666760916104536e-05,
      "loss": 0.4823,
      "step": 2150
    },
    {
      "epoch": 0.25656253711842264,
      "grad_norm": 11.950045585632324,
      "learning_rate": 4.664741285293049e-05,
      "loss": 0.3819,
      "step": 2160
    },
    {
      "epoch": 0.257750326642119,
      "grad_norm": 5.315244674682617,
      "learning_rate": 4.6627216544815614e-05,
      "loss": 0.4088,
      "step": 2170
    },
    {
      "epoch": 0.2589381161658154,
      "grad_norm": 16.66663360595703,
      "learning_rate": 4.660702023670073e-05,
      "loss": 0.393,
      "step": 2180
    },
    {
      "epoch": 0.2601259056895118,
      "grad_norm": 7.909355163574219,
      "learning_rate": 4.658682392858586e-05,
      "loss": 0.3492,
      "step": 2190
    },
    {
      "epoch": 0.26131369521320824,
      "grad_norm": 7.2842302322387695,
      "learning_rate": 4.656662762047098e-05,
      "loss": 0.4222,
      "step": 2200
    },
    {
      "epoch": 0.2625014847369046,
      "grad_norm": 18.798355102539062,
      "learning_rate": 4.65464313123561e-05,
      "loss": 0.4438,
      "step": 2210
    },
    {
      "epoch": 0.263689274260601,
      "grad_norm": 12.2824068069458,
      "learning_rate": 4.652623500424123e-05,
      "loss": 0.3608,
      "step": 2220
    },
    {
      "epoch": 0.26487706378429743,
      "grad_norm": 5.844780921936035,
      "learning_rate": 4.650603869612635e-05,
      "loss": 0.4291,
      "step": 2230
    },
    {
      "epoch": 0.26606485330799384,
      "grad_norm": 11.465861320495605,
      "learning_rate": 4.648584238801148e-05,
      "loss": 0.5435,
      "step": 2240
    },
    {
      "epoch": 0.2672526428316902,
      "grad_norm": 9.61861801147461,
      "learning_rate": 4.6465646079896596e-05,
      "loss": 0.4031,
      "step": 2250
    },
    {
      "epoch": 0.2684404323553866,
      "grad_norm": 7.932845115661621,
      "learning_rate": 4.6445449771781715e-05,
      "loss": 0.3118,
      "step": 2260
    },
    {
      "epoch": 0.26962822187908303,
      "grad_norm": 18.786752700805664,
      "learning_rate": 4.642525346366685e-05,
      "loss": 0.5005,
      "step": 2270
    },
    {
      "epoch": 0.27081601140277944,
      "grad_norm": 15.974261283874512,
      "learning_rate": 4.6405057155551966e-05,
      "loss": 0.5509,
      "step": 2280
    },
    {
      "epoch": 0.2720038009264758,
      "grad_norm": 11.837593078613281,
      "learning_rate": 4.638486084743709e-05,
      "loss": 0.3788,
      "step": 2290
    },
    {
      "epoch": 0.2731915904501722,
      "grad_norm": 4.74309778213501,
      "learning_rate": 4.636466453932222e-05,
      "loss": 0.3716,
      "step": 2300
    },
    {
      "epoch": 0.27437937997386863,
      "grad_norm": 14.604912757873535,
      "learning_rate": 4.6344468231207335e-05,
      "loss": 0.4689,
      "step": 2310
    },
    {
      "epoch": 0.27556716949756505,
      "grad_norm": 17.05802345275879,
      "learning_rate": 4.632427192309246e-05,
      "loss": 0.3541,
      "step": 2320
    },
    {
      "epoch": 0.27675495902126146,
      "grad_norm": 8.757406234741211,
      "learning_rate": 4.630407561497758e-05,
      "loss": 0.3084,
      "step": 2330
    },
    {
      "epoch": 0.2779427485449578,
      "grad_norm": 14.270926475524902,
      "learning_rate": 4.628387930686271e-05,
      "loss": 0.425,
      "step": 2340
    },
    {
      "epoch": 0.27913053806865423,
      "grad_norm": 53.29812240600586,
      "learning_rate": 4.626368299874783e-05,
      "loss": 0.5205,
      "step": 2350
    },
    {
      "epoch": 0.28031832759235065,
      "grad_norm": 21.826309204101562,
      "learning_rate": 4.6243486690632956e-05,
      "loss": 0.3877,
      "step": 2360
    },
    {
      "epoch": 0.28150611711604706,
      "grad_norm": 21.623350143432617,
      "learning_rate": 4.6223290382518074e-05,
      "loss": 0.339,
      "step": 2370
    },
    {
      "epoch": 0.2826939066397434,
      "grad_norm": 7.923421382904053,
      "learning_rate": 4.62030940744032e-05,
      "loss": 0.4516,
      "step": 2380
    },
    {
      "epoch": 0.28388169616343983,
      "grad_norm": 16.60175132751465,
      "learning_rate": 4.6182897766288325e-05,
      "loss": 0.4398,
      "step": 2390
    },
    {
      "epoch": 0.28506948568713625,
      "grad_norm": 20.52156639099121,
      "learning_rate": 4.6162701458173444e-05,
      "loss": 0.4965,
      "step": 2400
    },
    {
      "epoch": 0.28625727521083266,
      "grad_norm": 10.168922424316406,
      "learning_rate": 4.6142505150058576e-05,
      "loss": 0.5497,
      "step": 2410
    },
    {
      "epoch": 0.287445064734529,
      "grad_norm": 10.445052146911621,
      "learning_rate": 4.6122308841943695e-05,
      "loss": 0.359,
      "step": 2420
    },
    {
      "epoch": 0.28863285425822544,
      "grad_norm": 9.222341537475586,
      "learning_rate": 4.610211253382882e-05,
      "loss": 0.3312,
      "step": 2430
    },
    {
      "epoch": 0.28982064378192185,
      "grad_norm": 3.2413759231567383,
      "learning_rate": 4.608191622571394e-05,
      "loss": 0.4143,
      "step": 2440
    },
    {
      "epoch": 0.29100843330561826,
      "grad_norm": 6.683810710906982,
      "learning_rate": 4.6061719917599064e-05,
      "loss": 0.4427,
      "step": 2450
    },
    {
      "epoch": 0.2921962228293146,
      "grad_norm": 8.63145923614502,
      "learning_rate": 4.604152360948419e-05,
      "loss": 0.3786,
      "step": 2460
    },
    {
      "epoch": 0.29338401235301104,
      "grad_norm": 8.000901222229004,
      "learning_rate": 4.602132730136931e-05,
      "loss": 0.36,
      "step": 2470
    },
    {
      "epoch": 0.29457180187670745,
      "grad_norm": 2.657128095626831,
      "learning_rate": 4.600113099325444e-05,
      "loss": 0.4778,
      "step": 2480
    },
    {
      "epoch": 0.29575959140040387,
      "grad_norm": 7.7156524658203125,
      "learning_rate": 4.598093468513956e-05,
      "loss": 0.3836,
      "step": 2490
    },
    {
      "epoch": 0.2969473809241002,
      "grad_norm": 6.074797630310059,
      "learning_rate": 4.5960738377024684e-05,
      "loss": 0.434,
      "step": 2500
    },
    {
      "epoch": 0.29813517044779664,
      "grad_norm": 27.329389572143555,
      "learning_rate": 4.59405420689098e-05,
      "loss": 0.4092,
      "step": 2510
    },
    {
      "epoch": 0.29932295997149305,
      "grad_norm": 3.836005449295044,
      "learning_rate": 4.592034576079493e-05,
      "loss": 0.2666,
      "step": 2520
    },
    {
      "epoch": 0.30051074949518947,
      "grad_norm": 6.92724609375,
      "learning_rate": 4.5900149452680054e-05,
      "loss": 0.515,
      "step": 2530
    },
    {
      "epoch": 0.3016985390188859,
      "grad_norm": 3.0361931324005127,
      "learning_rate": 4.587995314456517e-05,
      "loss": 0.2991,
      "step": 2540
    },
    {
      "epoch": 0.30288632854258224,
      "grad_norm": 19.627805709838867,
      "learning_rate": 4.5859756836450305e-05,
      "loss": 0.4448,
      "step": 2550
    },
    {
      "epoch": 0.30407411806627865,
      "grad_norm": 11.694130897521973,
      "learning_rate": 4.583956052833542e-05,
      "loss": 0.467,
      "step": 2560
    },
    {
      "epoch": 0.30526190758997507,
      "grad_norm": 4.8844685554504395,
      "learning_rate": 4.581936422022055e-05,
      "loss": 0.3543,
      "step": 2570
    },
    {
      "epoch": 0.3064496971136715,
      "grad_norm": 14.175518989562988,
      "learning_rate": 4.579916791210567e-05,
      "loss": 0.2952,
      "step": 2580
    },
    {
      "epoch": 0.30763748663736784,
      "grad_norm": 19.29123878479004,
      "learning_rate": 4.577897160399079e-05,
      "loss": 0.4614,
      "step": 2590
    },
    {
      "epoch": 0.30882527616106425,
      "grad_norm": 12.127927780151367,
      "learning_rate": 4.575877529587592e-05,
      "loss": 0.5072,
      "step": 2600
    },
    {
      "epoch": 0.31001306568476067,
      "grad_norm": 11.614591598510742,
      "learning_rate": 4.573857898776104e-05,
      "loss": 0.4973,
      "step": 2610
    },
    {
      "epoch": 0.3112008552084571,
      "grad_norm": 6.396824359893799,
      "learning_rate": 4.571838267964617e-05,
      "loss": 0.4304,
      "step": 2620
    },
    {
      "epoch": 0.31238864473215344,
      "grad_norm": 8.470419883728027,
      "learning_rate": 4.569818637153129e-05,
      "loss": 0.4762,
      "step": 2630
    },
    {
      "epoch": 0.31357643425584986,
      "grad_norm": 13.268900871276855,
      "learning_rate": 4.5677990063416406e-05,
      "loss": 0.3294,
      "step": 2640
    },
    {
      "epoch": 0.31476422377954627,
      "grad_norm": 12.65753173828125,
      "learning_rate": 4.565779375530153e-05,
      "loss": 0.3835,
      "step": 2650
    },
    {
      "epoch": 0.3159520133032427,
      "grad_norm": 28.63498878479004,
      "learning_rate": 4.563759744718666e-05,
      "loss": 0.346,
      "step": 2660
    },
    {
      "epoch": 0.31713980282693904,
      "grad_norm": 16.64824867248535,
      "learning_rate": 4.561740113907178e-05,
      "loss": 0.3465,
      "step": 2670
    },
    {
      "epoch": 0.31832759235063546,
      "grad_norm": 9.503334999084473,
      "learning_rate": 4.55972048309569e-05,
      "loss": 0.37,
      "step": 2680
    },
    {
      "epoch": 0.31951538187433187,
      "grad_norm": 11.527192115783691,
      "learning_rate": 4.5577008522842026e-05,
      "loss": 0.4103,
      "step": 2690
    },
    {
      "epoch": 0.3207031713980283,
      "grad_norm": 3.233851909637451,
      "learning_rate": 4.555681221472715e-05,
      "loss": 0.3451,
      "step": 2700
    },
    {
      "epoch": 0.32189096092172464,
      "grad_norm": 7.9146504402160645,
      "learning_rate": 4.553661590661227e-05,
      "loss": 0.2885,
      "step": 2710
    },
    {
      "epoch": 0.32307875044542106,
      "grad_norm": 1.9722609519958496,
      "learning_rate": 4.5516419598497396e-05,
      "loss": 0.2885,
      "step": 2720
    },
    {
      "epoch": 0.3242665399691175,
      "grad_norm": 14.059633255004883,
      "learning_rate": 4.549622329038252e-05,
      "loss": 0.4473,
      "step": 2730
    },
    {
      "epoch": 0.3254543294928139,
      "grad_norm": 10.714337348937988,
      "learning_rate": 4.547602698226765e-05,
      "loss": 0.5333,
      "step": 2740
    },
    {
      "epoch": 0.3266421190165103,
      "grad_norm": 21.0417423248291,
      "learning_rate": 4.5455830674152765e-05,
      "loss": 0.3656,
      "step": 2750
    },
    {
      "epoch": 0.32782990854020666,
      "grad_norm": 17.92778205871582,
      "learning_rate": 4.543563436603789e-05,
      "loss": 0.5642,
      "step": 2760
    },
    {
      "epoch": 0.3290176980639031,
      "grad_norm": 7.248648643493652,
      "learning_rate": 4.5415438057923016e-05,
      "loss": 0.4641,
      "step": 2770
    },
    {
      "epoch": 0.3302054875875995,
      "grad_norm": 5.496622562408447,
      "learning_rate": 4.5395241749808135e-05,
      "loss": 0.334,
      "step": 2780
    },
    {
      "epoch": 0.3313932771112959,
      "grad_norm": 9.370548248291016,
      "learning_rate": 4.537504544169326e-05,
      "loss": 0.4508,
      "step": 2790
    },
    {
      "epoch": 0.33258106663499226,
      "grad_norm": 9.950486183166504,
      "learning_rate": 4.5354849133578386e-05,
      "loss": 0.3373,
      "step": 2800
    },
    {
      "epoch": 0.3337688561586887,
      "grad_norm": 10.14198112487793,
      "learning_rate": 4.533465282546351e-05,
      "loss": 0.493,
      "step": 2810
    },
    {
      "epoch": 0.3349566456823851,
      "grad_norm": 15.428964614868164,
      "learning_rate": 4.531445651734863e-05,
      "loss": 0.4835,
      "step": 2820
    },
    {
      "epoch": 0.3361444352060815,
      "grad_norm": 7.583471775054932,
      "learning_rate": 4.5294260209233755e-05,
      "loss": 0.372,
      "step": 2830
    },
    {
      "epoch": 0.33733222472977786,
      "grad_norm": 2.755049705505371,
      "learning_rate": 4.527406390111888e-05,
      "loss": 0.2434,
      "step": 2840
    },
    {
      "epoch": 0.3385200142534743,
      "grad_norm": 20.16036033630371,
      "learning_rate": 4.5253867593004e-05,
      "loss": 0.3541,
      "step": 2850
    },
    {
      "epoch": 0.3397078037771707,
      "grad_norm": 2.6942453384399414,
      "learning_rate": 4.5233671284889124e-05,
      "loss": 0.3914,
      "step": 2860
    },
    {
      "epoch": 0.3408955933008671,
      "grad_norm": 13.700599670410156,
      "learning_rate": 4.521347497677425e-05,
      "loss": 0.2977,
      "step": 2870
    },
    {
      "epoch": 0.34208338282456346,
      "grad_norm": 11.469378471374512,
      "learning_rate": 4.5193278668659375e-05,
      "loss": 0.3483,
      "step": 2880
    },
    {
      "epoch": 0.3432711723482599,
      "grad_norm": 17.048847198486328,
      "learning_rate": 4.5173082360544494e-05,
      "loss": 0.3547,
      "step": 2890
    },
    {
      "epoch": 0.3444589618719563,
      "grad_norm": 12.716607093811035,
      "learning_rate": 4.515288605242962e-05,
      "loss": 0.3063,
      "step": 2900
    },
    {
      "epoch": 0.3456467513956527,
      "grad_norm": 4.693846702575684,
      "learning_rate": 4.5132689744314745e-05,
      "loss": 0.4137,
      "step": 2910
    },
    {
      "epoch": 0.34683454091934907,
      "grad_norm": 6.413184642791748,
      "learning_rate": 4.511249343619986e-05,
      "loss": 0.3467,
      "step": 2920
    },
    {
      "epoch": 0.3480223304430455,
      "grad_norm": 12.552629470825195,
      "learning_rate": 4.509229712808499e-05,
      "loss": 0.4323,
      "step": 2930
    },
    {
      "epoch": 0.3492101199667419,
      "grad_norm": 12.508402824401855,
      "learning_rate": 4.507210081997011e-05,
      "loss": 0.3145,
      "step": 2940
    },
    {
      "epoch": 0.3503979094904383,
      "grad_norm": 11.820070266723633,
      "learning_rate": 4.505190451185524e-05,
      "loss": 0.6181,
      "step": 2950
    },
    {
      "epoch": 0.3515856990141347,
      "grad_norm": 3.2258009910583496,
      "learning_rate": 4.503170820374036e-05,
      "loss": 0.292,
      "step": 2960
    },
    {
      "epoch": 0.3527734885378311,
      "grad_norm": 7.677980899810791,
      "learning_rate": 4.501151189562548e-05,
      "loss": 0.4825,
      "step": 2970
    },
    {
      "epoch": 0.3539612780615275,
      "grad_norm": 8.544417381286621,
      "learning_rate": 4.499131558751061e-05,
      "loss": 0.416,
      "step": 2980
    },
    {
      "epoch": 0.3551490675852239,
      "grad_norm": 14.969865798950195,
      "learning_rate": 4.497111927939573e-05,
      "loss": 0.3516,
      "step": 2990
    },
    {
      "epoch": 0.3563368571089203,
      "grad_norm": 3.8635447025299072,
      "learning_rate": 4.495092297128085e-05,
      "loss": 0.4023,
      "step": 3000
    },
    {
      "epoch": 0.3575246466326167,
      "grad_norm": 13.661275863647461,
      "learning_rate": 4.493072666316597e-05,
      "loss": 0.4602,
      "step": 3010
    },
    {
      "epoch": 0.3587124361563131,
      "grad_norm": 22.266080856323242,
      "learning_rate": 4.49105303550511e-05,
      "loss": 0.42,
      "step": 3020
    },
    {
      "epoch": 0.3599002256800095,
      "grad_norm": 11.463329315185547,
      "learning_rate": 4.489033404693622e-05,
      "loss": 0.2854,
      "step": 3030
    },
    {
      "epoch": 0.3610880152037059,
      "grad_norm": 6.0218048095703125,
      "learning_rate": 4.487013773882134e-05,
      "loss": 0.4267,
      "step": 3040
    },
    {
      "epoch": 0.3622758047274023,
      "grad_norm": 15.213096618652344,
      "learning_rate": 4.484994143070647e-05,
      "loss": 0.4615,
      "step": 3050
    },
    {
      "epoch": 0.3634635942510987,
      "grad_norm": 5.439938068389893,
      "learning_rate": 4.482974512259159e-05,
      "loss": 0.4258,
      "step": 3060
    },
    {
      "epoch": 0.3646513837747951,
      "grad_norm": 10.035447120666504,
      "learning_rate": 4.480954881447672e-05,
      "loss": 0.2348,
      "step": 3070
    },
    {
      "epoch": 0.3658391732984915,
      "grad_norm": 14.916609764099121,
      "learning_rate": 4.4789352506361836e-05,
      "loss": 0.4859,
      "step": 3080
    },
    {
      "epoch": 0.3670269628221879,
      "grad_norm": 23.3326416015625,
      "learning_rate": 4.476915619824696e-05,
      "loss": 0.4125,
      "step": 3090
    },
    {
      "epoch": 0.3682147523458843,
      "grad_norm": 1.0474132299423218,
      "learning_rate": 4.474895989013209e-05,
      "loss": 0.3933,
      "step": 3100
    },
    {
      "epoch": 0.3694025418695807,
      "grad_norm": 18.18515968322754,
      "learning_rate": 4.4728763582017205e-05,
      "loss": 0.2747,
      "step": 3110
    },
    {
      "epoch": 0.37059033139327713,
      "grad_norm": 6.331620216369629,
      "learning_rate": 4.470856727390234e-05,
      "loss": 0.308,
      "step": 3120
    },
    {
      "epoch": 0.3717781209169735,
      "grad_norm": 3.965709924697876,
      "learning_rate": 4.4688370965787456e-05,
      "loss": 0.3144,
      "step": 3130
    },
    {
      "epoch": 0.3729659104406699,
      "grad_norm": 9.964198112487793,
      "learning_rate": 4.466817465767258e-05,
      "loss": 0.2545,
      "step": 3140
    },
    {
      "epoch": 0.3741536999643663,
      "grad_norm": 7.4843668937683105,
      "learning_rate": 4.46479783495577e-05,
      "loss": 0.3575,
      "step": 3150
    },
    {
      "epoch": 0.37534148948806273,
      "grad_norm": 29.760860443115234,
      "learning_rate": 4.4627782041442826e-05,
      "loss": 0.2024,
      "step": 3160
    },
    {
      "epoch": 0.37652927901175914,
      "grad_norm": 26.95182991027832,
      "learning_rate": 4.460758573332795e-05,
      "loss": 0.4099,
      "step": 3170
    },
    {
      "epoch": 0.3777170685354555,
      "grad_norm": 8.9773588180542,
      "learning_rate": 4.458738942521307e-05,
      "loss": 0.4688,
      "step": 3180
    },
    {
      "epoch": 0.3789048580591519,
      "grad_norm": 7.424287796020508,
      "learning_rate": 4.45671931170982e-05,
      "loss": 0.3094,
      "step": 3190
    },
    {
      "epoch": 0.38009264758284833,
      "grad_norm": 4.381921291351318,
      "learning_rate": 4.454699680898332e-05,
      "loss": 0.3774,
      "step": 3200
    },
    {
      "epoch": 0.38128043710654475,
      "grad_norm": 25.510421752929688,
      "learning_rate": 4.4526800500868446e-05,
      "loss": 0.476,
      "step": 3210
    },
    {
      "epoch": 0.3824682266302411,
      "grad_norm": 17.589637756347656,
      "learning_rate": 4.4506604192753565e-05,
      "loss": 0.5483,
      "step": 3220
    },
    {
      "epoch": 0.3836560161539375,
      "grad_norm": 18.96725845336914,
      "learning_rate": 4.448640788463869e-05,
      "loss": 0.299,
      "step": 3230
    },
    {
      "epoch": 0.38484380567763393,
      "grad_norm": 19.48969078063965,
      "learning_rate": 4.4466211576523815e-05,
      "loss": 0.4174,
      "step": 3240
    },
    {
      "epoch": 0.38603159520133035,
      "grad_norm": 31.013425827026367,
      "learning_rate": 4.4446015268408934e-05,
      "loss": 0.4148,
      "step": 3250
    },
    {
      "epoch": 0.3872193847250267,
      "grad_norm": 12.710129737854004,
      "learning_rate": 4.442581896029406e-05,
      "loss": 0.4204,
      "step": 3260
    },
    {
      "epoch": 0.3884071742487231,
      "grad_norm": 10.037944793701172,
      "learning_rate": 4.4405622652179185e-05,
      "loss": 0.4746,
      "step": 3270
    },
    {
      "epoch": 0.38959496377241953,
      "grad_norm": 9.258882522583008,
      "learning_rate": 4.438542634406431e-05,
      "loss": 0.5033,
      "step": 3280
    },
    {
      "epoch": 0.39078275329611595,
      "grad_norm": 20.173011779785156,
      "learning_rate": 4.436523003594943e-05,
      "loss": 0.4631,
      "step": 3290
    },
    {
      "epoch": 0.3919705428198123,
      "grad_norm": 10.452534675598145,
      "learning_rate": 4.4345033727834554e-05,
      "loss": 0.395,
      "step": 3300
    },
    {
      "epoch": 0.3931583323435087,
      "grad_norm": 15.678132057189941,
      "learning_rate": 4.432483741971968e-05,
      "loss": 0.3774,
      "step": 3310
    },
    {
      "epoch": 0.39434612186720513,
      "grad_norm": 6.001423358917236,
      "learning_rate": 4.43046411116048e-05,
      "loss": 0.4218,
      "step": 3320
    },
    {
      "epoch": 0.39553391139090155,
      "grad_norm": 3.1600759029388428,
      "learning_rate": 4.4284444803489924e-05,
      "loss": 0.267,
      "step": 3330
    },
    {
      "epoch": 0.3967217009145979,
      "grad_norm": 15.701601028442383,
      "learning_rate": 4.426424849537505e-05,
      "loss": 0.4171,
      "step": 3340
    },
    {
      "epoch": 0.3979094904382943,
      "grad_norm": 14.965439796447754,
      "learning_rate": 4.424405218726017e-05,
      "loss": 0.51,
      "step": 3350
    },
    {
      "epoch": 0.39909727996199074,
      "grad_norm": 9.799454689025879,
      "learning_rate": 4.422385587914529e-05,
      "loss": 0.5128,
      "step": 3360
    },
    {
      "epoch": 0.40028506948568715,
      "grad_norm": 11.53872013092041,
      "learning_rate": 4.420365957103042e-05,
      "loss": 0.4137,
      "step": 3370
    },
    {
      "epoch": 0.40147285900938356,
      "grad_norm": 24.697078704833984,
      "learning_rate": 4.4183463262915544e-05,
      "loss": 0.3897,
      "step": 3380
    },
    {
      "epoch": 0.4026606485330799,
      "grad_norm": 2.031918525695801,
      "learning_rate": 4.416326695480066e-05,
      "loss": 0.3018,
      "step": 3390
    },
    {
      "epoch": 0.40384843805677634,
      "grad_norm": 12.18288516998291,
      "learning_rate": 4.414307064668579e-05,
      "loss": 0.3534,
      "step": 3400
    },
    {
      "epoch": 0.40503622758047275,
      "grad_norm": 10.754319190979004,
      "learning_rate": 4.4122874338570913e-05,
      "loss": 0.3373,
      "step": 3410
    },
    {
      "epoch": 0.40622401710416917,
      "grad_norm": 15.510159492492676,
      "learning_rate": 4.410267803045603e-05,
      "loss": 0.2861,
      "step": 3420
    },
    {
      "epoch": 0.4074118066278655,
      "grad_norm": 5.158355712890625,
      "learning_rate": 4.408248172234116e-05,
      "loss": 0.2839,
      "step": 3430
    },
    {
      "epoch": 0.40859959615156194,
      "grad_norm": 5.095500469207764,
      "learning_rate": 4.406228541422628e-05,
      "loss": 0.4358,
      "step": 3440
    },
    {
      "epoch": 0.40978738567525835,
      "grad_norm": 15.187273025512695,
      "learning_rate": 4.404208910611141e-05,
      "loss": 0.637,
      "step": 3450
    },
    {
      "epoch": 0.41097517519895477,
      "grad_norm": 3.205122947692871,
      "learning_rate": 4.402189279799653e-05,
      "loss": 0.2753,
      "step": 3460
    },
    {
      "epoch": 0.4121629647226511,
      "grad_norm": 14.393389701843262,
      "learning_rate": 4.400169648988165e-05,
      "loss": 0.3418,
      "step": 3470
    },
    {
      "epoch": 0.41335075424634754,
      "grad_norm": 25.65963363647461,
      "learning_rate": 4.398150018176678e-05,
      "loss": 0.4401,
      "step": 3480
    },
    {
      "epoch": 0.41453854377004395,
      "grad_norm": 16.838680267333984,
      "learning_rate": 4.3961303873651896e-05,
      "loss": 0.5664,
      "step": 3490
    },
    {
      "epoch": 0.41572633329374037,
      "grad_norm": 15.010178565979004,
      "learning_rate": 4.394110756553702e-05,
      "loss": 0.3574,
      "step": 3500
    },
    {
      "epoch": 0.4169141228174367,
      "grad_norm": 6.812884330749512,
      "learning_rate": 4.392091125742214e-05,
      "loss": 0.2718,
      "step": 3510
    },
    {
      "epoch": 0.41810191234113314,
      "grad_norm": 9.333667755126953,
      "learning_rate": 4.390071494930727e-05,
      "loss": 0.408,
      "step": 3520
    },
    {
      "epoch": 0.41928970186482956,
      "grad_norm": 15.54117488861084,
      "learning_rate": 4.388051864119239e-05,
      "loss": 0.4535,
      "step": 3530
    },
    {
      "epoch": 0.42047749138852597,
      "grad_norm": 17.10935401916504,
      "learning_rate": 4.386032233307752e-05,
      "loss": 0.3454,
      "step": 3540
    },
    {
      "epoch": 0.42166528091222233,
      "grad_norm": 12.55117130279541,
      "learning_rate": 4.384012602496264e-05,
      "loss": 0.2627,
      "step": 3550
    },
    {
      "epoch": 0.42285307043591874,
      "grad_norm": 14.86527156829834,
      "learning_rate": 4.381992971684776e-05,
      "loss": 0.4194,
      "step": 3560
    },
    {
      "epoch": 0.42404085995961516,
      "grad_norm": 20.373779296875,
      "learning_rate": 4.3799733408732886e-05,
      "loss": 0.4185,
      "step": 3570
    },
    {
      "epoch": 0.42522864948331157,
      "grad_norm": 6.7415690422058105,
      "learning_rate": 4.3779537100618005e-05,
      "loss": 0.3785,
      "step": 3580
    },
    {
      "epoch": 0.426416439007008,
      "grad_norm": 26.398717880249023,
      "learning_rate": 4.375934079250314e-05,
      "loss": 0.3156,
      "step": 3590
    },
    {
      "epoch": 0.42760422853070434,
      "grad_norm": 20.97412109375,
      "learning_rate": 4.3739144484388256e-05,
      "loss": 0.4025,
      "step": 3600
    },
    {
      "epoch": 0.42879201805440076,
      "grad_norm": 12.382195472717285,
      "learning_rate": 4.371894817627338e-05,
      "loss": 0.4884,
      "step": 3610
    },
    {
      "epoch": 0.4299798075780972,
      "grad_norm": 11.388267517089844,
      "learning_rate": 4.3698751868158506e-05,
      "loss": 0.3592,
      "step": 3620
    },
    {
      "epoch": 0.4311675971017936,
      "grad_norm": 15.474785804748535,
      "learning_rate": 4.3678555560043625e-05,
      "loss": 0.311,
      "step": 3630
    },
    {
      "epoch": 0.43235538662548995,
      "grad_norm": 2.701507091522217,
      "learning_rate": 4.365835925192875e-05,
      "loss": 0.2764,
      "step": 3640
    },
    {
      "epoch": 0.43354317614918636,
      "grad_norm": 24.826433181762695,
      "learning_rate": 4.363816294381387e-05,
      "loss": 0.4323,
      "step": 3650
    },
    {
      "epoch": 0.4347309656728828,
      "grad_norm": 19.545717239379883,
      "learning_rate": 4.3617966635699e-05,
      "loss": 0.4339,
      "step": 3660
    },
    {
      "epoch": 0.4359187551965792,
      "grad_norm": 12.077818870544434,
      "learning_rate": 4.359777032758412e-05,
      "loss": 0.3767,
      "step": 3670
    },
    {
      "epoch": 0.43710654472027555,
      "grad_norm": 12.40162181854248,
      "learning_rate": 4.357757401946924e-05,
      "loss": 0.3163,
      "step": 3680
    },
    {
      "epoch": 0.43829433424397196,
      "grad_norm": 18.187673568725586,
      "learning_rate": 4.355737771135437e-05,
      "loss": 0.2156,
      "step": 3690
    },
    {
      "epoch": 0.4394821237676684,
      "grad_norm": 20.061111450195312,
      "learning_rate": 4.353718140323949e-05,
      "loss": 0.4384,
      "step": 3700
    },
    {
      "epoch": 0.4406699132913648,
      "grad_norm": 4.047170162200928,
      "learning_rate": 4.3516985095124615e-05,
      "loss": 0.3721,
      "step": 3710
    },
    {
      "epoch": 0.44185770281506115,
      "grad_norm": 5.222775459289551,
      "learning_rate": 4.349678878700973e-05,
      "loss": 0.3858,
      "step": 3720
    },
    {
      "epoch": 0.44304549233875756,
      "grad_norm": 10.884535789489746,
      "learning_rate": 4.347659247889486e-05,
      "loss": 0.3702,
      "step": 3730
    },
    {
      "epoch": 0.444233281862454,
      "grad_norm": 16.281879425048828,
      "learning_rate": 4.3456396170779984e-05,
      "loss": 0.4362,
      "step": 3740
    },
    {
      "epoch": 0.4454210713861504,
      "grad_norm": 2.4041261672973633,
      "learning_rate": 4.34361998626651e-05,
      "loss": 0.2976,
      "step": 3750
    },
    {
      "epoch": 0.44660886090984675,
      "grad_norm": 6.777461528778076,
      "learning_rate": 4.3416003554550235e-05,
      "loss": 0.3414,
      "step": 3760
    },
    {
      "epoch": 0.44779665043354316,
      "grad_norm": 7.669863700866699,
      "learning_rate": 4.3395807246435354e-05,
      "loss": 0.3954,
      "step": 3770
    },
    {
      "epoch": 0.4489844399572396,
      "grad_norm": 8.656243324279785,
      "learning_rate": 4.337561093832048e-05,
      "loss": 0.4409,
      "step": 3780
    },
    {
      "epoch": 0.450172229480936,
      "grad_norm": 10.858545303344727,
      "learning_rate": 4.33554146302056e-05,
      "loss": 0.4721,
      "step": 3790
    },
    {
      "epoch": 0.4513600190046324,
      "grad_norm": 1.6581653356552124,
      "learning_rate": 4.333521832209072e-05,
      "loss": 0.4162,
      "step": 3800
    },
    {
      "epoch": 0.45254780852832877,
      "grad_norm": 1.1774976253509521,
      "learning_rate": 4.331502201397585e-05,
      "loss": 0.3506,
      "step": 3810
    },
    {
      "epoch": 0.4537355980520252,
      "grad_norm": 4.5789103507995605,
      "learning_rate": 4.329482570586097e-05,
      "loss": 0.3356,
      "step": 3820
    },
    {
      "epoch": 0.4549233875757216,
      "grad_norm": 7.276851654052734,
      "learning_rate": 4.327462939774609e-05,
      "loss": 0.3483,
      "step": 3830
    },
    {
      "epoch": 0.456111177099418,
      "grad_norm": 3.2167487144470215,
      "learning_rate": 4.325443308963122e-05,
      "loss": 0.2807,
      "step": 3840
    },
    {
      "epoch": 0.45729896662311437,
      "grad_norm": 13.19559097290039,
      "learning_rate": 4.323423678151634e-05,
      "loss": 0.3456,
      "step": 3850
    },
    {
      "epoch": 0.4584867561468108,
      "grad_norm": 25.430503845214844,
      "learning_rate": 4.321404047340146e-05,
      "loss": 0.2899,
      "step": 3860
    },
    {
      "epoch": 0.4596745456705072,
      "grad_norm": 10.575112342834473,
      "learning_rate": 4.319384416528659e-05,
      "loss": 0.3278,
      "step": 3870
    },
    {
      "epoch": 0.4608623351942036,
      "grad_norm": 7.5166802406311035,
      "learning_rate": 4.317364785717171e-05,
      "loss": 0.3293,
      "step": 3880
    },
    {
      "epoch": 0.46205012471789997,
      "grad_norm": 24.12334442138672,
      "learning_rate": 4.315345154905683e-05,
      "loss": 0.5226,
      "step": 3890
    },
    {
      "epoch": 0.4632379142415964,
      "grad_norm": 3.545163869857788,
      "learning_rate": 4.313325524094196e-05,
      "loss": 0.3248,
      "step": 3900
    },
    {
      "epoch": 0.4644257037652928,
      "grad_norm": 33.887996673583984,
      "learning_rate": 4.311305893282708e-05,
      "loss": 0.3371,
      "step": 3910
    },
    {
      "epoch": 0.4656134932889892,
      "grad_norm": 12.632829666137695,
      "learning_rate": 4.309286262471221e-05,
      "loss": 0.369,
      "step": 3920
    },
    {
      "epoch": 0.46680128281268557,
      "grad_norm": 16.778484344482422,
      "learning_rate": 4.3072666316597326e-05,
      "loss": 0.3016,
      "step": 3930
    },
    {
      "epoch": 0.467989072336382,
      "grad_norm": 3.4431657791137695,
      "learning_rate": 4.305247000848245e-05,
      "loss": 0.2662,
      "step": 3940
    },
    {
      "epoch": 0.4691768618600784,
      "grad_norm": 16.091875076293945,
      "learning_rate": 4.303227370036758e-05,
      "loss": 0.2483,
      "step": 3950
    },
    {
      "epoch": 0.4703646513837748,
      "grad_norm": 6.015840530395508,
      "learning_rate": 4.3012077392252696e-05,
      "loss": 0.3688,
      "step": 3960
    },
    {
      "epoch": 0.47155244090747117,
      "grad_norm": 6.25945520401001,
      "learning_rate": 4.299188108413782e-05,
      "loss": 0.3638,
      "step": 3970
    },
    {
      "epoch": 0.4727402304311676,
      "grad_norm": 17.756319046020508,
      "learning_rate": 4.2971684776022947e-05,
      "loss": 0.4301,
      "step": 3980
    },
    {
      "epoch": 0.473928019954864,
      "grad_norm": 5.478827953338623,
      "learning_rate": 4.295148846790807e-05,
      "loss": 0.4089,
      "step": 3990
    },
    {
      "epoch": 0.4751158094785604,
      "grad_norm": 19.53929328918457,
      "learning_rate": 4.293129215979319e-05,
      "loss": 0.393,
      "step": 4000
    },
    {
      "epoch": 0.47630359900225683,
      "grad_norm": 13.203557968139648,
      "learning_rate": 4.2911095851678316e-05,
      "loss": 0.3288,
      "step": 4010
    },
    {
      "epoch": 0.4774913885259532,
      "grad_norm": 5.282154560089111,
      "learning_rate": 4.289089954356344e-05,
      "loss": 0.4575,
      "step": 4020
    },
    {
      "epoch": 0.4786791780496496,
      "grad_norm": 12.252219200134277,
      "learning_rate": 4.287070323544856e-05,
      "loss": 0.4281,
      "step": 4030
    },
    {
      "epoch": 0.479866967573346,
      "grad_norm": 14.5150146484375,
      "learning_rate": 4.2850506927333685e-05,
      "loss": 0.5185,
      "step": 4040
    },
    {
      "epoch": 0.48105475709704243,
      "grad_norm": 10.081263542175293,
      "learning_rate": 4.283031061921881e-05,
      "loss": 0.407,
      "step": 4050
    },
    {
      "epoch": 0.4822425466207388,
      "grad_norm": 15.112545013427734,
      "learning_rate": 4.281011431110393e-05,
      "loss": 0.3318,
      "step": 4060
    },
    {
      "epoch": 0.4834303361444352,
      "grad_norm": 7.3304667472839355,
      "learning_rate": 4.2789918002989055e-05,
      "loss": 0.3058,
      "step": 4070
    },
    {
      "epoch": 0.4846181256681316,
      "grad_norm": 25.76348876953125,
      "learning_rate": 4.2769721694874174e-05,
      "loss": 0.4159,
      "step": 4080
    },
    {
      "epoch": 0.48580591519182803,
      "grad_norm": 5.652888298034668,
      "learning_rate": 4.2749525386759306e-05,
      "loss": 0.5092,
      "step": 4090
    },
    {
      "epoch": 0.4869937047155244,
      "grad_norm": 15.139281272888184,
      "learning_rate": 4.2729329078644424e-05,
      "loss": 0.2226,
      "step": 4100
    },
    {
      "epoch": 0.4881814942392208,
      "grad_norm": 14.606767654418945,
      "learning_rate": 4.270913277052955e-05,
      "loss": 0.3034,
      "step": 4110
    },
    {
      "epoch": 0.4893692837629172,
      "grad_norm": 18.662830352783203,
      "learning_rate": 4.2688936462414675e-05,
      "loss": 0.3917,
      "step": 4120
    },
    {
      "epoch": 0.49055707328661363,
      "grad_norm": 16.383275985717773,
      "learning_rate": 4.2668740154299794e-05,
      "loss": 0.2646,
      "step": 4130
    },
    {
      "epoch": 0.49174486281031,
      "grad_norm": 1.6056936979293823,
      "learning_rate": 4.264854384618492e-05,
      "loss": 0.2865,
      "step": 4140
    },
    {
      "epoch": 0.4929326523340064,
      "grad_norm": 1.3440567255020142,
      "learning_rate": 4.262834753807004e-05,
      "loss": 0.3501,
      "step": 4150
    },
    {
      "epoch": 0.4941204418577028,
      "grad_norm": 7.550059795379639,
      "learning_rate": 4.260815122995517e-05,
      "loss": 0.304,
      "step": 4160
    },
    {
      "epoch": 0.49530823138139923,
      "grad_norm": 16.884960174560547,
      "learning_rate": 4.258795492184029e-05,
      "loss": 0.403,
      "step": 4170
    },
    {
      "epoch": 0.4964960209050956,
      "grad_norm": 11.404025077819824,
      "learning_rate": 4.2567758613725414e-05,
      "loss": 0.3168,
      "step": 4180
    },
    {
      "epoch": 0.497683810428792,
      "grad_norm": 8.391395568847656,
      "learning_rate": 4.254756230561054e-05,
      "loss": 0.5648,
      "step": 4190
    },
    {
      "epoch": 0.4988715999524884,
      "grad_norm": 6.171353816986084,
      "learning_rate": 4.252736599749566e-05,
      "loss": 0.3003,
      "step": 4200
    },
    {
      "epoch": 0.5000593894761848,
      "grad_norm": 35.38758087158203,
      "learning_rate": 4.2507169689380783e-05,
      "loss": 0.4199,
      "step": 4210
    },
    {
      "epoch": 0.5012471789998812,
      "grad_norm": 6.421270370483398,
      "learning_rate": 4.24869733812659e-05,
      "loss": 0.3901,
      "step": 4220
    },
    {
      "epoch": 0.5024349685235776,
      "grad_norm": 42.83706283569336,
      "learning_rate": 4.2466777073151034e-05,
      "loss": 0.2966,
      "step": 4230
    },
    {
      "epoch": 0.5036227580472741,
      "grad_norm": 38.558387756347656,
      "learning_rate": 4.244658076503615e-05,
      "loss": 0.292,
      "step": 4240
    },
    {
      "epoch": 0.5048105475709704,
      "grad_norm": 8.126205444335938,
      "learning_rate": 4.242638445692128e-05,
      "loss": 0.2822,
      "step": 4250
    },
    {
      "epoch": 0.5059983370946668,
      "grad_norm": 27.130029678344727,
      "learning_rate": 4.2406188148806404e-05,
      "loss": 0.327,
      "step": 4260
    },
    {
      "epoch": 0.5071861266183633,
      "grad_norm": 12.569177627563477,
      "learning_rate": 4.238599184069152e-05,
      "loss": 0.3209,
      "step": 4270
    },
    {
      "epoch": 0.5083739161420596,
      "grad_norm": 11.360605239868164,
      "learning_rate": 4.236579553257665e-05,
      "loss": 0.2969,
      "step": 4280
    },
    {
      "epoch": 0.509561705665756,
      "grad_norm": 26.788969039916992,
      "learning_rate": 4.2345599224461766e-05,
      "loss": 0.4165,
      "step": 4290
    },
    {
      "epoch": 0.5107494951894525,
      "grad_norm": 7.342958450317383,
      "learning_rate": 4.23254029163469e-05,
      "loss": 0.2945,
      "step": 4300
    },
    {
      "epoch": 0.5119372847131488,
      "grad_norm": 9.749953269958496,
      "learning_rate": 4.230520660823202e-05,
      "loss": 0.2583,
      "step": 4310
    },
    {
      "epoch": 0.5131250742368453,
      "grad_norm": 3.2481203079223633,
      "learning_rate": 4.228501030011714e-05,
      "loss": 0.3701,
      "step": 4320
    },
    {
      "epoch": 0.5143128637605416,
      "grad_norm": 14.451545715332031,
      "learning_rate": 4.226481399200227e-05,
      "loss": 0.5204,
      "step": 4330
    },
    {
      "epoch": 0.515500653284238,
      "grad_norm": 11.529878616333008,
      "learning_rate": 4.224461768388739e-05,
      "loss": 0.3277,
      "step": 4340
    },
    {
      "epoch": 0.5166884428079345,
      "grad_norm": 8.264071464538574,
      "learning_rate": 4.222442137577251e-05,
      "loss": 0.5282,
      "step": 4350
    },
    {
      "epoch": 0.5178762323316308,
      "grad_norm": 10.22516918182373,
      "learning_rate": 4.220422506765763e-05,
      "loss": 0.2783,
      "step": 4360
    },
    {
      "epoch": 0.5190640218553272,
      "grad_norm": 9.560822486877441,
      "learning_rate": 4.218402875954276e-05,
      "loss": 0.3694,
      "step": 4370
    },
    {
      "epoch": 0.5202518113790237,
      "grad_norm": 10.685698509216309,
      "learning_rate": 4.216383245142788e-05,
      "loss": 0.4895,
      "step": 4380
    },
    {
      "epoch": 0.52143960090272,
      "grad_norm": 23.41321563720703,
      "learning_rate": 4.2143636143313e-05,
      "loss": 0.3322,
      "step": 4390
    },
    {
      "epoch": 0.5226273904264165,
      "grad_norm": 3.8715100288391113,
      "learning_rate": 4.2123439835198126e-05,
      "loss": 0.4491,
      "step": 4400
    },
    {
      "epoch": 0.5238151799501128,
      "grad_norm": 14.751133918762207,
      "learning_rate": 4.210324352708325e-05,
      "loss": 0.4755,
      "step": 4410
    },
    {
      "epoch": 0.5250029694738092,
      "grad_norm": 16.98276138305664,
      "learning_rate": 4.2083047218968376e-05,
      "loss": 0.3625,
      "step": 4420
    },
    {
      "epoch": 0.5261907589975057,
      "grad_norm": 14.82901668548584,
      "learning_rate": 4.2062850910853495e-05,
      "loss": 0.329,
      "step": 4430
    },
    {
      "epoch": 0.527378548521202,
      "grad_norm": 8.991979598999023,
      "learning_rate": 4.204265460273862e-05,
      "loss": 0.2931,
      "step": 4440
    },
    {
      "epoch": 0.5285663380448985,
      "grad_norm": 6.595966339111328,
      "learning_rate": 4.2022458294623746e-05,
      "loss": 0.4016,
      "step": 4450
    },
    {
      "epoch": 0.5297541275685949,
      "grad_norm": 5.0067362785339355,
      "learning_rate": 4.2002261986508864e-05,
      "loss": 0.316,
      "step": 4460
    },
    {
      "epoch": 0.5309419170922912,
      "grad_norm": 11.206424713134766,
      "learning_rate": 4.198206567839399e-05,
      "loss": 0.1979,
      "step": 4470
    },
    {
      "epoch": 0.5321297066159877,
      "grad_norm": 6.949865818023682,
      "learning_rate": 4.1961869370279115e-05,
      "loss": 0.3681,
      "step": 4480
    },
    {
      "epoch": 0.533317496139684,
      "grad_norm": 2.2048873901367188,
      "learning_rate": 4.194167306216424e-05,
      "loss": 0.2838,
      "step": 4490
    },
    {
      "epoch": 0.5345052856633804,
      "grad_norm": 22.84633445739746,
      "learning_rate": 4.192147675404936e-05,
      "loss": 0.3598,
      "step": 4500
    },
    {
      "epoch": 0.5356930751870769,
      "grad_norm": 7.66761589050293,
      "learning_rate": 4.1901280445934485e-05,
      "loss": 0.3811,
      "step": 4510
    },
    {
      "epoch": 0.5368808647107732,
      "grad_norm": 5.503271579742432,
      "learning_rate": 4.188108413781961e-05,
      "loss": 0.3407,
      "step": 4520
    },
    {
      "epoch": 0.5380686542344697,
      "grad_norm": 11.162603378295898,
      "learning_rate": 4.186088782970473e-05,
      "loss": 0.2848,
      "step": 4530
    },
    {
      "epoch": 0.5392564437581661,
      "grad_norm": 9.206007957458496,
      "learning_rate": 4.1840691521589854e-05,
      "loss": 0.4457,
      "step": 4540
    },
    {
      "epoch": 0.5404442332818624,
      "grad_norm": 14.177682876586914,
      "learning_rate": 4.182049521347498e-05,
      "loss": 0.4475,
      "step": 4550
    },
    {
      "epoch": 0.5416320228055589,
      "grad_norm": 8.909317016601562,
      "learning_rate": 4.1800298905360105e-05,
      "loss": 0.4227,
      "step": 4560
    },
    {
      "epoch": 0.5428198123292552,
      "grad_norm": 12.618672370910645,
      "learning_rate": 4.1780102597245224e-05,
      "loss": 0.4074,
      "step": 4570
    },
    {
      "epoch": 0.5440076018529516,
      "grad_norm": 23.072168350219727,
      "learning_rate": 4.175990628913035e-05,
      "loss": 0.2979,
      "step": 4580
    },
    {
      "epoch": 0.5451953913766481,
      "grad_norm": 12.14932632446289,
      "learning_rate": 4.1739709981015474e-05,
      "loss": 0.3644,
      "step": 4590
    },
    {
      "epoch": 0.5463831809003444,
      "grad_norm": 17.566165924072266,
      "learning_rate": 4.171951367290059e-05,
      "loss": 0.2623,
      "step": 4600
    },
    {
      "epoch": 0.5475709704240409,
      "grad_norm": 1.3808825016021729,
      "learning_rate": 4.169931736478572e-05,
      "loss": 0.3746,
      "step": 4610
    },
    {
      "epoch": 0.5487587599477373,
      "grad_norm": 18.398242950439453,
      "learning_rate": 4.1679121056670844e-05,
      "loss": 0.3531,
      "step": 4620
    },
    {
      "epoch": 0.5499465494714336,
      "grad_norm": 25.340429306030273,
      "learning_rate": 4.165892474855597e-05,
      "loss": 0.4236,
      "step": 4630
    },
    {
      "epoch": 0.5511343389951301,
      "grad_norm": 0.6738950610160828,
      "learning_rate": 4.163872844044109e-05,
      "loss": 0.4221,
      "step": 4640
    },
    {
      "epoch": 0.5523221285188264,
      "grad_norm": 7.160059928894043,
      "learning_rate": 4.161853213232621e-05,
      "loss": 0.2837,
      "step": 4650
    },
    {
      "epoch": 0.5535099180425229,
      "grad_norm": 15.010000228881836,
      "learning_rate": 4.159833582421134e-05,
      "loss": 0.5477,
      "step": 4660
    },
    {
      "epoch": 0.5546977075662193,
      "grad_norm": 0.6289362907409668,
      "learning_rate": 4.157813951609646e-05,
      "loss": 0.2282,
      "step": 4670
    },
    {
      "epoch": 0.5558854970899156,
      "grad_norm": 0.4383513033390045,
      "learning_rate": 4.155794320798158e-05,
      "loss": 0.292,
      "step": 4680
    },
    {
      "epoch": 0.5570732866136121,
      "grad_norm": 2.9803483486175537,
      "learning_rate": 4.153774689986671e-05,
      "loss": 0.4715,
      "step": 4690
    },
    {
      "epoch": 0.5582610761373085,
      "grad_norm": 0.9251212477684021,
      "learning_rate": 4.1517550591751834e-05,
      "loss": 0.4181,
      "step": 4700
    },
    {
      "epoch": 0.5594488656610048,
      "grad_norm": 20.361446380615234,
      "learning_rate": 4.149735428363695e-05,
      "loss": 0.2521,
      "step": 4710
    },
    {
      "epoch": 0.5606366551847013,
      "grad_norm": 30.756389617919922,
      "learning_rate": 4.147715797552207e-05,
      "loss": 0.2042,
      "step": 4720
    },
    {
      "epoch": 0.5618244447083977,
      "grad_norm": 2.120246171951294,
      "learning_rate": 4.14569616674072e-05,
      "loss": 0.2842,
      "step": 4730
    },
    {
      "epoch": 0.5630122342320941,
      "grad_norm": 17.519840240478516,
      "learning_rate": 4.143676535929232e-05,
      "loss": 0.3074,
      "step": 4740
    },
    {
      "epoch": 0.5642000237557905,
      "grad_norm": 21.370149612426758,
      "learning_rate": 4.141656905117745e-05,
      "loss": 0.3542,
      "step": 4750
    },
    {
      "epoch": 0.5653878132794868,
      "grad_norm": 3.2447586059570312,
      "learning_rate": 4.139637274306257e-05,
      "loss": 0.2178,
      "step": 4760
    },
    {
      "epoch": 0.5665756028031833,
      "grad_norm": 12.521223068237305,
      "learning_rate": 4.137617643494769e-05,
      "loss": 0.4924,
      "step": 4770
    },
    {
      "epoch": 0.5677633923268797,
      "grad_norm": 28.59462547302246,
      "learning_rate": 4.1355980126832817e-05,
      "loss": 0.3977,
      "step": 4780
    },
    {
      "epoch": 0.568951181850576,
      "grad_norm": 4.111462116241455,
      "learning_rate": 4.1335783818717935e-05,
      "loss": 0.2946,
      "step": 4790
    },
    {
      "epoch": 0.5701389713742725,
      "grad_norm": 6.394406318664551,
      "learning_rate": 4.131558751060307e-05,
      "loss": 0.3265,
      "step": 4800
    },
    {
      "epoch": 0.5713267608979689,
      "grad_norm": 9.290630340576172,
      "learning_rate": 4.1295391202488186e-05,
      "loss": 0.2808,
      "step": 4810
    },
    {
      "epoch": 0.5725145504216653,
      "grad_norm": 0.5132561922073364,
      "learning_rate": 4.127519489437331e-05,
      "loss": 0.2636,
      "step": 4820
    },
    {
      "epoch": 0.5737023399453617,
      "grad_norm": 28.448570251464844,
      "learning_rate": 4.125499858625844e-05,
      "loss": 0.478,
      "step": 4830
    },
    {
      "epoch": 0.574890129469058,
      "grad_norm": 10.142313003540039,
      "learning_rate": 4.1234802278143555e-05,
      "loss": 0.3154,
      "step": 4840
    },
    {
      "epoch": 0.5760779189927545,
      "grad_norm": 3.780914783477783,
      "learning_rate": 4.121460597002868e-05,
      "loss": 0.2937,
      "step": 4850
    },
    {
      "epoch": 0.5772657085164509,
      "grad_norm": 32.98847579956055,
      "learning_rate": 4.11944096619138e-05,
      "loss": 0.3705,
      "step": 4860
    },
    {
      "epoch": 0.5784534980401473,
      "grad_norm": 18.09287452697754,
      "learning_rate": 4.117421335379893e-05,
      "loss": 0.4201,
      "step": 4870
    },
    {
      "epoch": 0.5796412875638437,
      "grad_norm": 10.127817153930664,
      "learning_rate": 4.115401704568405e-05,
      "loss": 0.4986,
      "step": 4880
    },
    {
      "epoch": 0.5808290770875401,
      "grad_norm": 1.058944582939148,
      "learning_rate": 4.1133820737569176e-05,
      "loss": 0.3042,
      "step": 4890
    },
    {
      "epoch": 0.5820168666112365,
      "grad_norm": 9.856781959533691,
      "learning_rate": 4.11136244294543e-05,
      "loss": 0.4041,
      "step": 4900
    },
    {
      "epoch": 0.5832046561349329,
      "grad_norm": 20.809192657470703,
      "learning_rate": 4.109342812133942e-05,
      "loss": 0.5482,
      "step": 4910
    },
    {
      "epoch": 0.5843924456586292,
      "grad_norm": 14.965951919555664,
      "learning_rate": 4.1073231813224545e-05,
      "loss": 0.3414,
      "step": 4920
    },
    {
      "epoch": 0.5855802351823257,
      "grad_norm": 10.207925796508789,
      "learning_rate": 4.1053035505109664e-05,
      "loss": 0.3572,
      "step": 4930
    },
    {
      "epoch": 0.5867680247060221,
      "grad_norm": 1.533730149269104,
      "learning_rate": 4.1032839196994796e-05,
      "loss": 0.2824,
      "step": 4940
    },
    {
      "epoch": 0.5879558142297185,
      "grad_norm": 25.02785301208496,
      "learning_rate": 4.1012642888879915e-05,
      "loss": 0.3768,
      "step": 4950
    },
    {
      "epoch": 0.5891436037534149,
      "grad_norm": 1.5977927446365356,
      "learning_rate": 4.099244658076504e-05,
      "loss": 0.2679,
      "step": 4960
    },
    {
      "epoch": 0.5903313932771113,
      "grad_norm": 6.8561811447143555,
      "learning_rate": 4.097225027265016e-05,
      "loss": 0.4982,
      "step": 4970
    },
    {
      "epoch": 0.5915191828008077,
      "grad_norm": 11.816139221191406,
      "learning_rate": 4.0952053964535284e-05,
      "loss": 0.2594,
      "step": 4980
    },
    {
      "epoch": 0.5927069723245041,
      "grad_norm": 15.79808521270752,
      "learning_rate": 4.093185765642041e-05,
      "loss": 0.6148,
      "step": 4990
    },
    {
      "epoch": 0.5938947618482004,
      "grad_norm": 0.7099695205688477,
      "learning_rate": 4.091166134830553e-05,
      "loss": 0.1564,
      "step": 5000
    },
    {
      "epoch": 0.5950825513718969,
      "grad_norm": 5.865558624267578,
      "learning_rate": 4.089146504019066e-05,
      "loss": 0.284,
      "step": 5010
    },
    {
      "epoch": 0.5962703408955933,
      "grad_norm": 16.383129119873047,
      "learning_rate": 4.087126873207578e-05,
      "loss": 0.3517,
      "step": 5020
    },
    {
      "epoch": 0.5974581304192897,
      "grad_norm": 19.06987190246582,
      "learning_rate": 4.0851072423960904e-05,
      "loss": 0.3976,
      "step": 5030
    },
    {
      "epoch": 0.5986459199429861,
      "grad_norm": 3.1247103214263916,
      "learning_rate": 4.083087611584602e-05,
      "loss": 0.2637,
      "step": 5040
    },
    {
      "epoch": 0.5998337094666825,
      "grad_norm": 33.65044021606445,
      "learning_rate": 4.081067980773115e-05,
      "loss": 0.5594,
      "step": 5050
    },
    {
      "epoch": 0.6010214989903789,
      "grad_norm": 4.82309103012085,
      "learning_rate": 4.0790483499616274e-05,
      "loss": 0.3964,
      "step": 5060
    },
    {
      "epoch": 0.6022092885140753,
      "grad_norm": 2.6429734230041504,
      "learning_rate": 4.077028719150139e-05,
      "loss": 0.2564,
      "step": 5070
    },
    {
      "epoch": 0.6033970780377718,
      "grad_norm": 21.53282928466797,
      "learning_rate": 4.0750090883386525e-05,
      "loss": 0.4069,
      "step": 5080
    },
    {
      "epoch": 0.6045848675614681,
      "grad_norm": 2.4060773849487305,
      "learning_rate": 4.072989457527164e-05,
      "loss": 0.3356,
      "step": 5090
    },
    {
      "epoch": 0.6057726570851645,
      "grad_norm": 15.121102333068848,
      "learning_rate": 4.070969826715676e-05,
      "loss": 0.4639,
      "step": 5100
    },
    {
      "epoch": 0.606960446608861,
      "grad_norm": 17.70600700378418,
      "learning_rate": 4.068950195904189e-05,
      "loss": 0.603,
      "step": 5110
    },
    {
      "epoch": 0.6081482361325573,
      "grad_norm": 17.995315551757812,
      "learning_rate": 4.066930565092701e-05,
      "loss": 0.4431,
      "step": 5120
    },
    {
      "epoch": 0.6093360256562537,
      "grad_norm": 0.9544994235038757,
      "learning_rate": 4.064910934281214e-05,
      "loss": 0.2612,
      "step": 5130
    },
    {
      "epoch": 0.6105238151799501,
      "grad_norm": 31.66908836364746,
      "learning_rate": 4.062891303469726e-05,
      "loss": 0.3944,
      "step": 5140
    },
    {
      "epoch": 0.6117116047036465,
      "grad_norm": 14.636369705200195,
      "learning_rate": 4.060871672658238e-05,
      "loss": 0.5524,
      "step": 5150
    },
    {
      "epoch": 0.612899394227343,
      "grad_norm": 13.257322311401367,
      "learning_rate": 4.058852041846751e-05,
      "loss": 0.2722,
      "step": 5160
    },
    {
      "epoch": 0.6140871837510393,
      "grad_norm": 9.158632278442383,
      "learning_rate": 4.0568324110352626e-05,
      "loss": 0.4928,
      "step": 5170
    },
    {
      "epoch": 0.6152749732747357,
      "grad_norm": 7.2856645584106445,
      "learning_rate": 4.054812780223775e-05,
      "loss": 0.4189,
      "step": 5180
    },
    {
      "epoch": 0.6164627627984322,
      "grad_norm": 0.4917243719100952,
      "learning_rate": 4.052793149412288e-05,
      "loss": 0.1837,
      "step": 5190
    },
    {
      "epoch": 0.6176505523221285,
      "grad_norm": 6.266456604003906,
      "learning_rate": 4.0507735186008e-05,
      "loss": 0.3429,
      "step": 5200
    },
    {
      "epoch": 0.6188383418458249,
      "grad_norm": 9.936497688293457,
      "learning_rate": 4.048753887789312e-05,
      "loss": 0.4346,
      "step": 5210
    },
    {
      "epoch": 0.6200261313695213,
      "grad_norm": 2.34983491897583,
      "learning_rate": 4.0467342569778246e-05,
      "loss": 0.3245,
      "step": 5220
    },
    {
      "epoch": 0.6212139208932177,
      "grad_norm": 26.613033294677734,
      "learning_rate": 4.044714626166337e-05,
      "loss": 0.3669,
      "step": 5230
    },
    {
      "epoch": 0.6224017104169142,
      "grad_norm": 7.130774974822998,
      "learning_rate": 4.042694995354849e-05,
      "loss": 0.3532,
      "step": 5240
    },
    {
      "epoch": 0.6235894999406105,
      "grad_norm": 3.007063150405884,
      "learning_rate": 4.0406753645433616e-05,
      "loss": 0.4028,
      "step": 5250
    },
    {
      "epoch": 0.6247772894643069,
      "grad_norm": 29.887165069580078,
      "learning_rate": 4.038655733731874e-05,
      "loss": 0.4158,
      "step": 5260
    },
    {
      "epoch": 0.6259650789880034,
      "grad_norm": 1.6297494173049927,
      "learning_rate": 4.036636102920387e-05,
      "loss": 0.285,
      "step": 5270
    },
    {
      "epoch": 0.6271528685116997,
      "grad_norm": 9.422127723693848,
      "learning_rate": 4.0346164721088985e-05,
      "loss": 0.5555,
      "step": 5280
    },
    {
      "epoch": 0.6283406580353962,
      "grad_norm": 5.567056179046631,
      "learning_rate": 4.032596841297411e-05,
      "loss": 0.3537,
      "step": 5290
    },
    {
      "epoch": 0.6295284475590925,
      "grad_norm": 2.14558482170105,
      "learning_rate": 4.0305772104859236e-05,
      "loss": 0.3037,
      "step": 5300
    },
    {
      "epoch": 0.6307162370827889,
      "grad_norm": 11.612177848815918,
      "learning_rate": 4.0285575796744355e-05,
      "loss": 0.3503,
      "step": 5310
    },
    {
      "epoch": 0.6319040266064854,
      "grad_norm": 19.941814422607422,
      "learning_rate": 4.026537948862948e-05,
      "loss": 0.4755,
      "step": 5320
    },
    {
      "epoch": 0.6330918161301817,
      "grad_norm": 3.6134676933288574,
      "learning_rate": 4.0245183180514606e-05,
      "loss": 0.3734,
      "step": 5330
    },
    {
      "epoch": 0.6342796056538781,
      "grad_norm": 5.220411777496338,
      "learning_rate": 4.022498687239973e-05,
      "loss": 0.3516,
      "step": 5340
    },
    {
      "epoch": 0.6354673951775746,
      "grad_norm": 16.220123291015625,
      "learning_rate": 4.020479056428485e-05,
      "loss": 0.2623,
      "step": 5350
    },
    {
      "epoch": 0.6366551847012709,
      "grad_norm": 10.495121955871582,
      "learning_rate": 4.0184594256169975e-05,
      "loss": 0.2293,
      "step": 5360
    },
    {
      "epoch": 0.6378429742249674,
      "grad_norm": 9.744635581970215,
      "learning_rate": 4.01643979480551e-05,
      "loss": 0.2827,
      "step": 5370
    },
    {
      "epoch": 0.6390307637486637,
      "grad_norm": 18.08155632019043,
      "learning_rate": 4.014420163994022e-05,
      "loss": 0.2721,
      "step": 5380
    },
    {
      "epoch": 0.6402185532723601,
      "grad_norm": 13.098069190979004,
      "learning_rate": 4.0124005331825345e-05,
      "loss": 0.313,
      "step": 5390
    },
    {
      "epoch": 0.6414063427960566,
      "grad_norm": 8.340842247009277,
      "learning_rate": 4.010380902371047e-05,
      "loss": 0.3954,
      "step": 5400
    },
    {
      "epoch": 0.6425941323197529,
      "grad_norm": 9.069754600524902,
      "learning_rate": 4.0083612715595595e-05,
      "loss": 0.1731,
      "step": 5410
    },
    {
      "epoch": 0.6437819218434493,
      "grad_norm": 8.321173667907715,
      "learning_rate": 4.0063416407480714e-05,
      "loss": 0.3544,
      "step": 5420
    },
    {
      "epoch": 0.6449697113671458,
      "grad_norm": 15.883840560913086,
      "learning_rate": 4.004322009936583e-05,
      "loss": 0.5054,
      "step": 5430
    },
    {
      "epoch": 0.6461575008908421,
      "grad_norm": 7.083425998687744,
      "learning_rate": 4.0023023791250965e-05,
      "loss": 0.241,
      "step": 5440
    },
    {
      "epoch": 0.6473452904145386,
      "grad_norm": 4.7603535652160645,
      "learning_rate": 4.0002827483136083e-05,
      "loss": 0.3249,
      "step": 5450
    },
    {
      "epoch": 0.648533079938235,
      "grad_norm": 14.853463172912598,
      "learning_rate": 3.998263117502121e-05,
      "loss": 0.2622,
      "step": 5460
    },
    {
      "epoch": 0.6497208694619313,
      "grad_norm": 12.64697551727295,
      "learning_rate": 3.9962434866906334e-05,
      "loss": 0.2321,
      "step": 5470
    },
    {
      "epoch": 0.6509086589856278,
      "grad_norm": 0.979583740234375,
      "learning_rate": 3.994223855879145e-05,
      "loss": 0.2012,
      "step": 5480
    },
    {
      "epoch": 0.6520964485093241,
      "grad_norm": 13.671353340148926,
      "learning_rate": 3.992204225067658e-05,
      "loss": 0.3149,
      "step": 5490
    },
    {
      "epoch": 0.6532842380330206,
      "grad_norm": 2.9384946823120117,
      "learning_rate": 3.99018459425617e-05,
      "loss": 0.3,
      "step": 5500
    },
    {
      "epoch": 0.654472027556717,
      "grad_norm": 11.554459571838379,
      "learning_rate": 3.988164963444683e-05,
      "loss": 0.4183,
      "step": 5510
    },
    {
      "epoch": 0.6556598170804133,
      "grad_norm": 10.810188293457031,
      "learning_rate": 3.986145332633195e-05,
      "loss": 0.4755,
      "step": 5520
    },
    {
      "epoch": 0.6568476066041098,
      "grad_norm": 17.859355926513672,
      "learning_rate": 3.984125701821707e-05,
      "loss": 0.3036,
      "step": 5530
    },
    {
      "epoch": 0.6580353961278061,
      "grad_norm": 19.125045776367188,
      "learning_rate": 3.982106071010219e-05,
      "loss": 0.3668,
      "step": 5540
    },
    {
      "epoch": 0.6592231856515025,
      "grad_norm": 36.97314453125,
      "learning_rate": 3.980086440198732e-05,
      "loss": 0.4004,
      "step": 5550
    },
    {
      "epoch": 0.660410975175199,
      "grad_norm": 31.338153839111328,
      "learning_rate": 3.978066809387244e-05,
      "loss": 0.2817,
      "step": 5560
    },
    {
      "epoch": 0.6615987646988953,
      "grad_norm": 13.857985496520996,
      "learning_rate": 3.976047178575756e-05,
      "loss": 0.3529,
      "step": 5570
    },
    {
      "epoch": 0.6627865542225918,
      "grad_norm": 7.830148220062256,
      "learning_rate": 3.9740275477642693e-05,
      "loss": 0.2827,
      "step": 5580
    },
    {
      "epoch": 0.6639743437462882,
      "grad_norm": 24.516202926635742,
      "learning_rate": 3.972007916952781e-05,
      "loss": 0.481,
      "step": 5590
    },
    {
      "epoch": 0.6651621332699845,
      "grad_norm": 3.151930093765259,
      "learning_rate": 3.969988286141294e-05,
      "loss": 0.2243,
      "step": 5600
    },
    {
      "epoch": 0.666349922793681,
      "grad_norm": 9.456182479858398,
      "learning_rate": 3.9679686553298056e-05,
      "loss": 0.3697,
      "step": 5610
    },
    {
      "epoch": 0.6675377123173774,
      "grad_norm": 9.897953033447266,
      "learning_rate": 3.965949024518318e-05,
      "loss": 0.2996,
      "step": 5620
    },
    {
      "epoch": 0.6687255018410737,
      "grad_norm": 10.9636812210083,
      "learning_rate": 3.963929393706831e-05,
      "loss": 0.3625,
      "step": 5630
    },
    {
      "epoch": 0.6699132913647702,
      "grad_norm": 14.579648971557617,
      "learning_rate": 3.9619097628953426e-05,
      "loss": 0.3899,
      "step": 5640
    },
    {
      "epoch": 0.6711010808884665,
      "grad_norm": 0.6166204214096069,
      "learning_rate": 3.959890132083856e-05,
      "loss": 0.3162,
      "step": 5650
    },
    {
      "epoch": 0.672288870412163,
      "grad_norm": 46.643577575683594,
      "learning_rate": 3.9578705012723676e-05,
      "loss": 0.3997,
      "step": 5660
    },
    {
      "epoch": 0.6734766599358594,
      "grad_norm": 9.251639366149902,
      "learning_rate": 3.95585087046088e-05,
      "loss": 0.3448,
      "step": 5670
    },
    {
      "epoch": 0.6746644494595557,
      "grad_norm": 14.441885948181152,
      "learning_rate": 3.953831239649392e-05,
      "loss": 0.3439,
      "step": 5680
    },
    {
      "epoch": 0.6758522389832522,
      "grad_norm": 10.906942367553711,
      "learning_rate": 3.9518116088379046e-05,
      "loss": 0.534,
      "step": 5690
    },
    {
      "epoch": 0.6770400285069486,
      "grad_norm": 14.48031997680664,
      "learning_rate": 3.949791978026417e-05,
      "loss": 0.2686,
      "step": 5700
    },
    {
      "epoch": 0.678227818030645,
      "grad_norm": 6.129205703735352,
      "learning_rate": 3.947772347214929e-05,
      "loss": 0.4362,
      "step": 5710
    },
    {
      "epoch": 0.6794156075543414,
      "grad_norm": 21.753482818603516,
      "learning_rate": 3.945752716403442e-05,
      "loss": 0.3371,
      "step": 5720
    },
    {
      "epoch": 0.6806033970780377,
      "grad_norm": 5.545515060424805,
      "learning_rate": 3.943733085591954e-05,
      "loss": 0.3507,
      "step": 5730
    },
    {
      "epoch": 0.6817911866017342,
      "grad_norm": 24.667022705078125,
      "learning_rate": 3.9417134547804666e-05,
      "loss": 0.3876,
      "step": 5740
    },
    {
      "epoch": 0.6829789761254306,
      "grad_norm": 2.0890769958496094,
      "learning_rate": 3.9396938239689785e-05,
      "loss": 0.3386,
      "step": 5750
    },
    {
      "epoch": 0.6841667656491269,
      "grad_norm": 9.145528793334961,
      "learning_rate": 3.937674193157491e-05,
      "loss": 0.3621,
      "step": 5760
    },
    {
      "epoch": 0.6853545551728234,
      "grad_norm": 29.360015869140625,
      "learning_rate": 3.9356545623460035e-05,
      "loss": 0.3034,
      "step": 5770
    },
    {
      "epoch": 0.6865423446965198,
      "grad_norm": 0.7443081140518188,
      "learning_rate": 3.9336349315345154e-05,
      "loss": 0.2645,
      "step": 5780
    },
    {
      "epoch": 0.6877301342202162,
      "grad_norm": 8.56640338897705,
      "learning_rate": 3.931615300723028e-05,
      "loss": 0.2251,
      "step": 5790
    },
    {
      "epoch": 0.6889179237439126,
      "grad_norm": 19.452878952026367,
      "learning_rate": 3.9295956699115405e-05,
      "loss": 0.2457,
      "step": 5800
    },
    {
      "epoch": 0.690105713267609,
      "grad_norm": 21.12953758239746,
      "learning_rate": 3.9275760391000524e-05,
      "loss": 0.3705,
      "step": 5810
    },
    {
      "epoch": 0.6912935027913054,
      "grad_norm": 14.60181999206543,
      "learning_rate": 3.925556408288565e-05,
      "loss": 0.4037,
      "step": 5820
    },
    {
      "epoch": 0.6924812923150018,
      "grad_norm": 30.332246780395508,
      "learning_rate": 3.9235367774770774e-05,
      "loss": 0.4617,
      "step": 5830
    },
    {
      "epoch": 0.6936690818386981,
      "grad_norm": 11.73900032043457,
      "learning_rate": 3.92151714666559e-05,
      "loss": 0.268,
      "step": 5840
    },
    {
      "epoch": 0.6948568713623946,
      "grad_norm": 7.384748935699463,
      "learning_rate": 3.919497515854102e-05,
      "loss": 0.2391,
      "step": 5850
    },
    {
      "epoch": 0.696044660886091,
      "grad_norm": 14.981720924377441,
      "learning_rate": 3.9174778850426144e-05,
      "loss": 0.4131,
      "step": 5860
    },
    {
      "epoch": 0.6972324504097874,
      "grad_norm": 3.052426815032959,
      "learning_rate": 3.915458254231127e-05,
      "loss": 0.4427,
      "step": 5870
    },
    {
      "epoch": 0.6984202399334838,
      "grad_norm": 30.443042755126953,
      "learning_rate": 3.913438623419639e-05,
      "loss": 0.3032,
      "step": 5880
    },
    {
      "epoch": 0.6996080294571801,
      "grad_norm": 2.355085611343384,
      "learning_rate": 3.911418992608151e-05,
      "loss": 0.374,
      "step": 5890
    },
    {
      "epoch": 0.7007958189808766,
      "grad_norm": 5.413206100463867,
      "learning_rate": 3.909399361796664e-05,
      "loss": 0.3382,
      "step": 5900
    },
    {
      "epoch": 0.701983608504573,
      "grad_norm": 9.888495445251465,
      "learning_rate": 3.9073797309851764e-05,
      "loss": 0.4265,
      "step": 5910
    },
    {
      "epoch": 0.7031713980282694,
      "grad_norm": 15.522689819335938,
      "learning_rate": 3.905360100173688e-05,
      "loss": 0.4621,
      "step": 5920
    },
    {
      "epoch": 0.7043591875519658,
      "grad_norm": 26.7539005279541,
      "learning_rate": 3.903340469362201e-05,
      "loss": 0.4228,
      "step": 5930
    },
    {
      "epoch": 0.7055469770756622,
      "grad_norm": 11.63267707824707,
      "learning_rate": 3.9013208385507134e-05,
      "loss": 0.3451,
      "step": 5940
    },
    {
      "epoch": 0.7067347665993586,
      "grad_norm": 9.209331512451172,
      "learning_rate": 3.899301207739225e-05,
      "loss": 0.3039,
      "step": 5950
    },
    {
      "epoch": 0.707922556123055,
      "grad_norm": 4.09293270111084,
      "learning_rate": 3.897281576927738e-05,
      "loss": 0.3695,
      "step": 5960
    },
    {
      "epoch": 0.7091103456467513,
      "grad_norm": 8.881096839904785,
      "learning_rate": 3.89526194611625e-05,
      "loss": 0.3222,
      "step": 5970
    },
    {
      "epoch": 0.7102981351704478,
      "grad_norm": 21.51690101623535,
      "learning_rate": 3.893242315304763e-05,
      "loss": 0.3054,
      "step": 5980
    },
    {
      "epoch": 0.7114859246941442,
      "grad_norm": 14.750570297241211,
      "learning_rate": 3.891222684493275e-05,
      "loss": 0.399,
      "step": 5990
    },
    {
      "epoch": 0.7126737142178406,
      "grad_norm": 7.172597408294678,
      "learning_rate": 3.889203053681787e-05,
      "loss": 0.3147,
      "step": 6000
    },
    {
      "epoch": 0.713861503741537,
      "grad_norm": 6.100771427154541,
      "learning_rate": 3.8871834228703e-05,
      "loss": 0.4079,
      "step": 6010
    },
    {
      "epoch": 0.7150492932652334,
      "grad_norm": 10.738564491271973,
      "learning_rate": 3.8851637920588116e-05,
      "loss": 0.2955,
      "step": 6020
    },
    {
      "epoch": 0.7162370827889298,
      "grad_norm": 17.981258392333984,
      "learning_rate": 3.883144161247324e-05,
      "loss": 0.2797,
      "step": 6030
    },
    {
      "epoch": 0.7174248723126262,
      "grad_norm": 15.299372673034668,
      "learning_rate": 3.881124530435837e-05,
      "loss": 0.1886,
      "step": 6040
    },
    {
      "epoch": 0.7186126618363226,
      "grad_norm": 42.63776397705078,
      "learning_rate": 3.879104899624349e-05,
      "loss": 0.4234,
      "step": 6050
    },
    {
      "epoch": 0.719800451360019,
      "grad_norm": 7.270719528198242,
      "learning_rate": 3.877085268812861e-05,
      "loss": 0.3584,
      "step": 6060
    },
    {
      "epoch": 0.7209882408837154,
      "grad_norm": 22.470998764038086,
      "learning_rate": 3.875065638001374e-05,
      "loss": 0.421,
      "step": 6070
    },
    {
      "epoch": 0.7221760304074119,
      "grad_norm": 7.876162528991699,
      "learning_rate": 3.873046007189886e-05,
      "loss": 0.3004,
      "step": 6080
    },
    {
      "epoch": 0.7233638199311082,
      "grad_norm": 12.903029441833496,
      "learning_rate": 3.871026376378398e-05,
      "loss": 0.2653,
      "step": 6090
    },
    {
      "epoch": 0.7245516094548046,
      "grad_norm": 13.778879165649414,
      "learning_rate": 3.8690067455669106e-05,
      "loss": 0.3704,
      "step": 6100
    },
    {
      "epoch": 0.725739398978501,
      "grad_norm": 3.4458847045898438,
      "learning_rate": 3.8669871147554225e-05,
      "loss": 0.3654,
      "step": 6110
    },
    {
      "epoch": 0.7269271885021974,
      "grad_norm": 29.78091049194336,
      "learning_rate": 3.864967483943936e-05,
      "loss": 0.3504,
      "step": 6120
    },
    {
      "epoch": 0.7281149780258939,
      "grad_norm": 0.545586109161377,
      "learning_rate": 3.8629478531324476e-05,
      "loss": 0.3097,
      "step": 6130
    },
    {
      "epoch": 0.7293027675495902,
      "grad_norm": 0.6250219345092773,
      "learning_rate": 3.8609282223209594e-05,
      "loss": 0.2813,
      "step": 6140
    },
    {
      "epoch": 0.7304905570732866,
      "grad_norm": 2.2120025157928467,
      "learning_rate": 3.8589085915094726e-05,
      "loss": 0.3833,
      "step": 6150
    },
    {
      "epoch": 0.731678346596983,
      "grad_norm": 21.732730865478516,
      "learning_rate": 3.8568889606979845e-05,
      "loss": 0.2899,
      "step": 6160
    },
    {
      "epoch": 0.7328661361206794,
      "grad_norm": 12.08127212524414,
      "learning_rate": 3.854869329886497e-05,
      "loss": 0.3191,
      "step": 6170
    },
    {
      "epoch": 0.7340539256443758,
      "grad_norm": 4.642640590667725,
      "learning_rate": 3.852849699075009e-05,
      "loss": 0.5127,
      "step": 6180
    },
    {
      "epoch": 0.7352417151680722,
      "grad_norm": 5.567893028259277,
      "learning_rate": 3.8508300682635215e-05,
      "loss": 0.4618,
      "step": 6190
    },
    {
      "epoch": 0.7364295046917686,
      "grad_norm": 10.705526351928711,
      "learning_rate": 3.848810437452034e-05,
      "loss": 0.3195,
      "step": 6200
    },
    {
      "epoch": 0.7376172942154651,
      "grad_norm": 12.152069091796875,
      "learning_rate": 3.846790806640546e-05,
      "loss": 0.3243,
      "step": 6210
    },
    {
      "epoch": 0.7388050837391614,
      "grad_norm": 9.898673057556152,
      "learning_rate": 3.844771175829059e-05,
      "loss": 0.2632,
      "step": 6220
    },
    {
      "epoch": 0.7399928732628578,
      "grad_norm": 15.201260566711426,
      "learning_rate": 3.842751545017571e-05,
      "loss": 0.3438,
      "step": 6230
    },
    {
      "epoch": 0.7411806627865543,
      "grad_norm": 5.3453450202941895,
      "learning_rate": 3.8407319142060835e-05,
      "loss": 0.3235,
      "step": 6240
    },
    {
      "epoch": 0.7423684523102506,
      "grad_norm": 6.023809909820557,
      "learning_rate": 3.8387122833945953e-05,
      "loss": 0.3351,
      "step": 6250
    },
    {
      "epoch": 0.743556241833947,
      "grad_norm": 6.027975082397461,
      "learning_rate": 3.836692652583108e-05,
      "loss": 0.3781,
      "step": 6260
    },
    {
      "epoch": 0.7447440313576434,
      "grad_norm": 4.3232622146606445,
      "learning_rate": 3.8346730217716204e-05,
      "loss": 0.2431,
      "step": 6270
    },
    {
      "epoch": 0.7459318208813398,
      "grad_norm": 9.60299015045166,
      "learning_rate": 3.832653390960132e-05,
      "loss": 0.4384,
      "step": 6280
    },
    {
      "epoch": 0.7471196104050363,
      "grad_norm": 22.02179527282715,
      "learning_rate": 3.8306337601486455e-05,
      "loss": 0.273,
      "step": 6290
    },
    {
      "epoch": 0.7483073999287326,
      "grad_norm": 7.335934162139893,
      "learning_rate": 3.8286141293371574e-05,
      "loss": 0.4083,
      "step": 6300
    },
    {
      "epoch": 0.749495189452429,
      "grad_norm": 16.336313247680664,
      "learning_rate": 3.82659449852567e-05,
      "loss": 0.4474,
      "step": 6310
    },
    {
      "epoch": 0.7506829789761255,
      "grad_norm": 4.468890190124512,
      "learning_rate": 3.824574867714182e-05,
      "loss": 0.4955,
      "step": 6320
    },
    {
      "epoch": 0.7518707684998218,
      "grad_norm": 1.5039397478103638,
      "learning_rate": 3.822555236902694e-05,
      "loss": 0.3607,
      "step": 6330
    },
    {
      "epoch": 0.7530585580235183,
      "grad_norm": 12.512925148010254,
      "learning_rate": 3.820535606091207e-05,
      "loss": 0.2038,
      "step": 6340
    },
    {
      "epoch": 0.7542463475472146,
      "grad_norm": 36.614871978759766,
      "learning_rate": 3.818515975279719e-05,
      "loss": 0.4642,
      "step": 6350
    },
    {
      "epoch": 0.755434137070911,
      "grad_norm": 10.65939998626709,
      "learning_rate": 3.816496344468231e-05,
      "loss": 0.3043,
      "step": 6360
    },
    {
      "epoch": 0.7566219265946075,
      "grad_norm": 6.071587562561035,
      "learning_rate": 3.814476713656744e-05,
      "loss": 0.4338,
      "step": 6370
    },
    {
      "epoch": 0.7578097161183038,
      "grad_norm": 5.33978796005249,
      "learning_rate": 3.8124570828452563e-05,
      "loss": 0.1905,
      "step": 6380
    },
    {
      "epoch": 0.7589975056420002,
      "grad_norm": 6.938310623168945,
      "learning_rate": 3.810437452033768e-05,
      "loss": 0.2809,
      "step": 6390
    },
    {
      "epoch": 0.7601852951656967,
      "grad_norm": 33.839752197265625,
      "learning_rate": 3.808417821222281e-05,
      "loss": 0.3674,
      "step": 6400
    },
    {
      "epoch": 0.761373084689393,
      "grad_norm": 14.715520858764648,
      "learning_rate": 3.806398190410793e-05,
      "loss": 0.3169,
      "step": 6410
    },
    {
      "epoch": 0.7625608742130895,
      "grad_norm": 2.8626925945281982,
      "learning_rate": 3.804378559599305e-05,
      "loss": 0.1919,
      "step": 6420
    },
    {
      "epoch": 0.7637486637367858,
      "grad_norm": 8.1962251663208,
      "learning_rate": 3.802358928787818e-05,
      "loss": 0.2761,
      "step": 6430
    },
    {
      "epoch": 0.7649364532604822,
      "grad_norm": 4.606043338775635,
      "learning_rate": 3.80033929797633e-05,
      "loss": 0.3353,
      "step": 6440
    },
    {
      "epoch": 0.7661242427841787,
      "grad_norm": 1.1922497749328613,
      "learning_rate": 3.798319667164843e-05,
      "loss": 0.2963,
      "step": 6450
    },
    {
      "epoch": 0.767312032307875,
      "grad_norm": 24.214548110961914,
      "learning_rate": 3.7963000363533546e-05,
      "loss": 0.2751,
      "step": 6460
    },
    {
      "epoch": 0.7684998218315714,
      "grad_norm": 28.549020767211914,
      "learning_rate": 3.794280405541867e-05,
      "loss": 0.4374,
      "step": 6470
    },
    {
      "epoch": 0.7696876113552679,
      "grad_norm": 8.790802001953125,
      "learning_rate": 3.79226077473038e-05,
      "loss": 0.4044,
      "step": 6480
    },
    {
      "epoch": 0.7708754008789642,
      "grad_norm": 15.8742094039917,
      "learning_rate": 3.7902411439188916e-05,
      "loss": 0.5747,
      "step": 6490
    },
    {
      "epoch": 0.7720631904026607,
      "grad_norm": 12.79800796508789,
      "learning_rate": 3.788221513107404e-05,
      "loss": 0.2452,
      "step": 6500
    },
    {
      "epoch": 0.773250979926357,
      "grad_norm": 11.691362380981445,
      "learning_rate": 3.786201882295917e-05,
      "loss": 0.2921,
      "step": 6510
    },
    {
      "epoch": 0.7744387694500534,
      "grad_norm": 9.24013900756836,
      "learning_rate": 3.7841822514844285e-05,
      "loss": 0.3455,
      "step": 6520
    },
    {
      "epoch": 0.7756265589737499,
      "grad_norm": 21.585519790649414,
      "learning_rate": 3.782162620672941e-05,
      "loss": 0.4601,
      "step": 6530
    },
    {
      "epoch": 0.7768143484974462,
      "grad_norm": 7.856496334075928,
      "learning_rate": 3.7801429898614536e-05,
      "loss": 0.4739,
      "step": 6540
    },
    {
      "epoch": 0.7780021380211427,
      "grad_norm": 2.6644411087036133,
      "learning_rate": 3.778123359049966e-05,
      "loss": 0.2857,
      "step": 6550
    },
    {
      "epoch": 0.7791899275448391,
      "grad_norm": 19.45290756225586,
      "learning_rate": 3.776103728238478e-05,
      "loss": 0.2864,
      "step": 6560
    },
    {
      "epoch": 0.7803777170685354,
      "grad_norm": 8.79105281829834,
      "learning_rate": 3.7740840974269906e-05,
      "loss": 0.2451,
      "step": 6570
    },
    {
      "epoch": 0.7815655065922319,
      "grad_norm": 0.907319962978363,
      "learning_rate": 3.772064466615503e-05,
      "loss": 0.3228,
      "step": 6580
    },
    {
      "epoch": 0.7827532961159283,
      "grad_norm": 19.481176376342773,
      "learning_rate": 3.770044835804015e-05,
      "loss": 0.4501,
      "step": 6590
    },
    {
      "epoch": 0.7839410856396246,
      "grad_norm": 10.816704750061035,
      "learning_rate": 3.7680252049925275e-05,
      "loss": 0.2684,
      "step": 6600
    },
    {
      "epoch": 0.7851288751633211,
      "grad_norm": 7.415419101715088,
      "learning_rate": 3.76600557418104e-05,
      "loss": 0.4216,
      "step": 6610
    },
    {
      "epoch": 0.7863166646870174,
      "grad_norm": 13.076635360717773,
      "learning_rate": 3.7639859433695526e-05,
      "loss": 0.3809,
      "step": 6620
    },
    {
      "epoch": 0.7875044542107139,
      "grad_norm": 21.3736515045166,
      "learning_rate": 3.7619663125580644e-05,
      "loss": 0.4434,
      "step": 6630
    },
    {
      "epoch": 0.7886922437344103,
      "grad_norm": 24.538877487182617,
      "learning_rate": 3.759946681746577e-05,
      "loss": 0.3233,
      "step": 6640
    },
    {
      "epoch": 0.7898800332581066,
      "grad_norm": 42.52351379394531,
      "learning_rate": 3.7579270509350895e-05,
      "loss": 0.4246,
      "step": 6650
    },
    {
      "epoch": 0.7910678227818031,
      "grad_norm": 11.11138916015625,
      "learning_rate": 3.7559074201236014e-05,
      "loss": 0.3812,
      "step": 6660
    },
    {
      "epoch": 0.7922556123054995,
      "grad_norm": 1.7089524269104004,
      "learning_rate": 3.753887789312114e-05,
      "loss": 0.1993,
      "step": 6670
    },
    {
      "epoch": 0.7934434018291958,
      "grad_norm": 14.3203763961792,
      "learning_rate": 3.751868158500626e-05,
      "loss": 0.2154,
      "step": 6680
    },
    {
      "epoch": 0.7946311913528923,
      "grad_norm": 13.822912216186523,
      "learning_rate": 3.749848527689139e-05,
      "loss": 0.4246,
      "step": 6690
    },
    {
      "epoch": 0.7958189808765886,
      "grad_norm": 54.32624816894531,
      "learning_rate": 3.747828896877651e-05,
      "loss": 0.4376,
      "step": 6700
    },
    {
      "epoch": 0.7970067704002851,
      "grad_norm": 46.982051849365234,
      "learning_rate": 3.7458092660661634e-05,
      "loss": 0.2833,
      "step": 6710
    },
    {
      "epoch": 0.7981945599239815,
      "grad_norm": 16.635709762573242,
      "learning_rate": 3.743789635254676e-05,
      "loss": 0.2635,
      "step": 6720
    },
    {
      "epoch": 0.7993823494476778,
      "grad_norm": 20.946725845336914,
      "learning_rate": 3.741770004443188e-05,
      "loss": 0.3008,
      "step": 6730
    },
    {
      "epoch": 0.8005701389713743,
      "grad_norm": 15.115287780761719,
      "learning_rate": 3.7397503736317004e-05,
      "loss": 0.2734,
      "step": 6740
    },
    {
      "epoch": 0.8017579284950707,
      "grad_norm": 12.948357582092285,
      "learning_rate": 3.737730742820212e-05,
      "loss": 0.6295,
      "step": 6750
    },
    {
      "epoch": 0.8029457180187671,
      "grad_norm": 4.4479594230651855,
      "learning_rate": 3.7357111120087254e-05,
      "loss": 0.4626,
      "step": 6760
    },
    {
      "epoch": 0.8041335075424635,
      "grad_norm": 23.19251251220703,
      "learning_rate": 3.733691481197237e-05,
      "loss": 0.4175,
      "step": 6770
    },
    {
      "epoch": 0.8053212970661598,
      "grad_norm": 24.45236587524414,
      "learning_rate": 3.73167185038575e-05,
      "loss": 0.5071,
      "step": 6780
    },
    {
      "epoch": 0.8065090865898563,
      "grad_norm": 13.112409591674805,
      "learning_rate": 3.7296522195742624e-05,
      "loss": 0.3411,
      "step": 6790
    },
    {
      "epoch": 0.8076968761135527,
      "grad_norm": 6.733178615570068,
      "learning_rate": 3.727632588762774e-05,
      "loss": 0.3313,
      "step": 6800
    },
    {
      "epoch": 0.808884665637249,
      "grad_norm": 8.721845626831055,
      "learning_rate": 3.725612957951287e-05,
      "loss": 0.2955,
      "step": 6810
    },
    {
      "epoch": 0.8100724551609455,
      "grad_norm": 0.5181615352630615,
      "learning_rate": 3.7235933271397987e-05,
      "loss": 0.3449,
      "step": 6820
    },
    {
      "epoch": 0.8112602446846419,
      "grad_norm": 5.058443069458008,
      "learning_rate": 3.721573696328312e-05,
      "loss": 0.303,
      "step": 6830
    },
    {
      "epoch": 0.8124480342083383,
      "grad_norm": 18.666879653930664,
      "learning_rate": 3.719554065516824e-05,
      "loss": 0.2577,
      "step": 6840
    },
    {
      "epoch": 0.8136358237320347,
      "grad_norm": 13.078118324279785,
      "learning_rate": 3.7175344347053356e-05,
      "loss": 0.4334,
      "step": 6850
    },
    {
      "epoch": 0.814823613255731,
      "grad_norm": 12.77995777130127,
      "learning_rate": 3.715514803893849e-05,
      "loss": 0.3793,
      "step": 6860
    },
    {
      "epoch": 0.8160114027794275,
      "grad_norm": 16.74199676513672,
      "learning_rate": 3.713495173082361e-05,
      "loss": 0.4295,
      "step": 6870
    },
    {
      "epoch": 0.8171991923031239,
      "grad_norm": 15.096821784973145,
      "learning_rate": 3.711475542270873e-05,
      "loss": 0.5247,
      "step": 6880
    },
    {
      "epoch": 0.8183869818268202,
      "grad_norm": 7.728818416595459,
      "learning_rate": 3.709455911459385e-05,
      "loss": 0.4868,
      "step": 6890
    },
    {
      "epoch": 0.8195747713505167,
      "grad_norm": 24.28749656677246,
      "learning_rate": 3.7074362806478976e-05,
      "loss": 0.275,
      "step": 6900
    },
    {
      "epoch": 0.8207625608742131,
      "grad_norm": 7.352373123168945,
      "learning_rate": 3.70541664983641e-05,
      "loss": 0.271,
      "step": 6910
    },
    {
      "epoch": 0.8219503503979095,
      "grad_norm": 15.552572250366211,
      "learning_rate": 3.703397019024922e-05,
      "loss": 0.2543,
      "step": 6920
    },
    {
      "epoch": 0.8231381399216059,
      "grad_norm": 4.298904895782471,
      "learning_rate": 3.7013773882134346e-05,
      "loss": 0.4127,
      "step": 6930
    },
    {
      "epoch": 0.8243259294453023,
      "grad_norm": 20.8520565032959,
      "learning_rate": 3.699357757401947e-05,
      "loss": 0.3532,
      "step": 6940
    },
    {
      "epoch": 0.8255137189689987,
      "grad_norm": 15.086904525756836,
      "learning_rate": 3.6973381265904597e-05,
      "loss": 0.2773,
      "step": 6950
    },
    {
      "epoch": 0.8267015084926951,
      "grad_norm": 11.154314994812012,
      "learning_rate": 3.6953184957789715e-05,
      "loss": 0.276,
      "step": 6960
    },
    {
      "epoch": 0.8278892980163916,
      "grad_norm": 2.0070948600769043,
      "learning_rate": 3.693298864967484e-05,
      "loss": 0.2042,
      "step": 6970
    },
    {
      "epoch": 0.8290770875400879,
      "grad_norm": 11.26481819152832,
      "learning_rate": 3.6912792341559966e-05,
      "loss": 0.2745,
      "step": 6980
    },
    {
      "epoch": 0.8302648770637843,
      "grad_norm": 14.15507698059082,
      "learning_rate": 3.6892596033445085e-05,
      "loss": 0.2227,
      "step": 6990
    },
    {
      "epoch": 0.8314526665874807,
      "grad_norm": 16.00166893005371,
      "learning_rate": 3.687239972533021e-05,
      "loss": 0.2691,
      "step": 7000
    },
    {
      "epoch": 0.8326404561111771,
      "grad_norm": 6.420453071594238,
      "learning_rate": 3.6852203417215335e-05,
      "loss": 0.3101,
      "step": 7010
    },
    {
      "epoch": 0.8338282456348735,
      "grad_norm": 36.2130012512207,
      "learning_rate": 3.683200710910046e-05,
      "loss": 0.3025,
      "step": 7020
    },
    {
      "epoch": 0.8350160351585699,
      "grad_norm": 1.3165409564971924,
      "learning_rate": 3.681181080098558e-05,
      "loss": 0.478,
      "step": 7030
    },
    {
      "epoch": 0.8362038246822663,
      "grad_norm": 10.118300437927246,
      "learning_rate": 3.6791614492870705e-05,
      "loss": 0.3272,
      "step": 7040
    },
    {
      "epoch": 0.8373916142059628,
      "grad_norm": 15.739791870117188,
      "learning_rate": 3.677141818475583e-05,
      "loss": 0.4338,
      "step": 7050
    },
    {
      "epoch": 0.8385794037296591,
      "grad_norm": 13.134099960327148,
      "learning_rate": 3.675122187664095e-05,
      "loss": 0.2802,
      "step": 7060
    },
    {
      "epoch": 0.8397671932533555,
      "grad_norm": 16.498905181884766,
      "learning_rate": 3.6731025568526074e-05,
      "loss": 0.5639,
      "step": 7070
    },
    {
      "epoch": 0.8409549827770519,
      "grad_norm": 18.566848754882812,
      "learning_rate": 3.67108292604112e-05,
      "loss": 0.409,
      "step": 7080
    },
    {
      "epoch": 0.8421427723007483,
      "grad_norm": 2.3104074001312256,
      "learning_rate": 3.6690632952296325e-05,
      "loss": 0.3399,
      "step": 7090
    },
    {
      "epoch": 0.8433305618244447,
      "grad_norm": 9.961785316467285,
      "learning_rate": 3.6670436644181444e-05,
      "loss": 0.357,
      "step": 7100
    },
    {
      "epoch": 0.8445183513481411,
      "grad_norm": 8.06614875793457,
      "learning_rate": 3.665024033606657e-05,
      "loss": 0.3326,
      "step": 7110
    },
    {
      "epoch": 0.8457061408718375,
      "grad_norm": 9.280320167541504,
      "learning_rate": 3.6630044027951695e-05,
      "loss": 0.4806,
      "step": 7120
    },
    {
      "epoch": 0.846893930395534,
      "grad_norm": 6.4754638671875,
      "learning_rate": 3.660984771983681e-05,
      "loss": 0.3492,
      "step": 7130
    },
    {
      "epoch": 0.8480817199192303,
      "grad_norm": 31.316862106323242,
      "learning_rate": 3.658965141172194e-05,
      "loss": 0.3319,
      "step": 7140
    },
    {
      "epoch": 0.8492695094429267,
      "grad_norm": 0.5198899507522583,
      "learning_rate": 3.6569455103607064e-05,
      "loss": 0.2398,
      "step": 7150
    },
    {
      "epoch": 0.8504572989666231,
      "grad_norm": 14.526021957397461,
      "learning_rate": 3.654925879549219e-05,
      "loss": 0.3327,
      "step": 7160
    },
    {
      "epoch": 0.8516450884903195,
      "grad_norm": 11.072700500488281,
      "learning_rate": 3.652906248737731e-05,
      "loss": 0.1441,
      "step": 7170
    },
    {
      "epoch": 0.852832878014016,
      "grad_norm": 1.5030326843261719,
      "learning_rate": 3.650886617926243e-05,
      "loss": 0.3067,
      "step": 7180
    },
    {
      "epoch": 0.8540206675377123,
      "grad_norm": 4.084576606750488,
      "learning_rate": 3.648866987114756e-05,
      "loss": 0.3189,
      "step": 7190
    },
    {
      "epoch": 0.8552084570614087,
      "grad_norm": 6.317748069763184,
      "learning_rate": 3.646847356303268e-05,
      "loss": 0.3332,
      "step": 7200
    },
    {
      "epoch": 0.8563962465851052,
      "grad_norm": 2.032158851623535,
      "learning_rate": 3.64482772549178e-05,
      "loss": 0.4108,
      "step": 7210
    },
    {
      "epoch": 0.8575840361088015,
      "grad_norm": 31.227712631225586,
      "learning_rate": 3.642808094680293e-05,
      "loss": 0.3556,
      "step": 7220
    },
    {
      "epoch": 0.8587718256324979,
      "grad_norm": 1.7121987342834473,
      "learning_rate": 3.640788463868805e-05,
      "loss": 0.4572,
      "step": 7230
    },
    {
      "epoch": 0.8599596151561943,
      "grad_norm": 8.704715728759766,
      "learning_rate": 3.638768833057317e-05,
      "loss": 0.2975,
      "step": 7240
    },
    {
      "epoch": 0.8611474046798907,
      "grad_norm": 7.547451972961426,
      "learning_rate": 3.636749202245829e-05,
      "loss": 0.2865,
      "step": 7250
    },
    {
      "epoch": 0.8623351942035872,
      "grad_norm": 4.218377113342285,
      "learning_rate": 3.634729571434342e-05,
      "loss": 0.2815,
      "step": 7260
    },
    {
      "epoch": 0.8635229837272835,
      "grad_norm": 20.972978591918945,
      "learning_rate": 3.632709940622854e-05,
      "loss": 0.3242,
      "step": 7270
    },
    {
      "epoch": 0.8647107732509799,
      "grad_norm": 8.3685941696167,
      "learning_rate": 3.630690309811367e-05,
      "loss": 0.3443,
      "step": 7280
    },
    {
      "epoch": 0.8658985627746764,
      "grad_norm": 35.38051986694336,
      "learning_rate": 3.628670678999879e-05,
      "loss": 0.2846,
      "step": 7290
    },
    {
      "epoch": 0.8670863522983727,
      "grad_norm": 25.385839462280273,
      "learning_rate": 3.626651048188391e-05,
      "loss": 0.3409,
      "step": 7300
    },
    {
      "epoch": 0.8682741418220691,
      "grad_norm": 24.119112014770508,
      "learning_rate": 3.624631417376904e-05,
      "loss": 0.3355,
      "step": 7310
    },
    {
      "epoch": 0.8694619313457655,
      "grad_norm": 9.726987838745117,
      "learning_rate": 3.6226117865654155e-05,
      "loss": 0.2804,
      "step": 7320
    },
    {
      "epoch": 0.8706497208694619,
      "grad_norm": 10.816146850585938,
      "learning_rate": 3.620592155753929e-05,
      "loss": 0.2744,
      "step": 7330
    },
    {
      "epoch": 0.8718375103931584,
      "grad_norm": 13.463343620300293,
      "learning_rate": 3.6185725249424406e-05,
      "loss": 0.3862,
      "step": 7340
    },
    {
      "epoch": 0.8730252999168547,
      "grad_norm": 2.1407055854797363,
      "learning_rate": 3.616552894130953e-05,
      "loss": 0.3911,
      "step": 7350
    },
    {
      "epoch": 0.8742130894405511,
      "grad_norm": 9.980289459228516,
      "learning_rate": 3.614533263319466e-05,
      "loss": 0.3537,
      "step": 7360
    },
    {
      "epoch": 0.8754008789642476,
      "grad_norm": 3.501061201095581,
      "learning_rate": 3.6125136325079776e-05,
      "loss": 0.1962,
      "step": 7370
    },
    {
      "epoch": 0.8765886684879439,
      "grad_norm": 13.934910774230957,
      "learning_rate": 3.61049400169649e-05,
      "loss": 0.4144,
      "step": 7380
    },
    {
      "epoch": 0.8777764580116404,
      "grad_norm": 15.347533226013184,
      "learning_rate": 3.608474370885002e-05,
      "loss": 0.4482,
      "step": 7390
    },
    {
      "epoch": 0.8789642475353368,
      "grad_norm": 16.661239624023438,
      "learning_rate": 3.606454740073515e-05,
      "loss": 0.5096,
      "step": 7400
    },
    {
      "epoch": 0.8801520370590331,
      "grad_norm": 34.92196273803711,
      "learning_rate": 3.604435109262027e-05,
      "loss": 0.3039,
      "step": 7410
    },
    {
      "epoch": 0.8813398265827296,
      "grad_norm": 26.022872924804688,
      "learning_rate": 3.6024154784505396e-05,
      "loss": 0.3284,
      "step": 7420
    },
    {
      "epoch": 0.8825276161064259,
      "grad_norm": 2.8503365516662598,
      "learning_rate": 3.600395847639052e-05,
      "loss": 0.2994,
      "step": 7430
    },
    {
      "epoch": 0.8837154056301223,
      "grad_norm": 29.237279891967773,
      "learning_rate": 3.598376216827564e-05,
      "loss": 0.5027,
      "step": 7440
    },
    {
      "epoch": 0.8849031951538188,
      "grad_norm": 17.153535842895508,
      "learning_rate": 3.5963565860160765e-05,
      "loss": 0.2605,
      "step": 7450
    },
    {
      "epoch": 0.8860909846775151,
      "grad_norm": 8.355451583862305,
      "learning_rate": 3.5943369552045884e-05,
      "loss": 0.2022,
      "step": 7460
    },
    {
      "epoch": 0.8872787742012116,
      "grad_norm": 1.0651823282241821,
      "learning_rate": 3.5923173243931016e-05,
      "loss": 0.2708,
      "step": 7470
    },
    {
      "epoch": 0.888466563724908,
      "grad_norm": 24.276561737060547,
      "learning_rate": 3.5902976935816135e-05,
      "loss": 0.4847,
      "step": 7480
    },
    {
      "epoch": 0.8896543532486043,
      "grad_norm": 13.79641342163086,
      "learning_rate": 3.588278062770126e-05,
      "loss": 0.2912,
      "step": 7490
    },
    {
      "epoch": 0.8908421427723008,
      "grad_norm": 3.6514790058135986,
      "learning_rate": 3.586258431958638e-05,
      "loss": 0.2702,
      "step": 7500
    },
    {
      "epoch": 0.8920299322959971,
      "grad_norm": 18.660612106323242,
      "learning_rate": 3.5842388011471504e-05,
      "loss": 0.4043,
      "step": 7510
    },
    {
      "epoch": 0.8932177218196935,
      "grad_norm": 26.344833374023438,
      "learning_rate": 3.582219170335663e-05,
      "loss": 0.2035,
      "step": 7520
    },
    {
      "epoch": 0.89440551134339,
      "grad_norm": 3.028019428253174,
      "learning_rate": 3.580199539524175e-05,
      "loss": 0.4463,
      "step": 7530
    },
    {
      "epoch": 0.8955933008670863,
      "grad_norm": 14.701037406921387,
      "learning_rate": 3.578179908712688e-05,
      "loss": 0.3815,
      "step": 7540
    },
    {
      "epoch": 0.8967810903907828,
      "grad_norm": 13.442949295043945,
      "learning_rate": 3.5761602779012e-05,
      "loss": 0.3555,
      "step": 7550
    },
    {
      "epoch": 0.8979688799144792,
      "grad_norm": 1.9246442317962646,
      "learning_rate": 3.574140647089712e-05,
      "loss": 0.3113,
      "step": 7560
    },
    {
      "epoch": 0.8991566694381755,
      "grad_norm": 3.6845943927764893,
      "learning_rate": 3.572121016278224e-05,
      "loss": 0.3736,
      "step": 7570
    },
    {
      "epoch": 0.900344458961872,
      "grad_norm": 12.04697036743164,
      "learning_rate": 3.570101385466737e-05,
      "loss": 0.3316,
      "step": 7580
    },
    {
      "epoch": 0.9015322484855683,
      "grad_norm": 18.688106536865234,
      "learning_rate": 3.5680817546552494e-05,
      "loss": 0.3577,
      "step": 7590
    },
    {
      "epoch": 0.9027200380092648,
      "grad_norm": 4.542378902435303,
      "learning_rate": 3.566062123843761e-05,
      "loss": 0.3398,
      "step": 7600
    },
    {
      "epoch": 0.9039078275329612,
      "grad_norm": 22.532896041870117,
      "learning_rate": 3.564042493032274e-05,
      "loss": 0.4317,
      "step": 7610
    },
    {
      "epoch": 0.9050956170566575,
      "grad_norm": 31.128786087036133,
      "learning_rate": 3.562022862220786e-05,
      "loss": 0.2125,
      "step": 7620
    },
    {
      "epoch": 0.906283406580354,
      "grad_norm": 16.884979248046875,
      "learning_rate": 3.560003231409298e-05,
      "loss": 0.3028,
      "step": 7630
    },
    {
      "epoch": 0.9074711961040504,
      "grad_norm": 20.810699462890625,
      "learning_rate": 3.557983600597811e-05,
      "loss": 0.2612,
      "step": 7640
    },
    {
      "epoch": 0.9086589856277467,
      "grad_norm": 6.010660648345947,
      "learning_rate": 3.555963969786323e-05,
      "loss": 0.4586,
      "step": 7650
    },
    {
      "epoch": 0.9098467751514432,
      "grad_norm": 37.12477493286133,
      "learning_rate": 3.553944338974836e-05,
      "loss": 0.1843,
      "step": 7660
    },
    {
      "epoch": 0.9110345646751395,
      "grad_norm": 12.430229187011719,
      "learning_rate": 3.551924708163348e-05,
      "loss": 0.3736,
      "step": 7670
    },
    {
      "epoch": 0.912222354198836,
      "grad_norm": 9.813881874084473,
      "learning_rate": 3.54990507735186e-05,
      "loss": 0.325,
      "step": 7680
    },
    {
      "epoch": 0.9134101437225324,
      "grad_norm": 16.253786087036133,
      "learning_rate": 3.547885446540373e-05,
      "loss": 0.2067,
      "step": 7690
    },
    {
      "epoch": 0.9145979332462287,
      "grad_norm": 15.60142993927002,
      "learning_rate": 3.5458658157288846e-05,
      "loss": 0.4793,
      "step": 7700
    },
    {
      "epoch": 0.9157857227699252,
      "grad_norm": 19.98772621154785,
      "learning_rate": 3.543846184917397e-05,
      "loss": 0.4487,
      "step": 7710
    },
    {
      "epoch": 0.9169735122936216,
      "grad_norm": 5.046797275543213,
      "learning_rate": 3.54182655410591e-05,
      "loss": 0.1764,
      "step": 7720
    },
    {
      "epoch": 0.9181613018173179,
      "grad_norm": 4.34799337387085,
      "learning_rate": 3.539806923294422e-05,
      "loss": 0.3589,
      "step": 7730
    },
    {
      "epoch": 0.9193490913410144,
      "grad_norm": 15.010414123535156,
      "learning_rate": 3.537787292482934e-05,
      "loss": 0.3318,
      "step": 7740
    },
    {
      "epoch": 0.9205368808647107,
      "grad_norm": 4.836052894592285,
      "learning_rate": 3.5357676616714467e-05,
      "loss": 0.4225,
      "step": 7750
    },
    {
      "epoch": 0.9217246703884072,
      "grad_norm": 6.196690559387207,
      "learning_rate": 3.533748030859959e-05,
      "loss": 0.2486,
      "step": 7760
    },
    {
      "epoch": 0.9229124599121036,
      "grad_norm": 9.524883270263672,
      "learning_rate": 3.531728400048471e-05,
      "loss": 0.4698,
      "step": 7770
    },
    {
      "epoch": 0.9241002494357999,
      "grad_norm": 21.61652183532715,
      "learning_rate": 3.5297087692369836e-05,
      "loss": 0.3081,
      "step": 7780
    },
    {
      "epoch": 0.9252880389594964,
      "grad_norm": 8.013331413269043,
      "learning_rate": 3.527689138425496e-05,
      "loss": 0.2304,
      "step": 7790
    },
    {
      "epoch": 0.9264758284831928,
      "grad_norm": 22.364910125732422,
      "learning_rate": 3.525669507614009e-05,
      "loss": 0.2641,
      "step": 7800
    },
    {
      "epoch": 0.9276636180068892,
      "grad_norm": 31.423370361328125,
      "learning_rate": 3.5236498768025205e-05,
      "loss": 0.3264,
      "step": 7810
    },
    {
      "epoch": 0.9288514075305856,
      "grad_norm": 29.22661781311035,
      "learning_rate": 3.521630245991033e-05,
      "loss": 0.4565,
      "step": 7820
    },
    {
      "epoch": 0.930039197054282,
      "grad_norm": 1.3737483024597168,
      "learning_rate": 3.5196106151795456e-05,
      "loss": 0.2291,
      "step": 7830
    },
    {
      "epoch": 0.9312269865779784,
      "grad_norm": 2.8225231170654297,
      "learning_rate": 3.5175909843680575e-05,
      "loss": 0.2501,
      "step": 7840
    },
    {
      "epoch": 0.9324147761016748,
      "grad_norm": 43.130916595458984,
      "learning_rate": 3.51557135355657e-05,
      "loss": 0.3601,
      "step": 7850
    },
    {
      "epoch": 0.9336025656253711,
      "grad_norm": 4.197845935821533,
      "learning_rate": 3.5135517227450826e-05,
      "loss": 0.3204,
      "step": 7860
    },
    {
      "epoch": 0.9347903551490676,
      "grad_norm": 12.912960052490234,
      "learning_rate": 3.511532091933595e-05,
      "loss": 0.2633,
      "step": 7870
    },
    {
      "epoch": 0.935978144672764,
      "grad_norm": 15.902312278747559,
      "learning_rate": 3.509512461122107e-05,
      "loss": 0.4097,
      "step": 7880
    },
    {
      "epoch": 0.9371659341964604,
      "grad_norm": 19.450931549072266,
      "learning_rate": 3.507492830310619e-05,
      "loss": 0.353,
      "step": 7890
    },
    {
      "epoch": 0.9383537237201568,
      "grad_norm": 17.03590202331543,
      "learning_rate": 3.505473199499132e-05,
      "loss": 0.38,
      "step": 7900
    },
    {
      "epoch": 0.9395415132438532,
      "grad_norm": 7.078878879547119,
      "learning_rate": 3.503453568687644e-05,
      "loss": 0.2966,
      "step": 7910
    },
    {
      "epoch": 0.9407293027675496,
      "grad_norm": 5.446987628936768,
      "learning_rate": 3.5014339378761565e-05,
      "loss": 0.2669,
      "step": 7920
    },
    {
      "epoch": 0.941917092291246,
      "grad_norm": 4.016434669494629,
      "learning_rate": 3.499414307064669e-05,
      "loss": 0.3906,
      "step": 7930
    },
    {
      "epoch": 0.9431048818149423,
      "grad_norm": 3.5092649459838867,
      "learning_rate": 3.497394676253181e-05,
      "loss": 0.3552,
      "step": 7940
    },
    {
      "epoch": 0.9442926713386388,
      "grad_norm": 12.981947898864746,
      "learning_rate": 3.4953750454416934e-05,
      "loss": 0.265,
      "step": 7950
    },
    {
      "epoch": 0.9454804608623352,
      "grad_norm": 18.330352783203125,
      "learning_rate": 3.493355414630205e-05,
      "loss": 0.4314,
      "step": 7960
    },
    {
      "epoch": 0.9466682503860316,
      "grad_norm": 8.110562324523926,
      "learning_rate": 3.4913357838187185e-05,
      "loss": 0.3105,
      "step": 7970
    },
    {
      "epoch": 0.947856039909728,
      "grad_norm": 37.67518997192383,
      "learning_rate": 3.4893161530072303e-05,
      "loss": 0.4178,
      "step": 7980
    },
    {
      "epoch": 0.9490438294334244,
      "grad_norm": 1.7347784042358398,
      "learning_rate": 3.487296522195743e-05,
      "loss": 0.3122,
      "step": 7990
    },
    {
      "epoch": 0.9502316189571208,
      "grad_norm": 40.107967376708984,
      "learning_rate": 3.4852768913842554e-05,
      "loss": 0.4909,
      "step": 8000
    },
    {
      "epoch": 0.9514194084808172,
      "grad_norm": 1.5925058126449585,
      "learning_rate": 3.483257260572767e-05,
      "loss": 0.2122,
      "step": 8010
    },
    {
      "epoch": 0.9526071980045137,
      "grad_norm": 8.655205726623535,
      "learning_rate": 3.48123762976128e-05,
      "loss": 0.3323,
      "step": 8020
    },
    {
      "epoch": 0.95379498752821,
      "grad_norm": 9.591625213623047,
      "learning_rate": 3.479217998949792e-05,
      "loss": 0.3995,
      "step": 8030
    },
    {
      "epoch": 0.9549827770519064,
      "grad_norm": 12.802044868469238,
      "learning_rate": 3.477198368138305e-05,
      "loss": 0.2798,
      "step": 8040
    },
    {
      "epoch": 0.9561705665756028,
      "grad_norm": 29.278783798217773,
      "learning_rate": 3.475178737326817e-05,
      "loss": 0.2951,
      "step": 8050
    },
    {
      "epoch": 0.9573583560992992,
      "grad_norm": 31.962366104125977,
      "learning_rate": 3.473159106515329e-05,
      "loss": 0.3263,
      "step": 8060
    },
    {
      "epoch": 0.9585461456229956,
      "grad_norm": 36.59934616088867,
      "learning_rate": 3.471139475703841e-05,
      "loss": 0.3914,
      "step": 8070
    },
    {
      "epoch": 0.959733935146692,
      "grad_norm": 12.593801498413086,
      "learning_rate": 3.469119844892354e-05,
      "loss": 0.4921,
      "step": 8080
    },
    {
      "epoch": 0.9609217246703884,
      "grad_norm": 2.870026111602783,
      "learning_rate": 3.467100214080866e-05,
      "loss": 0.4233,
      "step": 8090
    },
    {
      "epoch": 0.9621095141940849,
      "grad_norm": 4.128379821777344,
      "learning_rate": 3.465080583269378e-05,
      "loss": 0.3055,
      "step": 8100
    },
    {
      "epoch": 0.9632973037177812,
      "grad_norm": 7.693733215332031,
      "learning_rate": 3.4630609524578913e-05,
      "loss": 0.3607,
      "step": 8110
    },
    {
      "epoch": 0.9644850932414776,
      "grad_norm": 9.428699493408203,
      "learning_rate": 3.461041321646403e-05,
      "loss": 0.4106,
      "step": 8120
    },
    {
      "epoch": 0.965672882765174,
      "grad_norm": 22.305118560791016,
      "learning_rate": 3.459021690834916e-05,
      "loss": 0.3008,
      "step": 8130
    },
    {
      "epoch": 0.9668606722888704,
      "grad_norm": 21.59253692626953,
      "learning_rate": 3.4570020600234276e-05,
      "loss": 0.3499,
      "step": 8140
    },
    {
      "epoch": 0.9680484618125668,
      "grad_norm": 12.758451461791992,
      "learning_rate": 3.45498242921194e-05,
      "loss": 0.372,
      "step": 8150
    },
    {
      "epoch": 0.9692362513362632,
      "grad_norm": 1.1648589372634888,
      "learning_rate": 3.452962798400453e-05,
      "loss": 0.4213,
      "step": 8160
    },
    {
      "epoch": 0.9704240408599596,
      "grad_norm": 11.744294166564941,
      "learning_rate": 3.4509431675889646e-05,
      "loss": 0.3751,
      "step": 8170
    },
    {
      "epoch": 0.9716118303836561,
      "grad_norm": 5.110970497131348,
      "learning_rate": 3.448923536777478e-05,
      "loss": 0.3666,
      "step": 8180
    },
    {
      "epoch": 0.9727996199073524,
      "grad_norm": 9.917181015014648,
      "learning_rate": 3.4469039059659896e-05,
      "loss": 0.3381,
      "step": 8190
    },
    {
      "epoch": 0.9739874094310488,
      "grad_norm": 5.828907489776611,
      "learning_rate": 3.444884275154502e-05,
      "loss": 0.13,
      "step": 8200
    },
    {
      "epoch": 0.9751751989547452,
      "grad_norm": 17.362323760986328,
      "learning_rate": 3.442864644343014e-05,
      "loss": 0.42,
      "step": 8210
    },
    {
      "epoch": 0.9763629884784416,
      "grad_norm": 10.969995498657227,
      "learning_rate": 3.4408450135315266e-05,
      "loss": 0.4912,
      "step": 8220
    },
    {
      "epoch": 0.9775507780021381,
      "grad_norm": 1.2722994089126587,
      "learning_rate": 3.438825382720039e-05,
      "loss": 0.2472,
      "step": 8230
    },
    {
      "epoch": 0.9787385675258344,
      "grad_norm": 16.52678871154785,
      "learning_rate": 3.436805751908551e-05,
      "loss": 0.3887,
      "step": 8240
    },
    {
      "epoch": 0.9799263570495308,
      "grad_norm": 14.964811325073242,
      "learning_rate": 3.434786121097064e-05,
      "loss": 0.355,
      "step": 8250
    },
    {
      "epoch": 0.9811141465732273,
      "grad_norm": 7.988043785095215,
      "learning_rate": 3.432766490285576e-05,
      "loss": 0.2742,
      "step": 8260
    },
    {
      "epoch": 0.9823019360969236,
      "grad_norm": 19.35670280456543,
      "learning_rate": 3.430746859474088e-05,
      "loss": 0.3985,
      "step": 8270
    },
    {
      "epoch": 0.98348972562062,
      "grad_norm": 15.008645057678223,
      "learning_rate": 3.4287272286626005e-05,
      "loss": 0.3758,
      "step": 8280
    },
    {
      "epoch": 0.9846775151443165,
      "grad_norm": 21.98958969116211,
      "learning_rate": 3.426707597851113e-05,
      "loss": 0.3293,
      "step": 8290
    },
    {
      "epoch": 0.9858653046680128,
      "grad_norm": 2.259046792984009,
      "learning_rate": 3.4246879670396256e-05,
      "loss": 0.277,
      "step": 8300
    },
    {
      "epoch": 0.9870530941917093,
      "grad_norm": 26.337955474853516,
      "learning_rate": 3.4226683362281374e-05,
      "loss": 0.2907,
      "step": 8310
    },
    {
      "epoch": 0.9882408837154056,
      "grad_norm": 28.902847290039062,
      "learning_rate": 3.42064870541665e-05,
      "loss": 0.2866,
      "step": 8320
    },
    {
      "epoch": 0.989428673239102,
      "grad_norm": 9.167086601257324,
      "learning_rate": 3.4186290746051625e-05,
      "loss": 0.4542,
      "step": 8330
    },
    {
      "epoch": 0.9906164627627985,
      "grad_norm": 20.121004104614258,
      "learning_rate": 3.4166094437936744e-05,
      "loss": 0.3234,
      "step": 8340
    },
    {
      "epoch": 0.9918042522864948,
      "grad_norm": 0.793215274810791,
      "learning_rate": 3.414589812982187e-05,
      "loss": 0.3092,
      "step": 8350
    },
    {
      "epoch": 0.9929920418101912,
      "grad_norm": 3.876063346862793,
      "learning_rate": 3.4125701821706994e-05,
      "loss": 0.2061,
      "step": 8360
    },
    {
      "epoch": 0.9941798313338877,
      "grad_norm": 8.85168743133545,
      "learning_rate": 3.410550551359212e-05,
      "loss": 0.2795,
      "step": 8370
    },
    {
      "epoch": 0.995367620857584,
      "grad_norm": 8.846240997314453,
      "learning_rate": 3.408530920547724e-05,
      "loss": 0.456,
      "step": 8380
    },
    {
      "epoch": 0.9965554103812805,
      "grad_norm": 13.33649730682373,
      "learning_rate": 3.4065112897362364e-05,
      "loss": 0.3535,
      "step": 8390
    },
    {
      "epoch": 0.9977431999049768,
      "grad_norm": 12.869028091430664,
      "learning_rate": 3.404491658924749e-05,
      "loss": 0.2967,
      "step": 8400
    },
    {
      "epoch": 0.9989309894286732,
      "grad_norm": 5.75457239151001,
      "learning_rate": 3.402472028113261e-05,
      "loss": 0.2026,
      "step": 8410
    },
    {
      "epoch": 1.0001187789523696,
      "grad_norm": 1.6794381141662598,
      "learning_rate": 3.400452397301773e-05,
      "loss": 0.3157,
      "step": 8420
    },
    {
      "epoch": 1.001306568476066,
      "grad_norm": 13.557965278625488,
      "learning_rate": 3.398432766490286e-05,
      "loss": 0.2963,
      "step": 8430
    },
    {
      "epoch": 1.0024943579997625,
      "grad_norm": 10.1004056930542,
      "learning_rate": 3.3964131356787984e-05,
      "loss": 0.2695,
      "step": 8440
    },
    {
      "epoch": 1.0036821475234587,
      "grad_norm": 13.183156967163086,
      "learning_rate": 3.39439350486731e-05,
      "loss": 0.3517,
      "step": 8450
    },
    {
      "epoch": 1.0048699370471552,
      "grad_norm": 5.459792137145996,
      "learning_rate": 3.392373874055823e-05,
      "loss": 0.3974,
      "step": 8460
    },
    {
      "epoch": 1.0060577265708517,
      "grad_norm": 14.223832130432129,
      "learning_rate": 3.3903542432443354e-05,
      "loss": 0.2185,
      "step": 8470
    },
    {
      "epoch": 1.0072455160945482,
      "grad_norm": 4.980405807495117,
      "learning_rate": 3.388334612432847e-05,
      "loss": 0.436,
      "step": 8480
    },
    {
      "epoch": 1.0084333056182444,
      "grad_norm": 10.167390823364258,
      "learning_rate": 3.38631498162136e-05,
      "loss": 0.403,
      "step": 8490
    },
    {
      "epoch": 1.0096210951419409,
      "grad_norm": 15.788153648376465,
      "learning_rate": 3.384295350809872e-05,
      "loss": 0.2981,
      "step": 8500
    },
    {
      "epoch": 1.0108088846656373,
      "grad_norm": 2.6012635231018066,
      "learning_rate": 3.382275719998385e-05,
      "loss": 0.2215,
      "step": 8510
    },
    {
      "epoch": 1.0119966741893336,
      "grad_norm": 33.283695220947266,
      "learning_rate": 3.380256089186897e-05,
      "loss": 0.2877,
      "step": 8520
    },
    {
      "epoch": 1.01318446371303,
      "grad_norm": 13.761646270751953,
      "learning_rate": 3.378236458375409e-05,
      "loss": 0.3173,
      "step": 8530
    },
    {
      "epoch": 1.0143722532367265,
      "grad_norm": 10.900320053100586,
      "learning_rate": 3.376216827563922e-05,
      "loss": 0.4636,
      "step": 8540
    },
    {
      "epoch": 1.0155600427604228,
      "grad_norm": 1.644028663635254,
      "learning_rate": 3.3741971967524337e-05,
      "loss": 0.178,
      "step": 8550
    },
    {
      "epoch": 1.0167478322841192,
      "grad_norm": 8.731019020080566,
      "learning_rate": 3.372177565940946e-05,
      "loss": 0.2911,
      "step": 8560
    },
    {
      "epoch": 1.0179356218078157,
      "grad_norm": 8.286487579345703,
      "learning_rate": 3.370157935129459e-05,
      "loss": 0.2031,
      "step": 8570
    },
    {
      "epoch": 1.019123411331512,
      "grad_norm": 1.2993066310882568,
      "learning_rate": 3.368138304317971e-05,
      "loss": 0.2878,
      "step": 8580
    },
    {
      "epoch": 1.0203112008552084,
      "grad_norm": 9.728721618652344,
      "learning_rate": 3.366118673506483e-05,
      "loss": 0.2818,
      "step": 8590
    },
    {
      "epoch": 1.021498990378905,
      "grad_norm": 4.88653564453125,
      "learning_rate": 3.364099042694995e-05,
      "loss": 0.5664,
      "step": 8600
    },
    {
      "epoch": 1.0226867799026012,
      "grad_norm": 13.58228874206543,
      "learning_rate": 3.362079411883508e-05,
      "loss": 0.4562,
      "step": 8610
    },
    {
      "epoch": 1.0238745694262976,
      "grad_norm": 7.638315677642822,
      "learning_rate": 3.36005978107202e-05,
      "loss": 0.2039,
      "step": 8620
    },
    {
      "epoch": 1.025062358949994,
      "grad_norm": 21.68489646911621,
      "learning_rate": 3.3580401502605326e-05,
      "loss": 0.3476,
      "step": 8630
    },
    {
      "epoch": 1.0262501484736906,
      "grad_norm": 1.6738545894622803,
      "learning_rate": 3.3560205194490445e-05,
      "loss": 0.2067,
      "step": 8640
    },
    {
      "epoch": 1.0274379379973868,
      "grad_norm": 15.95511245727539,
      "learning_rate": 3.354000888637557e-05,
      "loss": 0.5283,
      "step": 8650
    },
    {
      "epoch": 1.0286257275210833,
      "grad_norm": 33.51917266845703,
      "learning_rate": 3.3519812578260696e-05,
      "loss": 0.398,
      "step": 8660
    },
    {
      "epoch": 1.0298135170447797,
      "grad_norm": 12.088363647460938,
      "learning_rate": 3.3499616270145814e-05,
      "loss": 0.248,
      "step": 8670
    },
    {
      "epoch": 1.031001306568476,
      "grad_norm": 17.638418197631836,
      "learning_rate": 3.3479419962030947e-05,
      "loss": 0.2712,
      "step": 8680
    },
    {
      "epoch": 1.0321890960921725,
      "grad_norm": 4.983070373535156,
      "learning_rate": 3.3459223653916065e-05,
      "loss": 0.3852,
      "step": 8690
    },
    {
      "epoch": 1.033376885615869,
      "grad_norm": 3.496751308441162,
      "learning_rate": 3.343902734580119e-05,
      "loss": 0.3236,
      "step": 8700
    },
    {
      "epoch": 1.0345646751395652,
      "grad_norm": 58.97075653076172,
      "learning_rate": 3.341883103768631e-05,
      "loss": 0.2612,
      "step": 8710
    },
    {
      "epoch": 1.0357524646632617,
      "grad_norm": 4.976655006408691,
      "learning_rate": 3.3398634729571435e-05,
      "loss": 0.2398,
      "step": 8720
    },
    {
      "epoch": 1.0369402541869581,
      "grad_norm": 13.253398895263672,
      "learning_rate": 3.337843842145656e-05,
      "loss": 0.4248,
      "step": 8730
    },
    {
      "epoch": 1.0381280437106544,
      "grad_norm": 11.341100692749023,
      "learning_rate": 3.335824211334168e-05,
      "loss": 0.3073,
      "step": 8740
    },
    {
      "epoch": 1.0393158332343508,
      "grad_norm": 6.288755893707275,
      "learning_rate": 3.333804580522681e-05,
      "loss": 0.2891,
      "step": 8750
    },
    {
      "epoch": 1.0405036227580473,
      "grad_norm": 4.598485946655273,
      "learning_rate": 3.331784949711193e-05,
      "loss": 0.3525,
      "step": 8760
    },
    {
      "epoch": 1.0416914122817438,
      "grad_norm": 2.0503997802734375,
      "learning_rate": 3.3297653188997055e-05,
      "loss": 0.2188,
      "step": 8770
    },
    {
      "epoch": 1.04287920180544,
      "grad_norm": 10.431378364562988,
      "learning_rate": 3.3277456880882174e-05,
      "loss": 0.4133,
      "step": 8780
    },
    {
      "epoch": 1.0440669913291365,
      "grad_norm": 9.396150588989258,
      "learning_rate": 3.32572605727673e-05,
      "loss": 0.2176,
      "step": 8790
    },
    {
      "epoch": 1.045254780852833,
      "grad_norm": 1.026813268661499,
      "learning_rate": 3.3237064264652424e-05,
      "loss": 0.3343,
      "step": 8800
    },
    {
      "epoch": 1.0464425703765292,
      "grad_norm": 20.247577667236328,
      "learning_rate": 3.321686795653754e-05,
      "loss": 0.3515,
      "step": 8810
    },
    {
      "epoch": 1.0476303599002257,
      "grad_norm": 5.2608561515808105,
      "learning_rate": 3.3196671648422675e-05,
      "loss": 0.4329,
      "step": 8820
    },
    {
      "epoch": 1.0488181494239222,
      "grad_norm": 2.0846681594848633,
      "learning_rate": 3.3176475340307794e-05,
      "loss": 0.3815,
      "step": 8830
    },
    {
      "epoch": 1.0500059389476184,
      "grad_norm": 17.93918228149414,
      "learning_rate": 3.315627903219292e-05,
      "loss": 0.3386,
      "step": 8840
    },
    {
      "epoch": 1.0511937284713149,
      "grad_norm": 0.5360638499259949,
      "learning_rate": 3.313608272407804e-05,
      "loss": 0.2774,
      "step": 8850
    },
    {
      "epoch": 1.0523815179950113,
      "grad_norm": 17.764978408813477,
      "learning_rate": 3.311588641596316e-05,
      "loss": 0.3157,
      "step": 8860
    },
    {
      "epoch": 1.0535693075187076,
      "grad_norm": 15.895980834960938,
      "learning_rate": 3.309569010784829e-05,
      "loss": 0.1572,
      "step": 8870
    },
    {
      "epoch": 1.054757097042404,
      "grad_norm": 6.2648539543151855,
      "learning_rate": 3.307549379973341e-05,
      "loss": 0.1683,
      "step": 8880
    },
    {
      "epoch": 1.0559448865661005,
      "grad_norm": 1.7732622623443604,
      "learning_rate": 3.305529749161853e-05,
      "loss": 0.2485,
      "step": 8890
    },
    {
      "epoch": 1.0571326760897968,
      "grad_norm": 0.9658241868019104,
      "learning_rate": 3.303510118350366e-05,
      "loss": 0.3833,
      "step": 8900
    },
    {
      "epoch": 1.0583204656134932,
      "grad_norm": 20.720510482788086,
      "learning_rate": 3.3014904875388784e-05,
      "loss": 0.2606,
      "step": 8910
    },
    {
      "epoch": 1.0595082551371897,
      "grad_norm": 13.15865707397461,
      "learning_rate": 3.29947085672739e-05,
      "loss": 0.3212,
      "step": 8920
    },
    {
      "epoch": 1.0606960446608862,
      "grad_norm": 0.8900420665740967,
      "learning_rate": 3.297451225915903e-05,
      "loss": 0.1837,
      "step": 8930
    },
    {
      "epoch": 1.0618838341845824,
      "grad_norm": 19.529098510742188,
      "learning_rate": 3.295431595104415e-05,
      "loss": 0.2903,
      "step": 8940
    },
    {
      "epoch": 1.063071623708279,
      "grad_norm": 10.801809310913086,
      "learning_rate": 3.293411964292927e-05,
      "loss": 0.2471,
      "step": 8950
    },
    {
      "epoch": 1.0642594132319754,
      "grad_norm": 7.2456183433532715,
      "learning_rate": 3.29139233348144e-05,
      "loss": 0.2483,
      "step": 8960
    },
    {
      "epoch": 1.0654472027556716,
      "grad_norm": 12.042861938476562,
      "learning_rate": 3.289372702669952e-05,
      "loss": 0.3088,
      "step": 8970
    },
    {
      "epoch": 1.066634992279368,
      "grad_norm": 11.178132057189941,
      "learning_rate": 3.287353071858464e-05,
      "loss": 0.3954,
      "step": 8980
    },
    {
      "epoch": 1.0678227818030646,
      "grad_norm": 11.337471008300781,
      "learning_rate": 3.2853334410469766e-05,
      "loss": 0.4718,
      "step": 8990
    },
    {
      "epoch": 1.0690105713267608,
      "grad_norm": 24.997238159179688,
      "learning_rate": 3.283313810235489e-05,
      "loss": 0.292,
      "step": 9000
    },
    {
      "epoch": 1.0701983608504573,
      "grad_norm": 18.392126083374023,
      "learning_rate": 3.281294179424002e-05,
      "loss": 0.3887,
      "step": 9010
    },
    {
      "epoch": 1.0713861503741537,
      "grad_norm": 1.1071451902389526,
      "learning_rate": 3.2792745486125136e-05,
      "loss": 0.2293,
      "step": 9020
    },
    {
      "epoch": 1.07257393989785,
      "grad_norm": 26.155954360961914,
      "learning_rate": 3.277254917801026e-05,
      "loss": 0.4537,
      "step": 9030
    },
    {
      "epoch": 1.0737617294215465,
      "grad_norm": 2.508192300796509,
      "learning_rate": 3.275235286989539e-05,
      "loss": 0.2711,
      "step": 9040
    },
    {
      "epoch": 1.074949518945243,
      "grad_norm": 9.930282592773438,
      "learning_rate": 3.2732156561780505e-05,
      "loss": 0.2087,
      "step": 9050
    },
    {
      "epoch": 1.0761373084689394,
      "grad_norm": 19.738813400268555,
      "learning_rate": 3.271196025366563e-05,
      "loss": 0.2444,
      "step": 9060
    },
    {
      "epoch": 1.0773250979926356,
      "grad_norm": 1.8219317197799683,
      "learning_rate": 3.2691763945550756e-05,
      "loss": 0.1143,
      "step": 9070
    },
    {
      "epoch": 1.0785128875163321,
      "grad_norm": 31.282489776611328,
      "learning_rate": 3.267156763743588e-05,
      "loss": 0.3183,
      "step": 9080
    },
    {
      "epoch": 1.0797006770400286,
      "grad_norm": 5.890576362609863,
      "learning_rate": 3.2651371329321e-05,
      "loss": 0.2395,
      "step": 9090
    },
    {
      "epoch": 1.0808884665637248,
      "grad_norm": 22.25905990600586,
      "learning_rate": 3.2631175021206126e-05,
      "loss": 0.249,
      "step": 9100
    },
    {
      "epoch": 1.0820762560874213,
      "grad_norm": 19.37005615234375,
      "learning_rate": 3.261097871309125e-05,
      "loss": 0.614,
      "step": 9110
    },
    {
      "epoch": 1.0832640456111178,
      "grad_norm": 1.2905528545379639,
      "learning_rate": 3.259078240497637e-05,
      "loss": 0.3962,
      "step": 9120
    },
    {
      "epoch": 1.084451835134814,
      "grad_norm": 2.557676315307617,
      "learning_rate": 3.2570586096861495e-05,
      "loss": 0.2258,
      "step": 9130
    },
    {
      "epoch": 1.0856396246585105,
      "grad_norm": 9.455745697021484,
      "learning_rate": 3.255038978874662e-05,
      "loss": 0.2414,
      "step": 9140
    },
    {
      "epoch": 1.086827414182207,
      "grad_norm": 6.507854461669922,
      "learning_rate": 3.2530193480631746e-05,
      "loss": 0.3311,
      "step": 9150
    },
    {
      "epoch": 1.0880152037059032,
      "grad_norm": 1.8739690780639648,
      "learning_rate": 3.2509997172516865e-05,
      "loss": 0.1785,
      "step": 9160
    },
    {
      "epoch": 1.0892029932295997,
      "grad_norm": 9.872477531433105,
      "learning_rate": 3.248980086440199e-05,
      "loss": 0.3465,
      "step": 9170
    },
    {
      "epoch": 1.0903907827532962,
      "grad_norm": 25.95928192138672,
      "learning_rate": 3.2469604556287115e-05,
      "loss": 0.1787,
      "step": 9180
    },
    {
      "epoch": 1.0915785722769926,
      "grad_norm": 1.3857536315917969,
      "learning_rate": 3.2449408248172234e-05,
      "loss": 0.3341,
      "step": 9190
    },
    {
      "epoch": 1.0927663618006889,
      "grad_norm": 21.229318618774414,
      "learning_rate": 3.242921194005736e-05,
      "loss": 0.2681,
      "step": 9200
    },
    {
      "epoch": 1.0939541513243853,
      "grad_norm": 21.30767059326172,
      "learning_rate": 3.240901563194248e-05,
      "loss": 0.3242,
      "step": 9210
    },
    {
      "epoch": 1.0951419408480818,
      "grad_norm": 0.2808346152305603,
      "learning_rate": 3.238881932382761e-05,
      "loss": 0.2684,
      "step": 9220
    },
    {
      "epoch": 1.096329730371778,
      "grad_norm": 22.65732192993164,
      "learning_rate": 3.236862301571273e-05,
      "loss": 0.2308,
      "step": 9230
    },
    {
      "epoch": 1.0975175198954745,
      "grad_norm": 7.185798645019531,
      "learning_rate": 3.2348426707597854e-05,
      "loss": 0.4514,
      "step": 9240
    },
    {
      "epoch": 1.098705309419171,
      "grad_norm": 1.3242149353027344,
      "learning_rate": 3.232823039948298e-05,
      "loss": 0.1525,
      "step": 9250
    },
    {
      "epoch": 1.0998930989428672,
      "grad_norm": 2.754199504852295,
      "learning_rate": 3.23080340913681e-05,
      "loss": 0.4537,
      "step": 9260
    },
    {
      "epoch": 1.1010808884665637,
      "grad_norm": 25.927989959716797,
      "learning_rate": 3.2287837783253224e-05,
      "loss": 0.2438,
      "step": 9270
    },
    {
      "epoch": 1.1022686779902602,
      "grad_norm": 15.182867050170898,
      "learning_rate": 3.226764147513834e-05,
      "loss": 0.3315,
      "step": 9280
    },
    {
      "epoch": 1.1034564675139564,
      "grad_norm": 8.480072021484375,
      "learning_rate": 3.2247445167023474e-05,
      "loss": 0.1423,
      "step": 9290
    },
    {
      "epoch": 1.104644257037653,
      "grad_norm": 1.1074351072311401,
      "learning_rate": 3.222724885890859e-05,
      "loss": 0.3971,
      "step": 9300
    },
    {
      "epoch": 1.1058320465613494,
      "grad_norm": 0.1257953941822052,
      "learning_rate": 3.220705255079371e-05,
      "loss": 0.1355,
      "step": 9310
    },
    {
      "epoch": 1.1070198360850458,
      "grad_norm": 3.691074848175049,
      "learning_rate": 3.2186856242678844e-05,
      "loss": 0.2816,
      "step": 9320
    },
    {
      "epoch": 1.108207625608742,
      "grad_norm": 3.8760673999786377,
      "learning_rate": 3.216665993456396e-05,
      "loss": 0.3073,
      "step": 9330
    },
    {
      "epoch": 1.1093954151324386,
      "grad_norm": 0.3443794846534729,
      "learning_rate": 3.214646362644909e-05,
      "loss": 0.1836,
      "step": 9340
    },
    {
      "epoch": 1.110583204656135,
      "grad_norm": 28.53167724609375,
      "learning_rate": 3.212626731833421e-05,
      "loss": 0.4829,
      "step": 9350
    },
    {
      "epoch": 1.1117709941798313,
      "grad_norm": 11.715275764465332,
      "learning_rate": 3.210607101021933e-05,
      "loss": 0.1268,
      "step": 9360
    },
    {
      "epoch": 1.1129587837035277,
      "grad_norm": 13.78066635131836,
      "learning_rate": 3.208587470210446e-05,
      "loss": 0.2162,
      "step": 9370
    },
    {
      "epoch": 1.1141465732272242,
      "grad_norm": 0.7310017943382263,
      "learning_rate": 3.2065678393989576e-05,
      "loss": 0.1605,
      "step": 9380
    },
    {
      "epoch": 1.1153343627509205,
      "grad_norm": 13.33165168762207,
      "learning_rate": 3.204548208587471e-05,
      "loss": 0.3978,
      "step": 9390
    },
    {
      "epoch": 1.116522152274617,
      "grad_norm": 4.175899982452393,
      "learning_rate": 3.202528577775983e-05,
      "loss": 0.3255,
      "step": 9400
    },
    {
      "epoch": 1.1177099417983134,
      "grad_norm": 33.30461502075195,
      "learning_rate": 3.200508946964495e-05,
      "loss": 0.3951,
      "step": 9410
    },
    {
      "epoch": 1.1188977313220096,
      "grad_norm": 0.2937946915626526,
      "learning_rate": 3.198489316153007e-05,
      "loss": 0.2137,
      "step": 9420
    },
    {
      "epoch": 1.1200855208457061,
      "grad_norm": 14.903120040893555,
      "learning_rate": 3.1964696853415196e-05,
      "loss": 0.2861,
      "step": 9430
    },
    {
      "epoch": 1.1212733103694026,
      "grad_norm": 1.3363945484161377,
      "learning_rate": 3.194450054530032e-05,
      "loss": 0.3179,
      "step": 9440
    },
    {
      "epoch": 1.122461099893099,
      "grad_norm": 16.311553955078125,
      "learning_rate": 3.192430423718544e-05,
      "loss": 0.3096,
      "step": 9450
    },
    {
      "epoch": 1.1236488894167953,
      "grad_norm": 17.051572799682617,
      "learning_rate": 3.1904107929070566e-05,
      "loss": 0.2603,
      "step": 9460
    },
    {
      "epoch": 1.1248366789404918,
      "grad_norm": 6.647456645965576,
      "learning_rate": 3.188391162095569e-05,
      "loss": 0.2732,
      "step": 9470
    },
    {
      "epoch": 1.126024468464188,
      "grad_norm": 17.990156173706055,
      "learning_rate": 3.1863715312840817e-05,
      "loss": 0.3311,
      "step": 9480
    },
    {
      "epoch": 1.1272122579878845,
      "grad_norm": 44.993675231933594,
      "learning_rate": 3.1843519004725935e-05,
      "loss": 0.3625,
      "step": 9490
    },
    {
      "epoch": 1.128400047511581,
      "grad_norm": 0.3173900246620178,
      "learning_rate": 3.182332269661106e-05,
      "loss": 0.164,
      "step": 9500
    },
    {
      "epoch": 1.1295878370352774,
      "grad_norm": 1.349674105644226,
      "learning_rate": 3.1803126388496186e-05,
      "loss": 0.4217,
      "step": 9510
    },
    {
      "epoch": 1.1307756265589737,
      "grad_norm": 30.59409523010254,
      "learning_rate": 3.1782930080381305e-05,
      "loss": 0.4676,
      "step": 9520
    },
    {
      "epoch": 1.1319634160826701,
      "grad_norm": 0.8903564810752869,
      "learning_rate": 3.176273377226643e-05,
      "loss": 0.347,
      "step": 9530
    },
    {
      "epoch": 1.1331512056063666,
      "grad_norm": 1.7182934284210205,
      "learning_rate": 3.1742537464151555e-05,
      "loss": 0.2146,
      "step": 9540
    },
    {
      "epoch": 1.1343389951300629,
      "grad_norm": 0.749564528465271,
      "learning_rate": 3.172234115603668e-05,
      "loss": 0.4871,
      "step": 9550
    },
    {
      "epoch": 1.1355267846537593,
      "grad_norm": 38.82373046875,
      "learning_rate": 3.17021448479218e-05,
      "loss": 0.3191,
      "step": 9560
    },
    {
      "epoch": 1.1367145741774558,
      "grad_norm": 23.047704696655273,
      "learning_rate": 3.1681948539806925e-05,
      "loss": 0.4294,
      "step": 9570
    },
    {
      "epoch": 1.1379023637011523,
      "grad_norm": 19.877634048461914,
      "learning_rate": 3.166175223169205e-05,
      "loss": 0.2445,
      "step": 9580
    },
    {
      "epoch": 1.1390901532248485,
      "grad_norm": 39.9615592956543,
      "learning_rate": 3.164155592357717e-05,
      "loss": 0.2474,
      "step": 9590
    },
    {
      "epoch": 1.140277942748545,
      "grad_norm": 14.63604736328125,
      "learning_rate": 3.1621359615462294e-05,
      "loss": 0.2689,
      "step": 9600
    },
    {
      "epoch": 1.1414657322722412,
      "grad_norm": 52.347145080566406,
      "learning_rate": 3.160116330734742e-05,
      "loss": 0.4282,
      "step": 9610
    },
    {
      "epoch": 1.1426535217959377,
      "grad_norm": 2.8573832511901855,
      "learning_rate": 3.1580966999232545e-05,
      "loss": 0.3188,
      "step": 9620
    },
    {
      "epoch": 1.1438413113196342,
      "grad_norm": 0.4711298942565918,
      "learning_rate": 3.1560770691117664e-05,
      "loss": 0.261,
      "step": 9630
    },
    {
      "epoch": 1.1450291008433306,
      "grad_norm": 30.658910751342773,
      "learning_rate": 3.154057438300279e-05,
      "loss": 0.326,
      "step": 9640
    },
    {
      "epoch": 1.146216890367027,
      "grad_norm": 6.865245342254639,
      "learning_rate": 3.1520378074887915e-05,
      "loss": 0.7415,
      "step": 9650
    },
    {
      "epoch": 1.1474046798907234,
      "grad_norm": 0.21402764320373535,
      "learning_rate": 3.150018176677303e-05,
      "loss": 0.1568,
      "step": 9660
    },
    {
      "epoch": 1.1485924694144198,
      "grad_norm": 15.353822708129883,
      "learning_rate": 3.147998545865816e-05,
      "loss": 0.3042,
      "step": 9670
    },
    {
      "epoch": 1.149780258938116,
      "grad_norm": 1.4556572437286377,
      "learning_rate": 3.1459789150543284e-05,
      "loss": 0.2543,
      "step": 9680
    },
    {
      "epoch": 1.1509680484618126,
      "grad_norm": 3.4043922424316406,
      "learning_rate": 3.14395928424284e-05,
      "loss": 0.1722,
      "step": 9690
    },
    {
      "epoch": 1.152155837985509,
      "grad_norm": 20.956226348876953,
      "learning_rate": 3.141939653431353e-05,
      "loss": 0.2717,
      "step": 9700
    },
    {
      "epoch": 1.1533436275092055,
      "grad_norm": 8.912738800048828,
      "learning_rate": 3.1399200226198654e-05,
      "loss": 0.303,
      "step": 9710
    },
    {
      "epoch": 1.1545314170329017,
      "grad_norm": 3.2548158168792725,
      "learning_rate": 3.137900391808378e-05,
      "loss": 0.3802,
      "step": 9720
    },
    {
      "epoch": 1.1557192065565982,
      "grad_norm": 5.492048740386963,
      "learning_rate": 3.13588076099689e-05,
      "loss": 0.3048,
      "step": 9730
    },
    {
      "epoch": 1.1569069960802945,
      "grad_norm": 0.8162797093391418,
      "learning_rate": 3.133861130185402e-05,
      "loss": 0.2417,
      "step": 9740
    },
    {
      "epoch": 1.158094785603991,
      "grad_norm": 30.460174560546875,
      "learning_rate": 3.131841499373915e-05,
      "loss": 0.231,
      "step": 9750
    },
    {
      "epoch": 1.1592825751276874,
      "grad_norm": 16.234710693359375,
      "learning_rate": 3.129821868562427e-05,
      "loss": 0.3309,
      "step": 9760
    },
    {
      "epoch": 1.1604703646513839,
      "grad_norm": 18.435483932495117,
      "learning_rate": 3.127802237750939e-05,
      "loss": 0.462,
      "step": 9770
    },
    {
      "epoch": 1.1616581541750801,
      "grad_norm": 9.140511512756348,
      "learning_rate": 3.125782606939451e-05,
      "loss": 0.4197,
      "step": 9780
    },
    {
      "epoch": 1.1628459436987766,
      "grad_norm": 24.94198226928711,
      "learning_rate": 3.123762976127964e-05,
      "loss": 0.3528,
      "step": 9790
    },
    {
      "epoch": 1.164033733222473,
      "grad_norm": 6.616217136383057,
      "learning_rate": 3.121743345316476e-05,
      "loss": 0.349,
      "step": 9800
    },
    {
      "epoch": 1.1652215227461693,
      "grad_norm": 0.3510296940803528,
      "learning_rate": 3.119723714504989e-05,
      "loss": 0.341,
      "step": 9810
    },
    {
      "epoch": 1.1664093122698658,
      "grad_norm": 0.49245038628578186,
      "learning_rate": 3.117704083693501e-05,
      "loss": 0.2206,
      "step": 9820
    },
    {
      "epoch": 1.1675971017935622,
      "grad_norm": 20.929969787597656,
      "learning_rate": 3.115684452882013e-05,
      "loss": 0.2412,
      "step": 9830
    },
    {
      "epoch": 1.1687848913172585,
      "grad_norm": 12.173144340515137,
      "learning_rate": 3.113664822070526e-05,
      "loss": 0.4495,
      "step": 9840
    },
    {
      "epoch": 1.169972680840955,
      "grad_norm": 11.883950233459473,
      "learning_rate": 3.1116451912590375e-05,
      "loss": 0.2978,
      "step": 9850
    },
    {
      "epoch": 1.1711604703646514,
      "grad_norm": 2.016188859939575,
      "learning_rate": 3.109625560447551e-05,
      "loss": 0.3978,
      "step": 9860
    },
    {
      "epoch": 1.1723482598883477,
      "grad_norm": 1.6014047861099243,
      "learning_rate": 3.1076059296360626e-05,
      "loss": 0.1507,
      "step": 9870
    },
    {
      "epoch": 1.1735360494120441,
      "grad_norm": 18.30937385559082,
      "learning_rate": 3.105586298824575e-05,
      "loss": 0.2026,
      "step": 9880
    },
    {
      "epoch": 1.1747238389357406,
      "grad_norm": 15.356085777282715,
      "learning_rate": 3.103566668013088e-05,
      "loss": 0.5074,
      "step": 9890
    },
    {
      "epoch": 1.175911628459437,
      "grad_norm": 1.911328911781311,
      "learning_rate": 3.1015470372015996e-05,
      "loss": 0.2254,
      "step": 9900
    },
    {
      "epoch": 1.1770994179831333,
      "grad_norm": 23.667343139648438,
      "learning_rate": 3.099527406390112e-05,
      "loss": 0.3042,
      "step": 9910
    },
    {
      "epoch": 1.1782872075068298,
      "grad_norm": 21.44178581237793,
      "learning_rate": 3.097507775578624e-05,
      "loss": 0.1306,
      "step": 9920
    },
    {
      "epoch": 1.1794749970305263,
      "grad_norm": 20.67034339904785,
      "learning_rate": 3.095488144767137e-05,
      "loss": 0.2653,
      "step": 9930
    },
    {
      "epoch": 1.1806627865542225,
      "grad_norm": 15.577522277832031,
      "learning_rate": 3.093468513955649e-05,
      "loss": 0.2328,
      "step": 9940
    },
    {
      "epoch": 1.181850576077919,
      "grad_norm": 0.8665529489517212,
      "learning_rate": 3.0914488831441616e-05,
      "loss": 0.3376,
      "step": 9950
    },
    {
      "epoch": 1.1830383656016155,
      "grad_norm": 6.881502151489258,
      "learning_rate": 3.089429252332674e-05,
      "loss": 0.5046,
      "step": 9960
    },
    {
      "epoch": 1.1842261551253117,
      "grad_norm": 20.77254295349121,
      "learning_rate": 3.087409621521186e-05,
      "loss": 0.2968,
      "step": 9970
    },
    {
      "epoch": 1.1854139446490082,
      "grad_norm": 1.0917201042175293,
      "learning_rate": 3.0853899907096985e-05,
      "loss": 0.2636,
      "step": 9980
    },
    {
      "epoch": 1.1866017341727046,
      "grad_norm": 2.3638315200805664,
      "learning_rate": 3.0833703598982104e-05,
      "loss": 0.2366,
      "step": 9990
    },
    {
      "epoch": 1.187789523696401,
      "grad_norm": 2.7327263355255127,
      "learning_rate": 3.0813507290867236e-05,
      "loss": 0.2908,
      "step": 10000
    },
    {
      "epoch": 1.1889773132200974,
      "grad_norm": 0.1804804503917694,
      "learning_rate": 3.0793310982752355e-05,
      "loss": 0.2348,
      "step": 10010
    },
    {
      "epoch": 1.1901651027437938,
      "grad_norm": 2.5997679233551025,
      "learning_rate": 3.0773114674637473e-05,
      "loss": 0.2156,
      "step": 10020
    },
    {
      "epoch": 1.1913528922674903,
      "grad_norm": 19.831008911132812,
      "learning_rate": 3.07529183665226e-05,
      "loss": 0.3493,
      "step": 10030
    },
    {
      "epoch": 1.1925406817911866,
      "grad_norm": 13.308206558227539,
      "learning_rate": 3.0732722058407724e-05,
      "loss": 0.2773,
      "step": 10040
    },
    {
      "epoch": 1.193728471314883,
      "grad_norm": 47.03755569458008,
      "learning_rate": 3.071252575029285e-05,
      "loss": 0.361,
      "step": 10050
    },
    {
      "epoch": 1.1949162608385795,
      "grad_norm": 12.779474258422852,
      "learning_rate": 3.069232944217797e-05,
      "loss": 0.3918,
      "step": 10060
    },
    {
      "epoch": 1.1961040503622757,
      "grad_norm": 21.019207000732422,
      "learning_rate": 3.0672133134063094e-05,
      "loss": 0.3697,
      "step": 10070
    },
    {
      "epoch": 1.1972918398859722,
      "grad_norm": 1.1054086685180664,
      "learning_rate": 3.065193682594822e-05,
      "loss": 0.1696,
      "step": 10080
    },
    {
      "epoch": 1.1984796294096687,
      "grad_norm": 9.555584907531738,
      "learning_rate": 3.063174051783334e-05,
      "loss": 0.1831,
      "step": 10090
    },
    {
      "epoch": 1.199667418933365,
      "grad_norm": 29.748477935791016,
      "learning_rate": 3.061154420971846e-05,
      "loss": 0.2295,
      "step": 10100
    },
    {
      "epoch": 1.2008552084570614,
      "grad_norm": 10.344868659973145,
      "learning_rate": 3.059134790160359e-05,
      "loss": 0.3958,
      "step": 10110
    },
    {
      "epoch": 1.2020429979807579,
      "grad_norm": 7.720113277435303,
      "learning_rate": 3.0571151593488714e-05,
      "loss": 0.3077,
      "step": 10120
    },
    {
      "epoch": 1.2032307875044541,
      "grad_norm": 19.26154899597168,
      "learning_rate": 3.055095528537383e-05,
      "loss": 0.3624,
      "step": 10130
    },
    {
      "epoch": 1.2044185770281506,
      "grad_norm": 12.667948722839355,
      "learning_rate": 3.053075897725896e-05,
      "loss": 0.2655,
      "step": 10140
    },
    {
      "epoch": 1.205606366551847,
      "grad_norm": 11.308798789978027,
      "learning_rate": 3.0510562669144083e-05,
      "loss": 0.3749,
      "step": 10150
    },
    {
      "epoch": 1.2067941560755435,
      "grad_norm": 2.610124111175537,
      "learning_rate": 3.0490366361029205e-05,
      "loss": 0.2516,
      "step": 10160
    },
    {
      "epoch": 1.2079819455992398,
      "grad_norm": 1.2966300249099731,
      "learning_rate": 3.0470170052914327e-05,
      "loss": 0.1077,
      "step": 10170
    },
    {
      "epoch": 1.2091697351229362,
      "grad_norm": 3.8031976222991943,
      "learning_rate": 3.0449973744799453e-05,
      "loss": 0.1924,
      "step": 10180
    },
    {
      "epoch": 1.2103575246466327,
      "grad_norm": 6.5902533531188965,
      "learning_rate": 3.0429777436684575e-05,
      "loss": 0.4168,
      "step": 10190
    },
    {
      "epoch": 1.211545314170329,
      "grad_norm": 11.885108947753906,
      "learning_rate": 3.0409581128569697e-05,
      "loss": 0.1929,
      "step": 10200
    },
    {
      "epoch": 1.2127331036940254,
      "grad_norm": 3.1456751823425293,
      "learning_rate": 3.0389384820454826e-05,
      "loss": 0.3159,
      "step": 10210
    },
    {
      "epoch": 1.213920893217722,
      "grad_norm": 20.372827529907227,
      "learning_rate": 3.0369188512339948e-05,
      "loss": 0.2699,
      "step": 10220
    },
    {
      "epoch": 1.2151086827414181,
      "grad_norm": 0.5489070415496826,
      "learning_rate": 3.034899220422507e-05,
      "loss": 0.1921,
      "step": 10230
    },
    {
      "epoch": 1.2162964722651146,
      "grad_norm": 3.10036563873291,
      "learning_rate": 3.0328795896110192e-05,
      "loss": 0.2833,
      "step": 10240
    },
    {
      "epoch": 1.217484261788811,
      "grad_norm": 0.45338308811187744,
      "learning_rate": 3.0308599587995317e-05,
      "loss": 0.2161,
      "step": 10250
    },
    {
      "epoch": 1.2186720513125073,
      "grad_norm": 24.640092849731445,
      "learning_rate": 3.028840327988044e-05,
      "loss": 0.3187,
      "step": 10260
    },
    {
      "epoch": 1.2198598408362038,
      "grad_norm": 37.22792434692383,
      "learning_rate": 3.026820697176556e-05,
      "loss": 0.4201,
      "step": 10270
    },
    {
      "epoch": 1.2210476303599003,
      "grad_norm": 0.12918585538864136,
      "learning_rate": 3.024801066365069e-05,
      "loss": 0.1337,
      "step": 10280
    },
    {
      "epoch": 1.2222354198835967,
      "grad_norm": 3.754275321960449,
      "learning_rate": 3.0227814355535812e-05,
      "loss": 0.2835,
      "step": 10290
    },
    {
      "epoch": 1.223423209407293,
      "grad_norm": 33.297794342041016,
      "learning_rate": 3.0207618047420934e-05,
      "loss": 0.3595,
      "step": 10300
    },
    {
      "epoch": 1.2246109989309895,
      "grad_norm": 19.925588607788086,
      "learning_rate": 3.0187421739306053e-05,
      "loss": 0.4294,
      "step": 10310
    },
    {
      "epoch": 1.2257987884546857,
      "grad_norm": 35.953365325927734,
      "learning_rate": 3.016722543119118e-05,
      "loss": 0.3613,
      "step": 10320
    },
    {
      "epoch": 1.2269865779783822,
      "grad_norm": 20.5725040435791,
      "learning_rate": 3.0147029123076304e-05,
      "loss": 0.2439,
      "step": 10330
    },
    {
      "epoch": 1.2281743675020786,
      "grad_norm": 18.012985229492188,
      "learning_rate": 3.0126832814961426e-05,
      "loss": 0.2576,
      "step": 10340
    },
    {
      "epoch": 1.2293621570257751,
      "grad_norm": 2.6987133026123047,
      "learning_rate": 3.0106636506846548e-05,
      "loss": 0.3309,
      "step": 10350
    },
    {
      "epoch": 1.2305499465494714,
      "grad_norm": 12.842037200927734,
      "learning_rate": 3.0086440198731673e-05,
      "loss": 0.3444,
      "step": 10360
    },
    {
      "epoch": 1.2317377360731678,
      "grad_norm": 1.7603651285171509,
      "learning_rate": 3.0066243890616795e-05,
      "loss": 0.3773,
      "step": 10370
    },
    {
      "epoch": 1.2329255255968643,
      "grad_norm": 13.529601097106934,
      "learning_rate": 3.0046047582501917e-05,
      "loss": 0.1699,
      "step": 10380
    },
    {
      "epoch": 1.2341133151205606,
      "grad_norm": 13.369104385375977,
      "learning_rate": 3.0025851274387046e-05,
      "loss": 0.2812,
      "step": 10390
    },
    {
      "epoch": 1.235301104644257,
      "grad_norm": 14.01528549194336,
      "learning_rate": 3.0005654966272168e-05,
      "loss": 0.4411,
      "step": 10400
    },
    {
      "epoch": 1.2364888941679535,
      "grad_norm": 26.552459716796875,
      "learning_rate": 2.998545865815729e-05,
      "loss": 0.1949,
      "step": 10410
    },
    {
      "epoch": 1.23767668369165,
      "grad_norm": 21.409639358520508,
      "learning_rate": 2.9965262350042412e-05,
      "loss": 0.3991,
      "step": 10420
    },
    {
      "epoch": 1.2388644732153462,
      "grad_norm": 0.27896806597709656,
      "learning_rate": 2.9945066041927537e-05,
      "loss": 0.3087,
      "step": 10430
    },
    {
      "epoch": 1.2400522627390427,
      "grad_norm": 0.1527291089296341,
      "learning_rate": 2.992486973381266e-05,
      "loss": 0.2989,
      "step": 10440
    },
    {
      "epoch": 1.241240052262739,
      "grad_norm": 11.166529655456543,
      "learning_rate": 2.990467342569778e-05,
      "loss": 0.3101,
      "step": 10450
    },
    {
      "epoch": 1.2424278417864354,
      "grad_norm": 2.6338722705841064,
      "learning_rate": 2.988447711758291e-05,
      "loss": 0.1271,
      "step": 10460
    },
    {
      "epoch": 1.2436156313101319,
      "grad_norm": 1.2567604780197144,
      "learning_rate": 2.9864280809468032e-05,
      "loss": 0.3124,
      "step": 10470
    },
    {
      "epoch": 1.2448034208338283,
      "grad_norm": 14.758538246154785,
      "learning_rate": 2.9844084501353154e-05,
      "loss": 0.3756,
      "step": 10480
    },
    {
      "epoch": 1.2459912103575246,
      "grad_norm": 2.436565399169922,
      "learning_rate": 2.9823888193238276e-05,
      "loss": 0.3254,
      "step": 10490
    },
    {
      "epoch": 1.247178999881221,
      "grad_norm": 1.364513635635376,
      "learning_rate": 2.98036918851234e-05,
      "loss": 0.1963,
      "step": 10500
    },
    {
      "epoch": 1.2483667894049175,
      "grad_norm": 0.6360008716583252,
      "learning_rate": 2.9783495577008524e-05,
      "loss": 0.2549,
      "step": 10510
    },
    {
      "epoch": 1.2495545789286138,
      "grad_norm": 38.1715087890625,
      "learning_rate": 2.9763299268893646e-05,
      "loss": 0.3506,
      "step": 10520
    },
    {
      "epoch": 1.2507423684523102,
      "grad_norm": 27.737104415893555,
      "learning_rate": 2.9743102960778774e-05,
      "loss": 0.3768,
      "step": 10530
    },
    {
      "epoch": 1.2519301579760067,
      "grad_norm": 10.629215240478516,
      "learning_rate": 2.9722906652663896e-05,
      "loss": 0.2691,
      "step": 10540
    },
    {
      "epoch": 1.2531179474997032,
      "grad_norm": 21.080615997314453,
      "learning_rate": 2.970271034454902e-05,
      "loss": 0.2526,
      "step": 10550
    },
    {
      "epoch": 1.2543057370233994,
      "grad_norm": 56.57893753051758,
      "learning_rate": 2.968251403643414e-05,
      "loss": 0.2715,
      "step": 10560
    },
    {
      "epoch": 1.255493526547096,
      "grad_norm": 0.28986865282058716,
      "learning_rate": 2.9662317728319266e-05,
      "loss": 0.1476,
      "step": 10570
    },
    {
      "epoch": 1.2566813160707921,
      "grad_norm": 6.930875778198242,
      "learning_rate": 2.9642121420204388e-05,
      "loss": 0.3022,
      "step": 10580
    },
    {
      "epoch": 1.2578691055944886,
      "grad_norm": 0.7017906904220581,
      "learning_rate": 2.962192511208951e-05,
      "loss": 0.343,
      "step": 10590
    },
    {
      "epoch": 1.259056895118185,
      "grad_norm": 8.276020050048828,
      "learning_rate": 2.9601728803974632e-05,
      "loss": 0.4427,
      "step": 10600
    },
    {
      "epoch": 1.2602446846418816,
      "grad_norm": 4.898797988891602,
      "learning_rate": 2.958153249585976e-05,
      "loss": 0.1859,
      "step": 10610
    },
    {
      "epoch": 1.2614324741655778,
      "grad_norm": 18.595829010009766,
      "learning_rate": 2.9561336187744883e-05,
      "loss": 0.2988,
      "step": 10620
    },
    {
      "epoch": 1.2626202636892743,
      "grad_norm": 12.316645622253418,
      "learning_rate": 2.9541139879630005e-05,
      "loss": 0.3363,
      "step": 10630
    },
    {
      "epoch": 1.2638080532129707,
      "grad_norm": 38.76258850097656,
      "learning_rate": 2.952094357151513e-05,
      "loss": 0.1537,
      "step": 10640
    },
    {
      "epoch": 1.264995842736667,
      "grad_norm": 1.3497314453125,
      "learning_rate": 2.9500747263400252e-05,
      "loss": 0.2799,
      "step": 10650
    },
    {
      "epoch": 1.2661836322603635,
      "grad_norm": 15.9502592086792,
      "learning_rate": 2.9480550955285374e-05,
      "loss": 0.4527,
      "step": 10660
    },
    {
      "epoch": 1.26737142178406,
      "grad_norm": 0.4126391112804413,
      "learning_rate": 2.9460354647170496e-05,
      "loss": 0.1665,
      "step": 10670
    },
    {
      "epoch": 1.2685592113077564,
      "grad_norm": 0.5061984658241272,
      "learning_rate": 2.9440158339055625e-05,
      "loss": 0.2724,
      "step": 10680
    },
    {
      "epoch": 1.2697470008314526,
      "grad_norm": 9.535811424255371,
      "learning_rate": 2.9419962030940744e-05,
      "loss": 0.2277,
      "step": 10690
    },
    {
      "epoch": 1.2709347903551491,
      "grad_norm": 1.1860147714614868,
      "learning_rate": 2.9399765722825866e-05,
      "loss": 0.0651,
      "step": 10700
    },
    {
      "epoch": 1.2721225798788454,
      "grad_norm": 2.263975143432617,
      "learning_rate": 2.9379569414710994e-05,
      "loss": 0.2795,
      "step": 10710
    },
    {
      "epoch": 1.2733103694025418,
      "grad_norm": 21.65612030029297,
      "learning_rate": 2.9359373106596117e-05,
      "loss": 0.4803,
      "step": 10720
    },
    {
      "epoch": 1.2744981589262383,
      "grad_norm": 17.81829833984375,
      "learning_rate": 2.933917679848124e-05,
      "loss": 0.3888,
      "step": 10730
    },
    {
      "epoch": 1.2756859484499348,
      "grad_norm": 23.26875877380371,
      "learning_rate": 2.931898049036636e-05,
      "loss": 0.3559,
      "step": 10740
    },
    {
      "epoch": 1.276873737973631,
      "grad_norm": 12.530683517456055,
      "learning_rate": 2.9298784182251486e-05,
      "loss": 0.2738,
      "step": 10750
    },
    {
      "epoch": 1.2780615274973275,
      "grad_norm": 34.22443771362305,
      "learning_rate": 2.9278587874136608e-05,
      "loss": 0.3839,
      "step": 10760
    },
    {
      "epoch": 1.279249317021024,
      "grad_norm": 2.860018014907837,
      "learning_rate": 2.925839156602173e-05,
      "loss": 0.3677,
      "step": 10770
    },
    {
      "epoch": 1.2804371065447202,
      "grad_norm": 0.2870716452598572,
      "learning_rate": 2.923819525790686e-05,
      "loss": 0.3163,
      "step": 10780
    },
    {
      "epoch": 1.2816248960684167,
      "grad_norm": 11.855289459228516,
      "learning_rate": 2.921799894979198e-05,
      "loss": 0.1579,
      "step": 10790
    },
    {
      "epoch": 1.2828126855921131,
      "grad_norm": 2.244852304458618,
      "learning_rate": 2.9197802641677103e-05,
      "loss": 0.2322,
      "step": 10800
    },
    {
      "epoch": 1.2840004751158096,
      "grad_norm": 4.215865135192871,
      "learning_rate": 2.9177606333562225e-05,
      "loss": 0.3195,
      "step": 10810
    },
    {
      "epoch": 1.2851882646395059,
      "grad_norm": 0.694185733795166,
      "learning_rate": 2.915741002544735e-05,
      "loss": 0.3338,
      "step": 10820
    },
    {
      "epoch": 1.2863760541632023,
      "grad_norm": 0.1967315673828125,
      "learning_rate": 2.9137213717332472e-05,
      "loss": 0.1214,
      "step": 10830
    },
    {
      "epoch": 1.2875638436868986,
      "grad_norm": 32.36836242675781,
      "learning_rate": 2.9117017409217594e-05,
      "loss": 0.2011,
      "step": 10840
    },
    {
      "epoch": 1.288751633210595,
      "grad_norm": 11.381983757019043,
      "learning_rate": 2.9096821101102723e-05,
      "loss": 0.4123,
      "step": 10850
    },
    {
      "epoch": 1.2899394227342915,
      "grad_norm": 0.31010502576828003,
      "learning_rate": 2.9076624792987845e-05,
      "loss": 0.3874,
      "step": 10860
    },
    {
      "epoch": 1.291127212257988,
      "grad_norm": 1.3096415996551514,
      "learning_rate": 2.9056428484872967e-05,
      "loss": 0.2547,
      "step": 10870
    },
    {
      "epoch": 1.2923150017816842,
      "grad_norm": 0.129969984292984,
      "learning_rate": 2.903623217675809e-05,
      "loss": 0.3553,
      "step": 10880
    },
    {
      "epoch": 1.2935027913053807,
      "grad_norm": 0.5006138682365417,
      "learning_rate": 2.9016035868643215e-05,
      "loss": 0.4021,
      "step": 10890
    },
    {
      "epoch": 1.294690580829077,
      "grad_norm": 10.329758644104004,
      "learning_rate": 2.8995839560528337e-05,
      "loss": 0.4551,
      "step": 10900
    },
    {
      "epoch": 1.2958783703527734,
      "grad_norm": 21.828428268432617,
      "learning_rate": 2.897564325241346e-05,
      "loss": 0.1724,
      "step": 10910
    },
    {
      "epoch": 1.29706615987647,
      "grad_norm": 9.03077220916748,
      "learning_rate": 2.895544694429858e-05,
      "loss": 0.3537,
      "step": 10920
    },
    {
      "epoch": 1.2982539494001664,
      "grad_norm": 4.29155969619751,
      "learning_rate": 2.893525063618371e-05,
      "loss": 0.3398,
      "step": 10930
    },
    {
      "epoch": 1.2994417389238626,
      "grad_norm": 29.84624671936035,
      "learning_rate": 2.891505432806883e-05,
      "loss": 0.4772,
      "step": 10940
    },
    {
      "epoch": 1.300629528447559,
      "grad_norm": 25.489913940429688,
      "learning_rate": 2.8894858019953953e-05,
      "loss": 0.3184,
      "step": 10950
    },
    {
      "epoch": 1.3018173179712555,
      "grad_norm": 5.170255184173584,
      "learning_rate": 2.887466171183908e-05,
      "loss": 0.3058,
      "step": 10960
    },
    {
      "epoch": 1.3030051074949518,
      "grad_norm": 2.9381511211395264,
      "learning_rate": 2.88544654037242e-05,
      "loss": 0.2134,
      "step": 10970
    },
    {
      "epoch": 1.3041928970186483,
      "grad_norm": 0.5709607601165771,
      "learning_rate": 2.8834269095609323e-05,
      "loss": 0.283,
      "step": 10980
    },
    {
      "epoch": 1.3053806865423447,
      "grad_norm": 14.82340145111084,
      "learning_rate": 2.8814072787494445e-05,
      "loss": 0.2656,
      "step": 10990
    },
    {
      "epoch": 1.3065684760660412,
      "grad_norm": 42.40926742553711,
      "learning_rate": 2.8793876479379574e-05,
      "loss": 0.4612,
      "step": 11000
    },
    {
      "epoch": 1.3077562655897375,
      "grad_norm": 22.875646591186523,
      "learning_rate": 2.8773680171264696e-05,
      "loss": 0.4397,
      "step": 11010
    },
    {
      "epoch": 1.308944055113434,
      "grad_norm": 19.801799774169922,
      "learning_rate": 2.8753483863149814e-05,
      "loss": 0.285,
      "step": 11020
    },
    {
      "epoch": 1.3101318446371302,
      "grad_norm": 21.268848419189453,
      "learning_rate": 2.8733287555034943e-05,
      "loss": 0.3294,
      "step": 11030
    },
    {
      "epoch": 1.3113196341608266,
      "grad_norm": 11.826160430908203,
      "learning_rate": 2.8713091246920065e-05,
      "loss": 0.2945,
      "step": 11040
    },
    {
      "epoch": 1.3125074236845231,
      "grad_norm": 12.864595413208008,
      "learning_rate": 2.8692894938805187e-05,
      "loss": 0.1557,
      "step": 11050
    },
    {
      "epoch": 1.3136952132082196,
      "grad_norm": 0.40874621272087097,
      "learning_rate": 2.867269863069031e-05,
      "loss": 0.2204,
      "step": 11060
    },
    {
      "epoch": 1.3148830027319158,
      "grad_norm": 0.4464448094367981,
      "learning_rate": 2.8652502322575435e-05,
      "loss": 0.4,
      "step": 11070
    },
    {
      "epoch": 1.3160707922556123,
      "grad_norm": 17.232940673828125,
      "learning_rate": 2.8632306014460557e-05,
      "loss": 0.322,
      "step": 11080
    },
    {
      "epoch": 1.3172585817793088,
      "grad_norm": 19.70979881286621,
      "learning_rate": 2.861210970634568e-05,
      "loss": 0.4392,
      "step": 11090
    },
    {
      "epoch": 1.318446371303005,
      "grad_norm": 9.317924499511719,
      "learning_rate": 2.8591913398230807e-05,
      "loss": 0.1617,
      "step": 11100
    },
    {
      "epoch": 1.3196341608267015,
      "grad_norm": 31.84865951538086,
      "learning_rate": 2.857171709011593e-05,
      "loss": 0.3096,
      "step": 11110
    },
    {
      "epoch": 1.320821950350398,
      "grad_norm": 20.478185653686523,
      "learning_rate": 2.855152078200105e-05,
      "loss": 0.3132,
      "step": 11120
    },
    {
      "epoch": 1.3220097398740944,
      "grad_norm": 9.14892864227295,
      "learning_rate": 2.8531324473886174e-05,
      "loss": 0.371,
      "step": 11130
    },
    {
      "epoch": 1.3231975293977907,
      "grad_norm": 11.183612823486328,
      "learning_rate": 2.85111281657713e-05,
      "loss": 0.1196,
      "step": 11140
    },
    {
      "epoch": 1.3243853189214871,
      "grad_norm": 21.888355255126953,
      "learning_rate": 2.849093185765642e-05,
      "loss": 0.3824,
      "step": 11150
    },
    {
      "epoch": 1.3255731084451834,
      "grad_norm": 6.5146803855896,
      "learning_rate": 2.8470735549541543e-05,
      "loss": 0.2581,
      "step": 11160
    },
    {
      "epoch": 1.3267608979688799,
      "grad_norm": 10.006038665771484,
      "learning_rate": 2.8450539241426665e-05,
      "loss": 0.1675,
      "step": 11170
    },
    {
      "epoch": 1.3279486874925763,
      "grad_norm": 2.8236451148986816,
      "learning_rate": 2.8430342933311794e-05,
      "loss": 0.2099,
      "step": 11180
    },
    {
      "epoch": 1.3291364770162728,
      "grad_norm": 0.5033746957778931,
      "learning_rate": 2.8410146625196916e-05,
      "loss": 0.2229,
      "step": 11190
    },
    {
      "epoch": 1.330324266539969,
      "grad_norm": 2.1612043380737305,
      "learning_rate": 2.8389950317082038e-05,
      "loss": 0.038,
      "step": 11200
    },
    {
      "epoch": 1.3315120560636655,
      "grad_norm": 14.94909954071045,
      "learning_rate": 2.8369754008967163e-05,
      "loss": 0.326,
      "step": 11210
    },
    {
      "epoch": 1.332699845587362,
      "grad_norm": 0.1609950065612793,
      "learning_rate": 2.8349557700852285e-05,
      "loss": 0.2854,
      "step": 11220
    },
    {
      "epoch": 1.3338876351110582,
      "grad_norm": 41.14449691772461,
      "learning_rate": 2.8329361392737407e-05,
      "loss": 0.4874,
      "step": 11230
    },
    {
      "epoch": 1.3350754246347547,
      "grad_norm": 1.8009415864944458,
      "learning_rate": 2.830916508462253e-05,
      "loss": 0.3307,
      "step": 11240
    },
    {
      "epoch": 1.3362632141584512,
      "grad_norm": 24.767791748046875,
      "learning_rate": 2.8288968776507658e-05,
      "loss": 0.4402,
      "step": 11250
    },
    {
      "epoch": 1.3374510036821476,
      "grad_norm": 39.63792419433594,
      "learning_rate": 2.826877246839278e-05,
      "loss": 0.2684,
      "step": 11260
    },
    {
      "epoch": 1.338638793205844,
      "grad_norm": 0.3303332030773163,
      "learning_rate": 2.8248576160277902e-05,
      "loss": 0.4985,
      "step": 11270
    },
    {
      "epoch": 1.3398265827295404,
      "grad_norm": 14.146836280822754,
      "learning_rate": 2.8228379852163028e-05,
      "loss": 0.1909,
      "step": 11280
    },
    {
      "epoch": 1.3410143722532366,
      "grad_norm": 15.840417861938477,
      "learning_rate": 2.820818354404815e-05,
      "loss": 0.3859,
      "step": 11290
    },
    {
      "epoch": 1.342202161776933,
      "grad_norm": 1.3333677053451538,
      "learning_rate": 2.818798723593327e-05,
      "loss": 0.2628,
      "step": 11300
    },
    {
      "epoch": 1.3433899513006295,
      "grad_norm": 14.765963554382324,
      "learning_rate": 2.8167790927818394e-05,
      "loss": 0.2762,
      "step": 11310
    },
    {
      "epoch": 1.344577740824326,
      "grad_norm": 19.082204818725586,
      "learning_rate": 2.8147594619703522e-05,
      "loss": 0.2045,
      "step": 11320
    },
    {
      "epoch": 1.3457655303480223,
      "grad_norm": 25.854448318481445,
      "learning_rate": 2.8127398311588644e-05,
      "loss": 0.2422,
      "step": 11330
    },
    {
      "epoch": 1.3469533198717187,
      "grad_norm": 0.7006480693817139,
      "learning_rate": 2.8107202003473766e-05,
      "loss": 0.3932,
      "step": 11340
    },
    {
      "epoch": 1.3481411093954152,
      "grad_norm": 5.580587863922119,
      "learning_rate": 2.8087005695358892e-05,
      "loss": 0.2215,
      "step": 11350
    },
    {
      "epoch": 1.3493288989191115,
      "grad_norm": 30.196338653564453,
      "learning_rate": 2.8066809387244014e-05,
      "loss": 0.3906,
      "step": 11360
    },
    {
      "epoch": 1.350516688442808,
      "grad_norm": 1.555072546005249,
      "learning_rate": 2.8046613079129136e-05,
      "loss": 0.3371,
      "step": 11370
    },
    {
      "epoch": 1.3517044779665044,
      "grad_norm": 0.3468671441078186,
      "learning_rate": 2.8026416771014258e-05,
      "loss": 0.1836,
      "step": 11380
    },
    {
      "epoch": 1.3528922674902009,
      "grad_norm": 1.724274754524231,
      "learning_rate": 2.8006220462899387e-05,
      "loss": 0.3999,
      "step": 11390
    },
    {
      "epoch": 1.354080057013897,
      "grad_norm": 8.761119842529297,
      "learning_rate": 2.7986024154784505e-05,
      "loss": 0.2222,
      "step": 11400
    },
    {
      "epoch": 1.3552678465375936,
      "grad_norm": 10.46484375,
      "learning_rate": 2.7965827846669627e-05,
      "loss": 0.2574,
      "step": 11410
    },
    {
      "epoch": 1.3564556360612898,
      "grad_norm": 6.8641486167907715,
      "learning_rate": 2.7945631538554756e-05,
      "loss": 0.2922,
      "step": 11420
    },
    {
      "epoch": 1.3576434255849863,
      "grad_norm": 26.723037719726562,
      "learning_rate": 2.7925435230439878e-05,
      "loss": 0.2693,
      "step": 11430
    },
    {
      "epoch": 1.3588312151086828,
      "grad_norm": 4.2224249839782715,
      "learning_rate": 2.7905238922325e-05,
      "loss": 0.2753,
      "step": 11440
    },
    {
      "epoch": 1.3600190046323792,
      "grad_norm": 6.603777885437012,
      "learning_rate": 2.7885042614210122e-05,
      "loss": 0.1973,
      "step": 11450
    },
    {
      "epoch": 1.3612067941560755,
      "grad_norm": 34.386863708496094,
      "learning_rate": 2.7864846306095248e-05,
      "loss": 0.2982,
      "step": 11460
    },
    {
      "epoch": 1.362394583679772,
      "grad_norm": 0.8445078134536743,
      "learning_rate": 2.784464999798037e-05,
      "loss": 0.3499,
      "step": 11470
    },
    {
      "epoch": 1.3635823732034684,
      "grad_norm": 4.205403804779053,
      "learning_rate": 2.782445368986549e-05,
      "loss": 0.3138,
      "step": 11480
    },
    {
      "epoch": 1.3647701627271647,
      "grad_norm": 0.15579821169376373,
      "learning_rate": 2.7804257381750614e-05,
      "loss": 0.3188,
      "step": 11490
    },
    {
      "epoch": 1.3659579522508611,
      "grad_norm": 1.0904967784881592,
      "learning_rate": 2.7784061073635743e-05,
      "loss": 0.1418,
      "step": 11500
    },
    {
      "epoch": 1.3671457417745576,
      "grad_norm": 9.107378959655762,
      "learning_rate": 2.7763864765520865e-05,
      "loss": 0.3463,
      "step": 11510
    },
    {
      "epoch": 1.368333531298254,
      "grad_norm": 7.313651084899902,
      "learning_rate": 2.7743668457405987e-05,
      "loss": 0.3829,
      "step": 11520
    },
    {
      "epoch": 1.3695213208219503,
      "grad_norm": 0.6871621608734131,
      "learning_rate": 2.7723472149291112e-05,
      "loss": 0.3212,
      "step": 11530
    },
    {
      "epoch": 1.3707091103456468,
      "grad_norm": 28.250913619995117,
      "learning_rate": 2.7703275841176234e-05,
      "loss": 0.3404,
      "step": 11540
    },
    {
      "epoch": 1.371896899869343,
      "grad_norm": 15.31019115447998,
      "learning_rate": 2.7683079533061356e-05,
      "loss": 0.4561,
      "step": 11550
    },
    {
      "epoch": 1.3730846893930395,
      "grad_norm": 0.5215128660202026,
      "learning_rate": 2.7662883224946478e-05,
      "loss": 0.3392,
      "step": 11560
    },
    {
      "epoch": 1.374272478916736,
      "grad_norm": 15.09287166595459,
      "learning_rate": 2.7642686916831607e-05,
      "loss": 0.1608,
      "step": 11570
    },
    {
      "epoch": 1.3754602684404325,
      "grad_norm": 17.200546264648438,
      "learning_rate": 2.762249060871673e-05,
      "loss": 0.4334,
      "step": 11580
    },
    {
      "epoch": 1.3766480579641287,
      "grad_norm": 21.786888122558594,
      "learning_rate": 2.760229430060185e-05,
      "loss": 0.2734,
      "step": 11590
    },
    {
      "epoch": 1.3778358474878252,
      "grad_norm": 38.73650360107422,
      "learning_rate": 2.7582097992486976e-05,
      "loss": 0.3069,
      "step": 11600
    },
    {
      "epoch": 1.3790236370115216,
      "grad_norm": 6.860352516174316,
      "learning_rate": 2.7561901684372098e-05,
      "loss": 0.1915,
      "step": 11610
    },
    {
      "epoch": 1.380211426535218,
      "grad_norm": 6.1149210929870605,
      "learning_rate": 2.754170537625722e-05,
      "loss": 0.4434,
      "step": 11620
    },
    {
      "epoch": 1.3813992160589144,
      "grad_norm": 27.494009017944336,
      "learning_rate": 2.7521509068142342e-05,
      "loss": 0.3991,
      "step": 11630
    },
    {
      "epoch": 1.3825870055826108,
      "grad_norm": 1.7841676473617554,
      "learning_rate": 2.750131276002747e-05,
      "loss": 0.0976,
      "step": 11640
    },
    {
      "epoch": 1.3837747951063073,
      "grad_norm": 3.1419358253479004,
      "learning_rate": 2.7481116451912593e-05,
      "loss": 0.2291,
      "step": 11650
    },
    {
      "epoch": 1.3849625846300035,
      "grad_norm": 57.06670379638672,
      "learning_rate": 2.7460920143797715e-05,
      "loss": 0.2109,
      "step": 11660
    },
    {
      "epoch": 1.3861503741537,
      "grad_norm": 7.740368843078613,
      "learning_rate": 2.744072383568284e-05,
      "loss": 0.4211,
      "step": 11670
    },
    {
      "epoch": 1.3873381636773963,
      "grad_norm": 20.316665649414062,
      "learning_rate": 2.7420527527567963e-05,
      "loss": 0.3482,
      "step": 11680
    },
    {
      "epoch": 1.3885259532010927,
      "grad_norm": 6.059563159942627,
      "learning_rate": 2.7400331219453085e-05,
      "loss": 0.1706,
      "step": 11690
    },
    {
      "epoch": 1.3897137427247892,
      "grad_norm": 0.2537075877189636,
      "learning_rate": 2.7380134911338207e-05,
      "loss": 0.2041,
      "step": 11700
    },
    {
      "epoch": 1.3909015322484857,
      "grad_norm": 42.06727600097656,
      "learning_rate": 2.7359938603223335e-05,
      "loss": 0.2009,
      "step": 11710
    },
    {
      "epoch": 1.392089321772182,
      "grad_norm": 18.16640853881836,
      "learning_rate": 2.7339742295108457e-05,
      "loss": 0.2957,
      "step": 11720
    },
    {
      "epoch": 1.3932771112958784,
      "grad_norm": 0.49627870321273804,
      "learning_rate": 2.7319545986993576e-05,
      "loss": 0.3116,
      "step": 11730
    },
    {
      "epoch": 1.3944649008195746,
      "grad_norm": 13.227527618408203,
      "learning_rate": 2.7299349678878698e-05,
      "loss": 0.3159,
      "step": 11740
    },
    {
      "epoch": 1.395652690343271,
      "grad_norm": 40.2190055847168,
      "learning_rate": 2.7279153370763827e-05,
      "loss": 0.1945,
      "step": 11750
    },
    {
      "epoch": 1.3968404798669676,
      "grad_norm": 13.350455284118652,
      "learning_rate": 2.725895706264895e-05,
      "loss": 0.1818,
      "step": 11760
    },
    {
      "epoch": 1.398028269390664,
      "grad_norm": 17.99063491821289,
      "learning_rate": 2.723876075453407e-05,
      "loss": 0.3748,
      "step": 11770
    },
    {
      "epoch": 1.3992160589143603,
      "grad_norm": 36.770835876464844,
      "learning_rate": 2.7218564446419196e-05,
      "loss": 0.2171,
      "step": 11780
    },
    {
      "epoch": 1.4004038484380568,
      "grad_norm": 0.2681293785572052,
      "learning_rate": 2.719836813830432e-05,
      "loss": 0.2245,
      "step": 11790
    },
    {
      "epoch": 1.4015916379617532,
      "grad_norm": 0.42592108249664307,
      "learning_rate": 2.717817183018944e-05,
      "loss": 0.2747,
      "step": 11800
    },
    {
      "epoch": 1.4027794274854495,
      "grad_norm": 0.2045125812292099,
      "learning_rate": 2.7157975522074562e-05,
      "loss": 0.168,
      "step": 11810
    },
    {
      "epoch": 1.403967217009146,
      "grad_norm": 0.245646134018898,
      "learning_rate": 2.713777921395969e-05,
      "loss": 0.3484,
      "step": 11820
    },
    {
      "epoch": 1.4051550065328424,
      "grad_norm": 13.890646934509277,
      "learning_rate": 2.7117582905844813e-05,
      "loss": 0.4024,
      "step": 11830
    },
    {
      "epoch": 1.406342796056539,
      "grad_norm": 26.559444427490234,
      "learning_rate": 2.7097386597729935e-05,
      "loss": 0.2752,
      "step": 11840
    },
    {
      "epoch": 1.4075305855802351,
      "grad_norm": 15.422603607177734,
      "learning_rate": 2.707719028961506e-05,
      "loss": 0.3452,
      "step": 11850
    },
    {
      "epoch": 1.4087183751039316,
      "grad_norm": 0.5322368741035461,
      "learning_rate": 2.7056993981500183e-05,
      "loss": 0.2914,
      "step": 11860
    },
    {
      "epoch": 1.4099061646276279,
      "grad_norm": 9.796002388000488,
      "learning_rate": 2.7036797673385305e-05,
      "loss": 0.1538,
      "step": 11870
    },
    {
      "epoch": 1.4110939541513243,
      "grad_norm": 45.34764862060547,
      "learning_rate": 2.7016601365270427e-05,
      "loss": 0.3326,
      "step": 11880
    },
    {
      "epoch": 1.4122817436750208,
      "grad_norm": 3.4285101890563965,
      "learning_rate": 2.6996405057155556e-05,
      "loss": 0.2224,
      "step": 11890
    },
    {
      "epoch": 1.4134695331987173,
      "grad_norm": 9.851250648498535,
      "learning_rate": 2.6976208749040678e-05,
      "loss": 0.3726,
      "step": 11900
    },
    {
      "epoch": 1.4146573227224135,
      "grad_norm": 3.5739858150482178,
      "learning_rate": 2.69560124409258e-05,
      "loss": 0.3741,
      "step": 11910
    },
    {
      "epoch": 1.41584511224611,
      "grad_norm": 5.200191020965576,
      "learning_rate": 2.6935816132810925e-05,
      "loss": 0.3094,
      "step": 11920
    },
    {
      "epoch": 1.4170329017698065,
      "grad_norm": 11.83829402923584,
      "learning_rate": 2.6915619824696047e-05,
      "loss": 0.1771,
      "step": 11930
    },
    {
      "epoch": 1.4182206912935027,
      "grad_norm": 0.27016857266426086,
      "learning_rate": 2.689542351658117e-05,
      "loss": 0.353,
      "step": 11940
    },
    {
      "epoch": 1.4194084808171992,
      "grad_norm": 2.613213539123535,
      "learning_rate": 2.687522720846629e-05,
      "loss": 0.2965,
      "step": 11950
    },
    {
      "epoch": 1.4205962703408956,
      "grad_norm": 0.8586907982826233,
      "learning_rate": 2.685503090035142e-05,
      "loss": 0.1297,
      "step": 11960
    },
    {
      "epoch": 1.421784059864592,
      "grad_norm": 17.42823600769043,
      "learning_rate": 2.6834834592236542e-05,
      "loss": 0.1961,
      "step": 11970
    },
    {
      "epoch": 1.4229718493882884,
      "grad_norm": 16.187519073486328,
      "learning_rate": 2.6814638284121664e-05,
      "loss": 0.3585,
      "step": 11980
    },
    {
      "epoch": 1.4241596389119848,
      "grad_norm": 0.8735162615776062,
      "learning_rate": 2.679444197600679e-05,
      "loss": 0.1856,
      "step": 11990
    },
    {
      "epoch": 1.425347428435681,
      "grad_norm": 34.37105178833008,
      "learning_rate": 2.677424566789191e-05,
      "loss": 0.4036,
      "step": 12000
    },
    {
      "epoch": 1.4265352179593775,
      "grad_norm": 0.15484075248241425,
      "learning_rate": 2.6754049359777033e-05,
      "loss": 0.2803,
      "step": 12010
    },
    {
      "epoch": 1.427723007483074,
      "grad_norm": 1.4486280679702759,
      "learning_rate": 2.6733853051662155e-05,
      "loss": 0.0662,
      "step": 12020
    },
    {
      "epoch": 1.4289107970067705,
      "grad_norm": 0.281901478767395,
      "learning_rate": 2.6713656743547284e-05,
      "loss": 0.2436,
      "step": 12030
    },
    {
      "epoch": 1.4300985865304667,
      "grad_norm": 2.502673387527466,
      "learning_rate": 2.6693460435432406e-05,
      "loss": 0.5344,
      "step": 12040
    },
    {
      "epoch": 1.4312863760541632,
      "grad_norm": 21.583654403686523,
      "learning_rate": 2.6673264127317528e-05,
      "loss": 0.3291,
      "step": 12050
    },
    {
      "epoch": 1.4324741655778597,
      "grad_norm": 31.32952117919922,
      "learning_rate": 2.6653067819202647e-05,
      "loss": 0.2326,
      "step": 12060
    },
    {
      "epoch": 1.433661955101556,
      "grad_norm": 13.935855865478516,
      "learning_rate": 2.6632871511087776e-05,
      "loss": 0.2913,
      "step": 12070
    },
    {
      "epoch": 1.4348497446252524,
      "grad_norm": 21.693845748901367,
      "learning_rate": 2.6612675202972898e-05,
      "loss": 0.3603,
      "step": 12080
    },
    {
      "epoch": 1.4360375341489489,
      "grad_norm": 1.9280554056167603,
      "learning_rate": 2.659247889485802e-05,
      "loss": 0.2737,
      "step": 12090
    },
    {
      "epoch": 1.4372253236726453,
      "grad_norm": 13.96633529663086,
      "learning_rate": 2.657228258674315e-05,
      "loss": 0.2519,
      "step": 12100
    },
    {
      "epoch": 1.4384131131963416,
      "grad_norm": 1.1997941732406616,
      "learning_rate": 2.6552086278628267e-05,
      "loss": 0.284,
      "step": 12110
    },
    {
      "epoch": 1.439600902720038,
      "grad_norm": 2.1610748767852783,
      "learning_rate": 2.653188997051339e-05,
      "loss": 0.3092,
      "step": 12120
    },
    {
      "epoch": 1.4407886922437343,
      "grad_norm": 6.285865783691406,
      "learning_rate": 2.651169366239851e-05,
      "loss": 0.263,
      "step": 12130
    },
    {
      "epoch": 1.4419764817674308,
      "grad_norm": 1.2294167280197144,
      "learning_rate": 2.649149735428364e-05,
      "loss": 0.3788,
      "step": 12140
    },
    {
      "epoch": 1.4431642712911272,
      "grad_norm": 5.150195121765137,
      "learning_rate": 2.6471301046168762e-05,
      "loss": 0.2373,
      "step": 12150
    },
    {
      "epoch": 1.4443520608148237,
      "grad_norm": 15.941953659057617,
      "learning_rate": 2.6451104738053884e-05,
      "loss": 0.254,
      "step": 12160
    },
    {
      "epoch": 1.44553985033852,
      "grad_norm": 10.36515998840332,
      "learning_rate": 2.643090842993901e-05,
      "loss": 0.3875,
      "step": 12170
    },
    {
      "epoch": 1.4467276398622164,
      "grad_norm": 20.111452102661133,
      "learning_rate": 2.641071212182413e-05,
      "loss": 0.3008,
      "step": 12180
    },
    {
      "epoch": 1.4479154293859129,
      "grad_norm": 0.2515845000743866,
      "learning_rate": 2.6390515813709253e-05,
      "loss": 0.3637,
      "step": 12190
    },
    {
      "epoch": 1.4491032189096091,
      "grad_norm": 1.4886752367019653,
      "learning_rate": 2.6370319505594375e-05,
      "loss": 0.2768,
      "step": 12200
    },
    {
      "epoch": 1.4502910084333056,
      "grad_norm": 2.428476095199585,
      "learning_rate": 2.6350123197479504e-05,
      "loss": 0.4405,
      "step": 12210
    },
    {
      "epoch": 1.451478797957002,
      "grad_norm": 44.094234466552734,
      "learning_rate": 2.6329926889364626e-05,
      "loss": 0.2722,
      "step": 12220
    },
    {
      "epoch": 1.4526665874806985,
      "grad_norm": 14.551595687866211,
      "learning_rate": 2.6309730581249748e-05,
      "loss": 0.3805,
      "step": 12230
    },
    {
      "epoch": 1.4538543770043948,
      "grad_norm": 25.754634857177734,
      "learning_rate": 2.6289534273134874e-05,
      "loss": 0.3238,
      "step": 12240
    },
    {
      "epoch": 1.4550421665280913,
      "grad_norm": 24.359094619750977,
      "learning_rate": 2.6269337965019996e-05,
      "loss": 0.255,
      "step": 12250
    },
    {
      "epoch": 1.4562299560517875,
      "grad_norm": 13.291731834411621,
      "learning_rate": 2.6249141656905118e-05,
      "loss": 0.1798,
      "step": 12260
    },
    {
      "epoch": 1.457417745575484,
      "grad_norm": 8.203130722045898,
      "learning_rate": 2.622894534879024e-05,
      "loss": 0.2195,
      "step": 12270
    },
    {
      "epoch": 1.4586055350991805,
      "grad_norm": 4.854207992553711,
      "learning_rate": 2.620874904067537e-05,
      "loss": 0.3093,
      "step": 12280
    },
    {
      "epoch": 1.459793324622877,
      "grad_norm": 18.976423263549805,
      "learning_rate": 2.618855273256049e-05,
      "loss": 0.3911,
      "step": 12290
    },
    {
      "epoch": 1.4609811141465732,
      "grad_norm": 3.220033884048462,
      "learning_rate": 2.6168356424445613e-05,
      "loss": 0.2266,
      "step": 12300
    },
    {
      "epoch": 1.4621689036702696,
      "grad_norm": 9.663531303405762,
      "learning_rate": 2.6148160116330735e-05,
      "loss": 0.3217,
      "step": 12310
    },
    {
      "epoch": 1.463356693193966,
      "grad_norm": 37.239654541015625,
      "learning_rate": 2.612796380821586e-05,
      "loss": 0.2457,
      "step": 12320
    },
    {
      "epoch": 1.4645444827176624,
      "grad_norm": 6.629789352416992,
      "learning_rate": 2.6107767500100982e-05,
      "loss": 0.4558,
      "step": 12330
    },
    {
      "epoch": 1.4657322722413588,
      "grad_norm": 9.717141151428223,
      "learning_rate": 2.6087571191986104e-05,
      "loss": 0.429,
      "step": 12340
    },
    {
      "epoch": 1.4669200617650553,
      "grad_norm": 23.262035369873047,
      "learning_rate": 2.6067374883871233e-05,
      "loss": 0.2916,
      "step": 12350
    },
    {
      "epoch": 1.4681078512887518,
      "grad_norm": 39.16508865356445,
      "learning_rate": 2.6047178575756355e-05,
      "loss": 0.3749,
      "step": 12360
    },
    {
      "epoch": 1.469295640812448,
      "grad_norm": 38.83778381347656,
      "learning_rate": 2.6026982267641477e-05,
      "loss": 0.4103,
      "step": 12370
    },
    {
      "epoch": 1.4704834303361445,
      "grad_norm": 55.38618087768555,
      "learning_rate": 2.60067859595266e-05,
      "loss": 0.2472,
      "step": 12380
    },
    {
      "epoch": 1.4716712198598407,
      "grad_norm": 8.79484748840332,
      "learning_rate": 2.5986589651411724e-05,
      "loss": 0.4978,
      "step": 12390
    },
    {
      "epoch": 1.4728590093835372,
      "grad_norm": 6.152874946594238,
      "learning_rate": 2.5966393343296846e-05,
      "loss": 0.2672,
      "step": 12400
    },
    {
      "epoch": 1.4740467989072337,
      "grad_norm": 5.410404205322266,
      "learning_rate": 2.594619703518197e-05,
      "loss": 0.3218,
      "step": 12410
    },
    {
      "epoch": 1.4752345884309301,
      "grad_norm": 13.743395805358887,
      "learning_rate": 2.5926000727067097e-05,
      "loss": 0.2751,
      "step": 12420
    },
    {
      "epoch": 1.4764223779546264,
      "grad_norm": 7.203677654266357,
      "learning_rate": 2.590580441895222e-05,
      "loss": 0.3716,
      "step": 12430
    },
    {
      "epoch": 1.4776101674783229,
      "grad_norm": 2.2943778038024902,
      "learning_rate": 2.5885608110837338e-05,
      "loss": 0.3853,
      "step": 12440
    },
    {
      "epoch": 1.4787979570020193,
      "grad_norm": 1.57619047164917,
      "learning_rate": 2.586541180272246e-05,
      "loss": 0.2532,
      "step": 12450
    },
    {
      "epoch": 1.4799857465257156,
      "grad_norm": 0.6777105331420898,
      "learning_rate": 2.584521549460759e-05,
      "loss": 0.3867,
      "step": 12460
    },
    {
      "epoch": 1.481173536049412,
      "grad_norm": 34.19824981689453,
      "learning_rate": 2.582501918649271e-05,
      "loss": 0.3599,
      "step": 12470
    },
    {
      "epoch": 1.4823613255731085,
      "grad_norm": 6.798253536224365,
      "learning_rate": 2.5804822878377833e-05,
      "loss": 0.2809,
      "step": 12480
    },
    {
      "epoch": 1.483549115096805,
      "grad_norm": 14.519745826721191,
      "learning_rate": 2.5784626570262958e-05,
      "loss": 0.4811,
      "step": 12490
    },
    {
      "epoch": 1.4847369046205012,
      "grad_norm": 12.547796249389648,
      "learning_rate": 2.576443026214808e-05,
      "loss": 0.3214,
      "step": 12500
    },
    {
      "epoch": 1.4859246941441977,
      "grad_norm": 27.217042922973633,
      "learning_rate": 2.5744233954033202e-05,
      "loss": 0.2033,
      "step": 12510
    },
    {
      "epoch": 1.487112483667894,
      "grad_norm": 0.18237261474132538,
      "learning_rate": 2.5724037645918324e-05,
      "loss": 0.0837,
      "step": 12520
    },
    {
      "epoch": 1.4883002731915904,
      "grad_norm": 0.23628447949886322,
      "learning_rate": 2.5703841337803453e-05,
      "loss": 0.2652,
      "step": 12530
    },
    {
      "epoch": 1.4894880627152869,
      "grad_norm": 0.3040972948074341,
      "learning_rate": 2.5683645029688575e-05,
      "loss": 0.287,
      "step": 12540
    },
    {
      "epoch": 1.4906758522389834,
      "grad_norm": 13.905143737792969,
      "learning_rate": 2.5663448721573697e-05,
      "loss": 0.2208,
      "step": 12550
    },
    {
      "epoch": 1.4918636417626796,
      "grad_norm": 20.599390029907227,
      "learning_rate": 2.5643252413458822e-05,
      "loss": 0.1297,
      "step": 12560
    },
    {
      "epoch": 1.493051431286376,
      "grad_norm": 1.1095770597457886,
      "learning_rate": 2.5623056105343944e-05,
      "loss": 0.1175,
      "step": 12570
    },
    {
      "epoch": 1.4942392208100723,
      "grad_norm": 21.50934410095215,
      "learning_rate": 2.5602859797229066e-05,
      "loss": 0.2216,
      "step": 12580
    },
    {
      "epoch": 1.4954270103337688,
      "grad_norm": 22.141393661499023,
      "learning_rate": 2.558266348911419e-05,
      "loss": 0.3821,
      "step": 12590
    },
    {
      "epoch": 1.4966147998574653,
      "grad_norm": 2.203676462173462,
      "learning_rate": 2.5562467180999317e-05,
      "loss": 0.3035,
      "step": 12600
    },
    {
      "epoch": 1.4978025893811617,
      "grad_norm": 18.78140640258789,
      "learning_rate": 2.554227087288444e-05,
      "loss": 0.2217,
      "step": 12610
    },
    {
      "epoch": 1.498990378904858,
      "grad_norm": 5.067966461181641,
      "learning_rate": 2.552207456476956e-05,
      "loss": 0.3484,
      "step": 12620
    },
    {
      "epoch": 1.5001781684285544,
      "grad_norm": 11.490653991699219,
      "learning_rate": 2.5501878256654683e-05,
      "loss": 0.2796,
      "step": 12630
    },
    {
      "epoch": 1.5013659579522507,
      "grad_norm": 4.474855422973633,
      "learning_rate": 2.548168194853981e-05,
      "loss": 0.1907,
      "step": 12640
    },
    {
      "epoch": 1.5025537474759472,
      "grad_norm": 30.52431297302246,
      "learning_rate": 2.546148564042493e-05,
      "loss": 0.2709,
      "step": 12650
    },
    {
      "epoch": 1.5037415369996436,
      "grad_norm": 5.6358160972595215,
      "learning_rate": 2.5441289332310053e-05,
      "loss": 0.3063,
      "step": 12660
    },
    {
      "epoch": 1.50492932652334,
      "grad_norm": 2.3293375968933105,
      "learning_rate": 2.542109302419518e-05,
      "loss": 0.4694,
      "step": 12670
    },
    {
      "epoch": 1.5061171160470366,
      "grad_norm": 19.81387710571289,
      "learning_rate": 2.5400896716080304e-05,
      "loss": 0.4776,
      "step": 12680
    },
    {
      "epoch": 1.5073049055707328,
      "grad_norm": 2.766037702560425,
      "learning_rate": 2.5380700407965426e-05,
      "loss": 0.3711,
      "step": 12690
    },
    {
      "epoch": 1.5084926950944293,
      "grad_norm": 9.30960464477539,
      "learning_rate": 2.5360504099850548e-05,
      "loss": 0.2375,
      "step": 12700
    },
    {
      "epoch": 1.5096804846181255,
      "grad_norm": 3.681612014770508,
      "learning_rate": 2.5340307791735673e-05,
      "loss": 0.2002,
      "step": 12710
    },
    {
      "epoch": 1.510868274141822,
      "grad_norm": 5.463210582733154,
      "learning_rate": 2.5320111483620795e-05,
      "loss": 0.185,
      "step": 12720
    },
    {
      "epoch": 1.5120560636655185,
      "grad_norm": 0.798078715801239,
      "learning_rate": 2.5299915175505917e-05,
      "loss": 0.1384,
      "step": 12730
    },
    {
      "epoch": 1.513243853189215,
      "grad_norm": 6.975722789764404,
      "learning_rate": 2.5279718867391046e-05,
      "loss": 0.2775,
      "step": 12740
    },
    {
      "epoch": 1.5144316427129114,
      "grad_norm": 2.6877763271331787,
      "learning_rate": 2.5259522559276168e-05,
      "loss": 0.1559,
      "step": 12750
    },
    {
      "epoch": 1.5156194322366077,
      "grad_norm": 60.28627014160156,
      "learning_rate": 2.523932625116129e-05,
      "loss": 0.2317,
      "step": 12760
    },
    {
      "epoch": 1.516807221760304,
      "grad_norm": 9.303532600402832,
      "learning_rate": 2.521912994304641e-05,
      "loss": 0.1041,
      "step": 12770
    },
    {
      "epoch": 1.5179950112840004,
      "grad_norm": 50.0369987487793,
      "learning_rate": 2.5198933634931537e-05,
      "loss": 0.2694,
      "step": 12780
    },
    {
      "epoch": 1.5191828008076969,
      "grad_norm": 19.702102661132812,
      "learning_rate": 2.517873732681666e-05,
      "loss": 0.3398,
      "step": 12790
    },
    {
      "epoch": 1.5203705903313933,
      "grad_norm": 12.722674369812012,
      "learning_rate": 2.515854101870178e-05,
      "loss": 0.595,
      "step": 12800
    },
    {
      "epoch": 1.5215583798550898,
      "grad_norm": 29.90802764892578,
      "learning_rate": 2.513834471058691e-05,
      "loss": 0.4104,
      "step": 12810
    },
    {
      "epoch": 1.522746169378786,
      "grad_norm": 21.885757446289062,
      "learning_rate": 2.511814840247203e-05,
      "loss": 0.3386,
      "step": 12820
    },
    {
      "epoch": 1.5239339589024825,
      "grad_norm": 21.1931095123291,
      "learning_rate": 2.509795209435715e-05,
      "loss": 0.314,
      "step": 12830
    },
    {
      "epoch": 1.5251217484261788,
      "grad_norm": 14.808363914489746,
      "learning_rate": 2.5077755786242273e-05,
      "loss": 0.3256,
      "step": 12840
    },
    {
      "epoch": 1.5263095379498752,
      "grad_norm": 0.4892483651638031,
      "learning_rate": 2.50575594781274e-05,
      "loss": 0.3324,
      "step": 12850
    },
    {
      "epoch": 1.5274973274735717,
      "grad_norm": 7.453845024108887,
      "learning_rate": 2.5037363170012524e-05,
      "loss": 0.2724,
      "step": 12860
    },
    {
      "epoch": 1.5286851169972682,
      "grad_norm": 0.22009287774562836,
      "learning_rate": 2.5017166861897646e-05,
      "loss": 0.1642,
      "step": 12870
    },
    {
      "epoch": 1.5298729065209646,
      "grad_norm": 20.016706466674805,
      "learning_rate": 2.499697055378277e-05,
      "loss": 0.5081,
      "step": 12880
    },
    {
      "epoch": 1.5310606960446609,
      "grad_norm": 24.97540855407715,
      "learning_rate": 2.4976774245667893e-05,
      "loss": 0.3165,
      "step": 12890
    },
    {
      "epoch": 1.5322484855683571,
      "grad_norm": 41.69332504272461,
      "learning_rate": 2.4956577937553015e-05,
      "loss": 0.29,
      "step": 12900
    },
    {
      "epoch": 1.5334362750920536,
      "grad_norm": 13.810271263122559,
      "learning_rate": 2.493638162943814e-05,
      "loss": 0.4,
      "step": 12910
    },
    {
      "epoch": 1.53462406461575,
      "grad_norm": 20.59303855895996,
      "learning_rate": 2.4916185321323262e-05,
      "loss": 0.3688,
      "step": 12920
    },
    {
      "epoch": 1.5358118541394465,
      "grad_norm": 18.637094497680664,
      "learning_rate": 2.4895989013208388e-05,
      "loss": 0.3039,
      "step": 12930
    },
    {
      "epoch": 1.536999643663143,
      "grad_norm": 2.6162500381469727,
      "learning_rate": 2.487579270509351e-05,
      "loss": 0.1336,
      "step": 12940
    },
    {
      "epoch": 1.5381874331868393,
      "grad_norm": 0.4564604163169861,
      "learning_rate": 2.4855596396978635e-05,
      "loss": 0.153,
      "step": 12950
    },
    {
      "epoch": 1.5393752227105357,
      "grad_norm": 5.053546905517578,
      "learning_rate": 2.4835400088863754e-05,
      "loss": 0.4389,
      "step": 12960
    },
    {
      "epoch": 1.540563012234232,
      "grad_norm": 8.112566947937012,
      "learning_rate": 2.481520378074888e-05,
      "loss": 0.1012,
      "step": 12970
    },
    {
      "epoch": 1.5417508017579284,
      "grad_norm": 9.161360740661621,
      "learning_rate": 2.4795007472634005e-05,
      "loss": 0.5549,
      "step": 12980
    },
    {
      "epoch": 1.542938591281625,
      "grad_norm": 12.494571685791016,
      "learning_rate": 2.4774811164519127e-05,
      "loss": 0.2702,
      "step": 12990
    },
    {
      "epoch": 1.5441263808053214,
      "grad_norm": 27.422775268554688,
      "learning_rate": 2.4754614856404252e-05,
      "loss": 0.4863,
      "step": 13000
    },
    {
      "epoch": 1.5453141703290179,
      "grad_norm": 0.3068317472934723,
      "learning_rate": 2.4734418548289374e-05,
      "loss": 0.2291,
      "step": 13010
    },
    {
      "epoch": 1.546501959852714,
      "grad_norm": 0.3894446790218353,
      "learning_rate": 2.4714222240174496e-05,
      "loss": 0.2004,
      "step": 13020
    },
    {
      "epoch": 1.5476897493764104,
      "grad_norm": 6.579713344573975,
      "learning_rate": 2.4694025932059618e-05,
      "loss": 0.378,
      "step": 13030
    },
    {
      "epoch": 1.5488775389001068,
      "grad_norm": 20.423555374145508,
      "learning_rate": 2.4673829623944744e-05,
      "loss": 0.3066,
      "step": 13040
    },
    {
      "epoch": 1.5500653284238033,
      "grad_norm": 5.390529155731201,
      "learning_rate": 2.465363331582987e-05,
      "loss": 0.2197,
      "step": 13050
    },
    {
      "epoch": 1.5512531179474998,
      "grad_norm": 20.00559425354004,
      "learning_rate": 2.463343700771499e-05,
      "loss": 0.3144,
      "step": 13060
    },
    {
      "epoch": 1.5524409074711962,
      "grad_norm": 0.6440827250480652,
      "learning_rate": 2.4613240699600117e-05,
      "loss": 0.1888,
      "step": 13070
    },
    {
      "epoch": 1.5536286969948925,
      "grad_norm": 11.760177612304688,
      "learning_rate": 2.459304439148524e-05,
      "loss": 0.2309,
      "step": 13080
    },
    {
      "epoch": 1.554816486518589,
      "grad_norm": 26.85556411743164,
      "learning_rate": 2.457284808337036e-05,
      "loss": 0.2052,
      "step": 13090
    },
    {
      "epoch": 1.5560042760422852,
      "grad_norm": 14.441383361816406,
      "learning_rate": 2.4552651775255483e-05,
      "loss": 0.5237,
      "step": 13100
    },
    {
      "epoch": 1.5571920655659817,
      "grad_norm": 0.3322876989841461,
      "learning_rate": 2.4532455467140608e-05,
      "loss": 0.2215,
      "step": 13110
    },
    {
      "epoch": 1.5583798550896781,
      "grad_norm": 30.873023986816406,
      "learning_rate": 2.451225915902573e-05,
      "loss": 0.3126,
      "step": 13120
    },
    {
      "epoch": 1.5595676446133746,
      "grad_norm": 17.964326858520508,
      "learning_rate": 2.4492062850910855e-05,
      "loss": 0.2906,
      "step": 13130
    },
    {
      "epoch": 1.560755434137071,
      "grad_norm": 1.6526206731796265,
      "learning_rate": 2.447186654279598e-05,
      "loss": 0.2367,
      "step": 13140
    },
    {
      "epoch": 1.5619432236607673,
      "grad_norm": 19.99576187133789,
      "learning_rate": 2.44516702346811e-05,
      "loss": 0.2225,
      "step": 13150
    },
    {
      "epoch": 1.5631310131844636,
      "grad_norm": 23.250747680664062,
      "learning_rate": 2.4431473926566225e-05,
      "loss": 0.4752,
      "step": 13160
    },
    {
      "epoch": 1.56431880270816,
      "grad_norm": 1.9402878284454346,
      "learning_rate": 2.4411277618451347e-05,
      "loss": 0.4756,
      "step": 13170
    },
    {
      "epoch": 1.5655065922318565,
      "grad_norm": 15.141718864440918,
      "learning_rate": 2.4391081310336472e-05,
      "loss": 0.2063,
      "step": 13180
    },
    {
      "epoch": 1.566694381755553,
      "grad_norm": 11.6840181350708,
      "learning_rate": 2.4370885002221594e-05,
      "loss": 0.2775,
      "step": 13190
    },
    {
      "epoch": 1.5678821712792494,
      "grad_norm": 4.176958084106445,
      "learning_rate": 2.435068869410672e-05,
      "loss": 0.2959,
      "step": 13200
    },
    {
      "epoch": 1.5690699608029457,
      "grad_norm": 17.942909240722656,
      "learning_rate": 2.4330492385991842e-05,
      "loss": 0.3924,
      "step": 13210
    },
    {
      "epoch": 1.5702577503266422,
      "grad_norm": 15.956271171569824,
      "learning_rate": 2.4310296077876964e-05,
      "loss": 0.2617,
      "step": 13220
    },
    {
      "epoch": 1.5714455398503384,
      "grad_norm": 17.613304138183594,
      "learning_rate": 2.429009976976209e-05,
      "loss": 0.2251,
      "step": 13230
    },
    {
      "epoch": 1.5726333293740349,
      "grad_norm": 19.58362579345703,
      "learning_rate": 2.426990346164721e-05,
      "loss": 0.3378,
      "step": 13240
    },
    {
      "epoch": 1.5738211188977314,
      "grad_norm": 9.573376655578613,
      "learning_rate": 2.4249707153532337e-05,
      "loss": 0.3266,
      "step": 13250
    },
    {
      "epoch": 1.5750089084214278,
      "grad_norm": 16.83286476135254,
      "learning_rate": 2.422951084541746e-05,
      "loss": 0.3252,
      "step": 13260
    },
    {
      "epoch": 1.576196697945124,
      "grad_norm": 35.26860046386719,
      "learning_rate": 2.4209314537302584e-05,
      "loss": 0.2747,
      "step": 13270
    },
    {
      "epoch": 1.5773844874688205,
      "grad_norm": 5.975813865661621,
      "learning_rate": 2.4189118229187706e-05,
      "loss": 0.166,
      "step": 13280
    },
    {
      "epoch": 1.5785722769925168,
      "grad_norm": 29.918827056884766,
      "learning_rate": 2.4168921921072828e-05,
      "loss": 0.3219,
      "step": 13290
    },
    {
      "epoch": 1.5797600665162133,
      "grad_norm": 15.56895637512207,
      "learning_rate": 2.4148725612957953e-05,
      "loss": 0.4119,
      "step": 13300
    },
    {
      "epoch": 1.5809478560399097,
      "grad_norm": 23.350139617919922,
      "learning_rate": 2.4128529304843075e-05,
      "loss": 0.3146,
      "step": 13310
    },
    {
      "epoch": 1.5821356455636062,
      "grad_norm": 29.66852378845215,
      "learning_rate": 2.41083329967282e-05,
      "loss": 0.3373,
      "step": 13320
    },
    {
      "epoch": 1.5833234350873027,
      "grad_norm": 28.70357322692871,
      "learning_rate": 2.4088136688613323e-05,
      "loss": 0.2321,
      "step": 13330
    },
    {
      "epoch": 1.584511224610999,
      "grad_norm": 56.77018737792969,
      "learning_rate": 2.4067940380498445e-05,
      "loss": 0.4405,
      "step": 13340
    },
    {
      "epoch": 1.5856990141346954,
      "grad_norm": 11.126208305358887,
      "learning_rate": 2.4047744072383567e-05,
      "loss": 0.2259,
      "step": 13350
    },
    {
      "epoch": 1.5868868036583916,
      "grad_norm": 22.398330688476562,
      "learning_rate": 2.4027547764268692e-05,
      "loss": 0.3954,
      "step": 13360
    },
    {
      "epoch": 1.588074593182088,
      "grad_norm": 9.285286903381348,
      "learning_rate": 2.4007351456153814e-05,
      "loss": 0.1858,
      "step": 13370
    },
    {
      "epoch": 1.5892623827057846,
      "grad_norm": 5.007570266723633,
      "learning_rate": 2.398715514803894e-05,
      "loss": 0.2192,
      "step": 13380
    },
    {
      "epoch": 1.590450172229481,
      "grad_norm": 5.665012359619141,
      "learning_rate": 2.3966958839924065e-05,
      "loss": 0.1816,
      "step": 13390
    },
    {
      "epoch": 1.5916379617531773,
      "grad_norm": 7.5212883949279785,
      "learning_rate": 2.3946762531809187e-05,
      "loss": 0.3424,
      "step": 13400
    },
    {
      "epoch": 1.5928257512768738,
      "grad_norm": 34.224735260009766,
      "learning_rate": 2.392656622369431e-05,
      "loss": 0.1987,
      "step": 13410
    },
    {
      "epoch": 1.59401354080057,
      "grad_norm": 10.730891227722168,
      "learning_rate": 2.390636991557943e-05,
      "loss": 0.259,
      "step": 13420
    },
    {
      "epoch": 1.5952013303242665,
      "grad_norm": 1.4018311500549316,
      "learning_rate": 2.3886173607464557e-05,
      "loss": 0.1017,
      "step": 13430
    },
    {
      "epoch": 1.596389119847963,
      "grad_norm": 16.549882888793945,
      "learning_rate": 2.386597729934968e-05,
      "loss": 0.1703,
      "step": 13440
    },
    {
      "epoch": 1.5975769093716594,
      "grad_norm": 19.28339385986328,
      "learning_rate": 2.3845780991234804e-05,
      "loss": 0.1772,
      "step": 13450
    },
    {
      "epoch": 1.5987646988953559,
      "grad_norm": 3.3329105377197266,
      "learning_rate": 2.382558468311993e-05,
      "loss": 0.2461,
      "step": 13460
    },
    {
      "epoch": 1.5999524884190521,
      "grad_norm": 11.973365783691406,
      "learning_rate": 2.380538837500505e-05,
      "loss": 0.3214,
      "step": 13470
    },
    {
      "epoch": 1.6011402779427484,
      "grad_norm": 17.185686111450195,
      "learning_rate": 2.3785192066890174e-05,
      "loss": 0.1545,
      "step": 13480
    },
    {
      "epoch": 1.6023280674664448,
      "grad_norm": 37.59801483154297,
      "learning_rate": 2.3764995758775296e-05,
      "loss": 0.2003,
      "step": 13490
    },
    {
      "epoch": 1.6035158569901413,
      "grad_norm": 3.915573835372925,
      "learning_rate": 2.374479945066042e-05,
      "loss": 0.4002,
      "step": 13500
    },
    {
      "epoch": 1.6047036465138378,
      "grad_norm": 0.1942138969898224,
      "learning_rate": 2.3724603142545543e-05,
      "loss": 0.2202,
      "step": 13510
    },
    {
      "epoch": 1.6058914360375343,
      "grad_norm": 34.026084899902344,
      "learning_rate": 2.370440683443067e-05,
      "loss": 0.2198,
      "step": 13520
    },
    {
      "epoch": 1.6070792255612305,
      "grad_norm": 20.464195251464844,
      "learning_rate": 2.368421052631579e-05,
      "loss": 0.2426,
      "step": 13530
    },
    {
      "epoch": 1.608267015084927,
      "grad_norm": 0.5125117897987366,
      "learning_rate": 2.3664014218200912e-05,
      "loss": 0.3907,
      "step": 13540
    },
    {
      "epoch": 1.6094548046086232,
      "grad_norm": 27.897653579711914,
      "learning_rate": 2.3643817910086038e-05,
      "loss": 0.635,
      "step": 13550
    },
    {
      "epoch": 1.6106425941323197,
      "grad_norm": 24.00575828552246,
      "learning_rate": 2.362362160197116e-05,
      "loss": 0.2638,
      "step": 13560
    },
    {
      "epoch": 1.6118303836560162,
      "grad_norm": 5.329796314239502,
      "learning_rate": 2.3603425293856285e-05,
      "loss": 0.2419,
      "step": 13570
    },
    {
      "epoch": 1.6130181731797126,
      "grad_norm": 15.922542572021484,
      "learning_rate": 2.3583228985741407e-05,
      "loss": 0.1631,
      "step": 13580
    },
    {
      "epoch": 1.614205962703409,
      "grad_norm": 39.20541000366211,
      "learning_rate": 2.3563032677626533e-05,
      "loss": 0.467,
      "step": 13590
    },
    {
      "epoch": 1.6153937522271054,
      "grad_norm": 9.290827751159668,
      "learning_rate": 2.3542836369511655e-05,
      "loss": 0.3894,
      "step": 13600
    },
    {
      "epoch": 1.6165815417508016,
      "grad_norm": 0.6313380599021912,
      "learning_rate": 2.3522640061396777e-05,
      "loss": 0.2534,
      "step": 13610
    },
    {
      "epoch": 1.617769331274498,
      "grad_norm": 27.83380126953125,
      "learning_rate": 2.3502443753281902e-05,
      "loss": 0.1976,
      "step": 13620
    },
    {
      "epoch": 1.6189571207981945,
      "grad_norm": 7.446811676025391,
      "learning_rate": 2.3482247445167024e-05,
      "loss": 0.263,
      "step": 13630
    },
    {
      "epoch": 1.620144910321891,
      "grad_norm": 18.883277893066406,
      "learning_rate": 2.346205113705215e-05,
      "loss": 0.3303,
      "step": 13640
    },
    {
      "epoch": 1.6213326998455875,
      "grad_norm": 0.5143921971321106,
      "learning_rate": 2.344185482893727e-05,
      "loss": 0.386,
      "step": 13650
    },
    {
      "epoch": 1.6225204893692837,
      "grad_norm": 25.793689727783203,
      "learning_rate": 2.3421658520822397e-05,
      "loss": 0.2501,
      "step": 13660
    },
    {
      "epoch": 1.6237082788929802,
      "grad_norm": 13.845599174499512,
      "learning_rate": 2.3401462212707516e-05,
      "loss": 0.4106,
      "step": 13670
    },
    {
      "epoch": 1.6248960684166764,
      "grad_norm": 23.488845825195312,
      "learning_rate": 2.338126590459264e-05,
      "loss": 0.1231,
      "step": 13680
    },
    {
      "epoch": 1.626083857940373,
      "grad_norm": 17.233158111572266,
      "learning_rate": 2.3361069596477763e-05,
      "loss": 0.3547,
      "step": 13690
    },
    {
      "epoch": 1.6272716474640694,
      "grad_norm": 1.8347301483154297,
      "learning_rate": 2.334087328836289e-05,
      "loss": 0.2242,
      "step": 13700
    },
    {
      "epoch": 1.6284594369877659,
      "grad_norm": 26.318119049072266,
      "learning_rate": 2.3320676980248014e-05,
      "loss": 0.2562,
      "step": 13710
    },
    {
      "epoch": 1.6296472265114623,
      "grad_norm": 0.2787672281265259,
      "learning_rate": 2.3300480672133136e-05,
      "loss": 0.286,
      "step": 13720
    },
    {
      "epoch": 1.6308350160351586,
      "grad_norm": 4.8763227462768555,
      "learning_rate": 2.3280284364018258e-05,
      "loss": 0.3122,
      "step": 13730
    },
    {
      "epoch": 1.6320228055588548,
      "grad_norm": 13.621922492980957,
      "learning_rate": 2.326008805590338e-05,
      "loss": 0.2893,
      "step": 13740
    },
    {
      "epoch": 1.6332105950825513,
      "grad_norm": 8.802413940429688,
      "learning_rate": 2.3239891747788505e-05,
      "loss": 0.2939,
      "step": 13750
    },
    {
      "epoch": 1.6343983846062478,
      "grad_norm": 8.612687110900879,
      "learning_rate": 2.3219695439673627e-05,
      "loss": 0.2845,
      "step": 13760
    },
    {
      "epoch": 1.6355861741299442,
      "grad_norm": 22.451126098632812,
      "learning_rate": 2.3199499131558753e-05,
      "loss": 0.432,
      "step": 13770
    },
    {
      "epoch": 1.6367739636536407,
      "grad_norm": 24.89232635498047,
      "learning_rate": 2.3179302823443878e-05,
      "loss": 0.1343,
      "step": 13780
    },
    {
      "epoch": 1.637961753177337,
      "grad_norm": 22.936180114746094,
      "learning_rate": 2.3159106515329e-05,
      "loss": 0.3983,
      "step": 13790
    },
    {
      "epoch": 1.6391495427010334,
      "grad_norm": 3.9685308933258057,
      "learning_rate": 2.3138910207214122e-05,
      "loss": 0.1858,
      "step": 13800
    },
    {
      "epoch": 1.6403373322247297,
      "grad_norm": 48.17149353027344,
      "learning_rate": 2.3118713899099244e-05,
      "loss": 0.4154,
      "step": 13810
    },
    {
      "epoch": 1.6415251217484261,
      "grad_norm": 12.848280906677246,
      "learning_rate": 2.309851759098437e-05,
      "loss": 0.3173,
      "step": 13820
    },
    {
      "epoch": 1.6427129112721226,
      "grad_norm": 28.294414520263672,
      "learning_rate": 2.307832128286949e-05,
      "loss": 0.3193,
      "step": 13830
    },
    {
      "epoch": 1.643900700795819,
      "grad_norm": 44.659751892089844,
      "learning_rate": 2.3058124974754617e-05,
      "loss": 0.2796,
      "step": 13840
    },
    {
      "epoch": 1.6450884903195155,
      "grad_norm": 0.27370285987854004,
      "learning_rate": 2.303792866663974e-05,
      "loss": 0.321,
      "step": 13850
    },
    {
      "epoch": 1.6462762798432118,
      "grad_norm": 13.507660865783691,
      "learning_rate": 2.301773235852486e-05,
      "loss": 0.2025,
      "step": 13860
    },
    {
      "epoch": 1.647464069366908,
      "grad_norm": 1.5332928895950317,
      "learning_rate": 2.2997536050409987e-05,
      "loss": 0.0992,
      "step": 13870
    },
    {
      "epoch": 1.6486518588906045,
      "grad_norm": 12.967998504638672,
      "learning_rate": 2.297733974229511e-05,
      "loss": 0.2031,
      "step": 13880
    },
    {
      "epoch": 1.649839648414301,
      "grad_norm": 28.329179763793945,
      "learning_rate": 2.2957143434180234e-05,
      "loss": 0.4567,
      "step": 13890
    },
    {
      "epoch": 1.6510274379379974,
      "grad_norm": 0.7899869084358215,
      "learning_rate": 2.2936947126065356e-05,
      "loss": 0.0774,
      "step": 13900
    },
    {
      "epoch": 1.652215227461694,
      "grad_norm": 0.25732558965682983,
      "learning_rate": 2.291675081795048e-05,
      "loss": 0.2719,
      "step": 13910
    },
    {
      "epoch": 1.6534030169853902,
      "grad_norm": 7.7392964363098145,
      "learning_rate": 2.2896554509835603e-05,
      "loss": 0.3099,
      "step": 13920
    },
    {
      "epoch": 1.6545908065090866,
      "grad_norm": 6.33418083190918,
      "learning_rate": 2.2876358201720725e-05,
      "loss": 0.3405,
      "step": 13930
    },
    {
      "epoch": 1.6557785960327829,
      "grad_norm": 16.615055084228516,
      "learning_rate": 2.2856161893605847e-05,
      "loss": 0.2239,
      "step": 13940
    },
    {
      "epoch": 1.6569663855564793,
      "grad_norm": 0.464049369096756,
      "learning_rate": 2.2835965585490973e-05,
      "loss": 0.2372,
      "step": 13950
    },
    {
      "epoch": 1.6581541750801758,
      "grad_norm": 25.515695571899414,
      "learning_rate": 2.2815769277376098e-05,
      "loss": 0.5587,
      "step": 13960
    },
    {
      "epoch": 1.6593419646038723,
      "grad_norm": 16.29933738708496,
      "learning_rate": 2.279557296926122e-05,
      "loss": 0.3351,
      "step": 13970
    },
    {
      "epoch": 1.6605297541275688,
      "grad_norm": 30.536394119262695,
      "learning_rate": 2.2775376661146346e-05,
      "loss": 0.5213,
      "step": 13980
    },
    {
      "epoch": 1.661717543651265,
      "grad_norm": 0.6478565335273743,
      "learning_rate": 2.2755180353031468e-05,
      "loss": 0.3042,
      "step": 13990
    },
    {
      "epoch": 1.6629053331749613,
      "grad_norm": 0.3967480957508087,
      "learning_rate": 2.273498404491659e-05,
      "loss": 0.2369,
      "step": 14000
    },
    {
      "epoch": 1.6640931226986577,
      "grad_norm": 8.447564125061035,
      "learning_rate": 2.2714787736801712e-05,
      "loss": 0.234,
      "step": 14010
    },
    {
      "epoch": 1.6652809122223542,
      "grad_norm": 1.6700448989868164,
      "learning_rate": 2.2694591428686837e-05,
      "loss": 0.2378,
      "step": 14020
    },
    {
      "epoch": 1.6664687017460507,
      "grad_norm": 27.727787017822266,
      "learning_rate": 2.2674395120571963e-05,
      "loss": 0.4627,
      "step": 14030
    },
    {
      "epoch": 1.6676564912697471,
      "grad_norm": 9.249374389648438,
      "learning_rate": 2.2654198812457085e-05,
      "loss": 0.2976,
      "step": 14040
    },
    {
      "epoch": 1.6688442807934434,
      "grad_norm": 5.015416622161865,
      "learning_rate": 2.2634002504342207e-05,
      "loss": 0.4185,
      "step": 14050
    },
    {
      "epoch": 1.6700320703171398,
      "grad_norm": 19.136089324951172,
      "learning_rate": 2.261380619622733e-05,
      "loss": 0.3096,
      "step": 14060
    },
    {
      "epoch": 1.671219859840836,
      "grad_norm": 1.3242002725601196,
      "learning_rate": 2.2593609888112454e-05,
      "loss": 0.1752,
      "step": 14070
    },
    {
      "epoch": 1.6724076493645326,
      "grad_norm": 24.217262268066406,
      "learning_rate": 2.2573413579997576e-05,
      "loss": 0.3595,
      "step": 14080
    },
    {
      "epoch": 1.673595438888229,
      "grad_norm": 11.487687110900879,
      "learning_rate": 2.25532172718827e-05,
      "loss": 0.2294,
      "step": 14090
    },
    {
      "epoch": 1.6747832284119255,
      "grad_norm": 1.7999162673950195,
      "learning_rate": 2.2533020963767824e-05,
      "loss": 0.2981,
      "step": 14100
    },
    {
      "epoch": 1.6759710179356218,
      "grad_norm": 19.285221099853516,
      "learning_rate": 2.251282465565295e-05,
      "loss": 0.3908,
      "step": 14110
    },
    {
      "epoch": 1.6771588074593182,
      "grad_norm": 30.05069923400879,
      "learning_rate": 2.249262834753807e-05,
      "loss": 0.1872,
      "step": 14120
    },
    {
      "epoch": 1.6783465969830145,
      "grad_norm": 8.955550193786621,
      "learning_rate": 2.2472432039423193e-05,
      "loss": 0.4171,
      "step": 14130
    },
    {
      "epoch": 1.679534386506711,
      "grad_norm": 0.17622055113315582,
      "learning_rate": 2.245223573130832e-05,
      "loss": 0.1721,
      "step": 14140
    },
    {
      "epoch": 1.6807221760304074,
      "grad_norm": 13.302616119384766,
      "learning_rate": 2.243203942319344e-05,
      "loss": 0.1817,
      "step": 14150
    },
    {
      "epoch": 1.6819099655541039,
      "grad_norm": 15.319034576416016,
      "learning_rate": 2.2411843115078566e-05,
      "loss": 0.2609,
      "step": 14160
    },
    {
      "epoch": 1.6830977550778004,
      "grad_norm": 12.015340805053711,
      "learning_rate": 2.2391646806963688e-05,
      "loss": 0.339,
      "step": 14170
    },
    {
      "epoch": 1.6842855446014966,
      "grad_norm": 0.7180861830711365,
      "learning_rate": 2.2371450498848813e-05,
      "loss": 0.2425,
      "step": 14180
    },
    {
      "epoch": 1.685473334125193,
      "grad_norm": 6.026019096374512,
      "learning_rate": 2.2351254190733935e-05,
      "loss": 0.1519,
      "step": 14190
    },
    {
      "epoch": 1.6866611236488893,
      "grad_norm": 7.214142799377441,
      "learning_rate": 2.2331057882619057e-05,
      "loss": 0.1948,
      "step": 14200
    },
    {
      "epoch": 1.6878489131725858,
      "grad_norm": 18.228729248046875,
      "learning_rate": 2.2310861574504183e-05,
      "loss": 0.3553,
      "step": 14210
    },
    {
      "epoch": 1.6890367026962823,
      "grad_norm": 14.122106552124023,
      "learning_rate": 2.2290665266389305e-05,
      "loss": 0.1513,
      "step": 14220
    },
    {
      "epoch": 1.6902244922199787,
      "grad_norm": 32.075775146484375,
      "learning_rate": 2.227046895827443e-05,
      "loss": 0.3324,
      "step": 14230
    },
    {
      "epoch": 1.691412281743675,
      "grad_norm": 31.447736740112305,
      "learning_rate": 2.2250272650159552e-05,
      "loss": 0.4607,
      "step": 14240
    },
    {
      "epoch": 1.6926000712673714,
      "grad_norm": 20.658838272094727,
      "learning_rate": 2.2230076342044674e-05,
      "loss": 0.1701,
      "step": 14250
    },
    {
      "epoch": 1.6937878607910677,
      "grad_norm": 8.854974746704102,
      "learning_rate": 2.2209880033929796e-05,
      "loss": 0.286,
      "step": 14260
    },
    {
      "epoch": 1.6949756503147642,
      "grad_norm": 41.947471618652344,
      "learning_rate": 2.218968372581492e-05,
      "loss": 0.2008,
      "step": 14270
    },
    {
      "epoch": 1.6961634398384606,
      "grad_norm": 31.928224563598633,
      "learning_rate": 2.2169487417700047e-05,
      "loss": 0.3921,
      "step": 14280
    },
    {
      "epoch": 1.697351229362157,
      "grad_norm": 32.79322052001953,
      "learning_rate": 2.214929110958517e-05,
      "loss": 0.3372,
      "step": 14290
    },
    {
      "epoch": 1.6985390188858536,
      "grad_norm": 7.251918792724609,
      "learning_rate": 2.2129094801470294e-05,
      "loss": 0.1643,
      "step": 14300
    },
    {
      "epoch": 1.6997268084095498,
      "grad_norm": 0.18271446228027344,
      "learning_rate": 2.2108898493355416e-05,
      "loss": 0.5136,
      "step": 14310
    },
    {
      "epoch": 1.700914597933246,
      "grad_norm": 0.21846191585063934,
      "learning_rate": 2.208870218524054e-05,
      "loss": 0.3959,
      "step": 14320
    },
    {
      "epoch": 1.7021023874569425,
      "grad_norm": 1.1854829788208008,
      "learning_rate": 2.206850587712566e-05,
      "loss": 0.2083,
      "step": 14330
    },
    {
      "epoch": 1.703290176980639,
      "grad_norm": 0.202267125248909,
      "learning_rate": 2.2048309569010786e-05,
      "loss": 0.2957,
      "step": 14340
    },
    {
      "epoch": 1.7044779665043355,
      "grad_norm": 19.48366928100586,
      "learning_rate": 2.202811326089591e-05,
      "loss": 0.2631,
      "step": 14350
    },
    {
      "epoch": 1.705665756028032,
      "grad_norm": 0.32781484723091125,
      "learning_rate": 2.2007916952781033e-05,
      "loss": 0.4214,
      "step": 14360
    },
    {
      "epoch": 1.7068535455517282,
      "grad_norm": 45.345455169677734,
      "learning_rate": 2.198772064466616e-05,
      "loss": 0.2964,
      "step": 14370
    },
    {
      "epoch": 1.7080413350754247,
      "grad_norm": 0.16750560700893402,
      "learning_rate": 2.1967524336551277e-05,
      "loss": 0.3054,
      "step": 14380
    },
    {
      "epoch": 1.709229124599121,
      "grad_norm": 1.6322746276855469,
      "learning_rate": 2.1947328028436403e-05,
      "loss": 0.1648,
      "step": 14390
    },
    {
      "epoch": 1.7104169141228174,
      "grad_norm": 13.531867027282715,
      "learning_rate": 2.1927131720321525e-05,
      "loss": 0.3225,
      "step": 14400
    },
    {
      "epoch": 1.7116047036465138,
      "grad_norm": 26.489513397216797,
      "learning_rate": 2.190693541220665e-05,
      "loss": 0.3252,
      "step": 14410
    },
    {
      "epoch": 1.7127924931702103,
      "grad_norm": 12.352659225463867,
      "learning_rate": 2.1886739104091772e-05,
      "loss": 0.2196,
      "step": 14420
    },
    {
      "epoch": 1.7139802826939068,
      "grad_norm": 14.548524856567383,
      "learning_rate": 2.1866542795976898e-05,
      "loss": 0.266,
      "step": 14430
    },
    {
      "epoch": 1.715168072217603,
      "grad_norm": 28.68492317199707,
      "learning_rate": 2.184634648786202e-05,
      "loss": 0.1907,
      "step": 14440
    },
    {
      "epoch": 1.7163558617412993,
      "grad_norm": 3.999053955078125,
      "learning_rate": 2.182615017974714e-05,
      "loss": 0.3398,
      "step": 14450
    },
    {
      "epoch": 1.7175436512649958,
      "grad_norm": 0.24547652900218964,
      "learning_rate": 2.1805953871632267e-05,
      "loss": 0.3906,
      "step": 14460
    },
    {
      "epoch": 1.7187314407886922,
      "grad_norm": 7.416358947753906,
      "learning_rate": 2.178575756351739e-05,
      "loss": 0.4012,
      "step": 14470
    },
    {
      "epoch": 1.7199192303123887,
      "grad_norm": 13.117854118347168,
      "learning_rate": 2.1765561255402514e-05,
      "loss": 0.4511,
      "step": 14480
    },
    {
      "epoch": 1.7211070198360852,
      "grad_norm": 11.666315078735352,
      "learning_rate": 2.1745364947287637e-05,
      "loss": 0.3516,
      "step": 14490
    },
    {
      "epoch": 1.7222948093597814,
      "grad_norm": 25.490760803222656,
      "learning_rate": 2.1725168639172762e-05,
      "loss": 0.1293,
      "step": 14500
    },
    {
      "epoch": 1.7234825988834779,
      "grad_norm": 54.417335510253906,
      "learning_rate": 2.1704972331057884e-05,
      "loss": 0.1978,
      "step": 14510
    },
    {
      "epoch": 1.7246703884071741,
      "grad_norm": 4.990489482879639,
      "learning_rate": 2.1684776022943006e-05,
      "loss": 0.2659,
      "step": 14520
    },
    {
      "epoch": 1.7258581779308706,
      "grad_norm": 34.4296875,
      "learning_rate": 2.166457971482813e-05,
      "loss": 0.3182,
      "step": 14530
    },
    {
      "epoch": 1.727045967454567,
      "grad_norm": 10.460498809814453,
      "learning_rate": 2.1644383406713253e-05,
      "loss": 0.2666,
      "step": 14540
    },
    {
      "epoch": 1.7282337569782635,
      "grad_norm": 8.423528671264648,
      "learning_rate": 2.162418709859838e-05,
      "loss": 0.2385,
      "step": 14550
    },
    {
      "epoch": 1.72942154650196,
      "grad_norm": 21.11067771911621,
      "learning_rate": 2.16039907904835e-05,
      "loss": 0.2367,
      "step": 14560
    },
    {
      "epoch": 1.7306093360256563,
      "grad_norm": 2.2906060218811035,
      "learning_rate": 2.1583794482368623e-05,
      "loss": 0.3841,
      "step": 14570
    },
    {
      "epoch": 1.7317971255493525,
      "grad_norm": 21.176719665527344,
      "learning_rate": 2.1563598174253745e-05,
      "loss": 0.4004,
      "step": 14580
    },
    {
      "epoch": 1.732984915073049,
      "grad_norm": 29.707111358642578,
      "learning_rate": 2.154340186613887e-05,
      "loss": 0.2719,
      "step": 14590
    },
    {
      "epoch": 1.7341727045967454,
      "grad_norm": 4.010573387145996,
      "learning_rate": 2.1523205558023996e-05,
      "loss": 0.2443,
      "step": 14600
    },
    {
      "epoch": 1.735360494120442,
      "grad_norm": 11.310073852539062,
      "learning_rate": 2.1503009249909118e-05,
      "loss": 0.2312,
      "step": 14610
    },
    {
      "epoch": 1.7365482836441384,
      "grad_norm": 0.21687401831150055,
      "learning_rate": 2.1482812941794243e-05,
      "loss": 0.241,
      "step": 14620
    },
    {
      "epoch": 1.7377360731678346,
      "grad_norm": 43.100860595703125,
      "learning_rate": 2.1462616633679365e-05,
      "loss": 0.3265,
      "step": 14630
    },
    {
      "epoch": 1.738923862691531,
      "grad_norm": 7.605052947998047,
      "learning_rate": 2.1442420325564487e-05,
      "loss": 0.1515,
      "step": 14640
    },
    {
      "epoch": 1.7401116522152273,
      "grad_norm": 0.8148497343063354,
      "learning_rate": 2.142222401744961e-05,
      "loss": 0.2599,
      "step": 14650
    },
    {
      "epoch": 1.7412994417389238,
      "grad_norm": 19.524444580078125,
      "learning_rate": 2.1402027709334735e-05,
      "loss": 0.3439,
      "step": 14660
    },
    {
      "epoch": 1.7424872312626203,
      "grad_norm": 17.170162200927734,
      "learning_rate": 2.1381831401219857e-05,
      "loss": 0.4192,
      "step": 14670
    },
    {
      "epoch": 1.7436750207863168,
      "grad_norm": 1.648471713066101,
      "learning_rate": 2.1361635093104982e-05,
      "loss": 0.3879,
      "step": 14680
    },
    {
      "epoch": 1.7448628103100132,
      "grad_norm": 47.231815338134766,
      "learning_rate": 2.1341438784990107e-05,
      "loss": 0.3076,
      "step": 14690
    },
    {
      "epoch": 1.7460505998337095,
      "grad_norm": 7.377106666564941,
      "learning_rate": 2.132124247687523e-05,
      "loss": 0.23,
      "step": 14700
    },
    {
      "epoch": 1.7472383893574057,
      "grad_norm": 39.76481628417969,
      "learning_rate": 2.130104616876035e-05,
      "loss": 0.2482,
      "step": 14710
    },
    {
      "epoch": 1.7484261788811022,
      "grad_norm": 1.3001961708068848,
      "learning_rate": 2.1280849860645473e-05,
      "loss": 0.2381,
      "step": 14720
    },
    {
      "epoch": 1.7496139684047987,
      "grad_norm": 22.954126358032227,
      "learning_rate": 2.12606535525306e-05,
      "loss": 0.2353,
      "step": 14730
    },
    {
      "epoch": 1.7508017579284951,
      "grad_norm": 24.78125,
      "learning_rate": 2.124045724441572e-05,
      "loss": 0.1943,
      "step": 14740
    },
    {
      "epoch": 1.7519895474521916,
      "grad_norm": 19.170001983642578,
      "learning_rate": 2.1220260936300846e-05,
      "loss": 0.3334,
      "step": 14750
    },
    {
      "epoch": 1.7531773369758878,
      "grad_norm": 9.581551551818848,
      "learning_rate": 2.120006462818597e-05,
      "loss": 0.2391,
      "step": 14760
    },
    {
      "epoch": 1.7543651264995843,
      "grad_norm": 4.822634220123291,
      "learning_rate": 2.117986832007109e-05,
      "loss": 0.2452,
      "step": 14770
    },
    {
      "epoch": 1.7555529160232806,
      "grad_norm": 24.613969802856445,
      "learning_rate": 2.1159672011956216e-05,
      "loss": 0.2909,
      "step": 14780
    },
    {
      "epoch": 1.756740705546977,
      "grad_norm": 16.120914459228516,
      "learning_rate": 2.1139475703841338e-05,
      "loss": 0.2872,
      "step": 14790
    },
    {
      "epoch": 1.7579284950706735,
      "grad_norm": 10.241340637207031,
      "learning_rate": 2.1119279395726463e-05,
      "loss": 0.3295,
      "step": 14800
    },
    {
      "epoch": 1.75911628459437,
      "grad_norm": 4.994508743286133,
      "learning_rate": 2.1099083087611585e-05,
      "loss": 0.3676,
      "step": 14810
    },
    {
      "epoch": 1.7603040741180664,
      "grad_norm": 2.3226959705352783,
      "learning_rate": 2.107888677949671e-05,
      "loss": 0.2489,
      "step": 14820
    },
    {
      "epoch": 1.7614918636417627,
      "grad_norm": 2.9005095958709717,
      "learning_rate": 2.1058690471381833e-05,
      "loss": 0.1929,
      "step": 14830
    },
    {
      "epoch": 1.762679653165459,
      "grad_norm": 2.8588762283325195,
      "learning_rate": 2.1038494163266955e-05,
      "loss": 0.2501,
      "step": 14840
    },
    {
      "epoch": 1.7638674426891554,
      "grad_norm": 0.7694858312606812,
      "learning_rate": 2.101829785515208e-05,
      "loss": 0.1963,
      "step": 14850
    },
    {
      "epoch": 1.7650552322128519,
      "grad_norm": 15.17210865020752,
      "learning_rate": 2.0998101547037202e-05,
      "loss": 0.185,
      "step": 14860
    },
    {
      "epoch": 1.7662430217365483,
      "grad_norm": 19.9705810546875,
      "learning_rate": 2.0977905238922327e-05,
      "loss": 0.1404,
      "step": 14870
    },
    {
      "epoch": 1.7674308112602448,
      "grad_norm": 26.882183074951172,
      "learning_rate": 2.095770893080745e-05,
      "loss": 0.1498,
      "step": 14880
    },
    {
      "epoch": 1.768618600783941,
      "grad_norm": 31.350112915039062,
      "learning_rate": 2.0937512622692575e-05,
      "loss": 0.4217,
      "step": 14890
    },
    {
      "epoch": 1.7698063903076375,
      "grad_norm": 38.901695251464844,
      "learning_rate": 2.0917316314577694e-05,
      "loss": 0.4146,
      "step": 14900
    },
    {
      "epoch": 1.7709941798313338,
      "grad_norm": 7.314798831939697,
      "learning_rate": 2.089712000646282e-05,
      "loss": 0.2323,
      "step": 14910
    },
    {
      "epoch": 1.7721819693550303,
      "grad_norm": 5.264237880706787,
      "learning_rate": 2.0876923698347944e-05,
      "loss": 0.3026,
      "step": 14920
    },
    {
      "epoch": 1.7733697588787267,
      "grad_norm": 7.3691558837890625,
      "learning_rate": 2.0856727390233066e-05,
      "loss": 0.3691,
      "step": 14930
    },
    {
      "epoch": 1.7745575484024232,
      "grad_norm": 0.5976560711860657,
      "learning_rate": 2.0836531082118192e-05,
      "loss": 0.264,
      "step": 14940
    },
    {
      "epoch": 1.7757453379261194,
      "grad_norm": 36.52761459350586,
      "learning_rate": 2.0816334774003314e-05,
      "loss": 0.3759,
      "step": 14950
    },
    {
      "epoch": 1.776933127449816,
      "grad_norm": 27.307968139648438,
      "learning_rate": 2.0796138465888436e-05,
      "loss": 0.5049,
      "step": 14960
    },
    {
      "epoch": 1.7781209169735122,
      "grad_norm": 12.018332481384277,
      "learning_rate": 2.0775942157773558e-05,
      "loss": 0.2594,
      "step": 14970
    },
    {
      "epoch": 1.7793087064972086,
      "grad_norm": 0.7641359567642212,
      "learning_rate": 2.0755745849658683e-05,
      "loss": 0.2611,
      "step": 14980
    },
    {
      "epoch": 1.780496496020905,
      "grad_norm": 5.840832233428955,
      "learning_rate": 2.0735549541543805e-05,
      "loss": 0.1865,
      "step": 14990
    },
    {
      "epoch": 1.7816842855446016,
      "grad_norm": 0.7252019047737122,
      "learning_rate": 2.071535323342893e-05,
      "loss": 0.2135,
      "step": 15000
    },
    {
      "epoch": 1.782872075068298,
      "grad_norm": 2.9648282527923584,
      "learning_rate": 2.0695156925314056e-05,
      "loss": 0.4921,
      "step": 15010
    },
    {
      "epoch": 1.7840598645919943,
      "grad_norm": 3.853459358215332,
      "learning_rate": 2.0674960617199178e-05,
      "loss": 0.2267,
      "step": 15020
    },
    {
      "epoch": 1.7852476541156908,
      "grad_norm": 36.72010040283203,
      "learning_rate": 2.06547643090843e-05,
      "loss": 0.737,
      "step": 15030
    },
    {
      "epoch": 1.786435443639387,
      "grad_norm": 3.268296003341675,
      "learning_rate": 2.0634568000969422e-05,
      "loss": 0.3838,
      "step": 15040
    },
    {
      "epoch": 1.7876232331630835,
      "grad_norm": 12.728361129760742,
      "learning_rate": 2.0614371692854548e-05,
      "loss": 0.3544,
      "step": 15050
    },
    {
      "epoch": 1.78881102268678,
      "grad_norm": 0.9806528687477112,
      "learning_rate": 2.059417538473967e-05,
      "loss": 0.1736,
      "step": 15060
    },
    {
      "epoch": 1.7899988122104764,
      "grad_norm": 17.739673614501953,
      "learning_rate": 2.0573979076624795e-05,
      "loss": 0.4161,
      "step": 15070
    },
    {
      "epoch": 1.7911866017341727,
      "grad_norm": 13.04822826385498,
      "learning_rate": 2.0553782768509917e-05,
      "loss": 0.2414,
      "step": 15080
    },
    {
      "epoch": 1.7923743912578691,
      "grad_norm": 16.34589195251465,
      "learning_rate": 2.053358646039504e-05,
      "loss": 0.2522,
      "step": 15090
    },
    {
      "epoch": 1.7935621807815654,
      "grad_norm": 0.5406787395477295,
      "learning_rate": 2.0513390152280164e-05,
      "loss": 0.3639,
      "step": 15100
    },
    {
      "epoch": 1.7947499703052618,
      "grad_norm": 38.567108154296875,
      "learning_rate": 2.0493193844165286e-05,
      "loss": 0.3233,
      "step": 15110
    },
    {
      "epoch": 1.7959377598289583,
      "grad_norm": 0.13544973731040955,
      "learning_rate": 2.0472997536050412e-05,
      "loss": 0.0611,
      "step": 15120
    },
    {
      "epoch": 1.7971255493526548,
      "grad_norm": 38.05567169189453,
      "learning_rate": 2.0452801227935534e-05,
      "loss": 0.0767,
      "step": 15130
    },
    {
      "epoch": 1.7983133388763513,
      "grad_norm": 15.420433044433594,
      "learning_rate": 2.043260491982066e-05,
      "loss": 0.2286,
      "step": 15140
    },
    {
      "epoch": 1.7995011284000475,
      "grad_norm": 6.0287981033325195,
      "learning_rate": 2.041240861170578e-05,
      "loss": 0.2623,
      "step": 15150
    },
    {
      "epoch": 1.8006889179237437,
      "grad_norm": 13.863151550292969,
      "learning_rate": 2.0392212303590903e-05,
      "loss": 0.1771,
      "step": 15160
    },
    {
      "epoch": 1.8018767074474402,
      "grad_norm": 5.484208583831787,
      "learning_rate": 2.037201599547603e-05,
      "loss": 0.3482,
      "step": 15170
    },
    {
      "epoch": 1.8030644969711367,
      "grad_norm": 0.2706778049468994,
      "learning_rate": 2.035181968736115e-05,
      "loss": 0.2929,
      "step": 15180
    },
    {
      "epoch": 1.8042522864948332,
      "grad_norm": 12.524858474731445,
      "learning_rate": 2.0331623379246276e-05,
      "loss": 0.3383,
      "step": 15190
    },
    {
      "epoch": 1.8054400760185296,
      "grad_norm": 0.2081393301486969,
      "learning_rate": 2.0311427071131398e-05,
      "loss": 0.2181,
      "step": 15200
    },
    {
      "epoch": 1.8066278655422259,
      "grad_norm": 0.7429483532905579,
      "learning_rate": 2.0291230763016524e-05,
      "loss": 0.2644,
      "step": 15210
    },
    {
      "epoch": 1.8078156550659223,
      "grad_norm": 24.5756778717041,
      "learning_rate": 2.0271034454901646e-05,
      "loss": 0.1838,
      "step": 15220
    },
    {
      "epoch": 1.8090034445896186,
      "grad_norm": 1.5865975618362427,
      "learning_rate": 2.0250838146786768e-05,
      "loss": 0.2874,
      "step": 15230
    },
    {
      "epoch": 1.810191234113315,
      "grad_norm": 5.804121494293213,
      "learning_rate": 2.023064183867189e-05,
      "loss": 0.4418,
      "step": 15240
    },
    {
      "epoch": 1.8113790236370115,
      "grad_norm": 23.587623596191406,
      "learning_rate": 2.0210445530557015e-05,
      "loss": 0.2982,
      "step": 15250
    },
    {
      "epoch": 1.812566813160708,
      "grad_norm": 1.9106407165527344,
      "learning_rate": 2.019024922244214e-05,
      "loss": 0.3289,
      "step": 15260
    },
    {
      "epoch": 1.8137546026844045,
      "grad_norm": 12.053060531616211,
      "learning_rate": 2.0170052914327263e-05,
      "loss": 0.3319,
      "step": 15270
    },
    {
      "epoch": 1.8149423922081007,
      "grad_norm": 0.2481435090303421,
      "learning_rate": 2.0149856606212385e-05,
      "loss": 0.3286,
      "step": 15280
    },
    {
      "epoch": 1.816130181731797,
      "grad_norm": 14.712221145629883,
      "learning_rate": 2.0129660298097507e-05,
      "loss": 0.2633,
      "step": 15290
    },
    {
      "epoch": 1.8173179712554934,
      "grad_norm": 33.18830871582031,
      "learning_rate": 2.0109463989982632e-05,
      "loss": 0.3528,
      "step": 15300
    },
    {
      "epoch": 1.81850576077919,
      "grad_norm": 35.27165603637695,
      "learning_rate": 2.0089267681867754e-05,
      "loss": 0.1134,
      "step": 15310
    },
    {
      "epoch": 1.8196935503028864,
      "grad_norm": 2.9073824882507324,
      "learning_rate": 2.006907137375288e-05,
      "loss": 0.1853,
      "step": 15320
    },
    {
      "epoch": 1.8208813398265828,
      "grad_norm": 37.49239730834961,
      "learning_rate": 2.0048875065638005e-05,
      "loss": 0.3672,
      "step": 15330
    },
    {
      "epoch": 1.822069129350279,
      "grad_norm": 10.660308837890625,
      "learning_rate": 2.0028678757523127e-05,
      "loss": 0.3475,
      "step": 15340
    },
    {
      "epoch": 1.8232569188739756,
      "grad_norm": 25.128673553466797,
      "learning_rate": 2.000848244940825e-05,
      "loss": 0.3598,
      "step": 15350
    },
    {
      "epoch": 1.8244447083976718,
      "grad_norm": 2.814429998397827,
      "learning_rate": 1.998828614129337e-05,
      "loss": 0.2593,
      "step": 15360
    },
    {
      "epoch": 1.8256324979213683,
      "grad_norm": 0.6425321102142334,
      "learning_rate": 1.9968089833178496e-05,
      "loss": 0.3037,
      "step": 15370
    },
    {
      "epoch": 1.8268202874450647,
      "grad_norm": 12.280265808105469,
      "learning_rate": 1.9947893525063618e-05,
      "loss": 0.3971,
      "step": 15380
    },
    {
      "epoch": 1.8280080769687612,
      "grad_norm": 19.86573600769043,
      "learning_rate": 1.9927697216948744e-05,
      "loss": 0.2696,
      "step": 15390
    },
    {
      "epoch": 1.8291958664924577,
      "grad_norm": 15.69439697265625,
      "learning_rate": 1.9907500908833866e-05,
      "loss": 0.2942,
      "step": 15400
    },
    {
      "epoch": 1.830383656016154,
      "grad_norm": 47.90037155151367,
      "learning_rate": 1.988730460071899e-05,
      "loss": 0.2598,
      "step": 15410
    },
    {
      "epoch": 1.8315714455398502,
      "grad_norm": 5.202155113220215,
      "learning_rate": 1.9867108292604113e-05,
      "loss": 0.2275,
      "step": 15420
    },
    {
      "epoch": 1.8327592350635467,
      "grad_norm": 7.086042404174805,
      "learning_rate": 1.9846911984489235e-05,
      "loss": 0.3026,
      "step": 15430
    },
    {
      "epoch": 1.8339470245872431,
      "grad_norm": 27.757871627807617,
      "learning_rate": 1.982671567637436e-05,
      "loss": 0.3723,
      "step": 15440
    },
    {
      "epoch": 1.8351348141109396,
      "grad_norm": 0.37024641036987305,
      "learning_rate": 1.9806519368259483e-05,
      "loss": 0.2136,
      "step": 15450
    },
    {
      "epoch": 1.836322603634636,
      "grad_norm": 39.08124923706055,
      "learning_rate": 1.9786323060144608e-05,
      "loss": 0.2295,
      "step": 15460
    },
    {
      "epoch": 1.8375103931583323,
      "grad_norm": 6.219071865081787,
      "learning_rate": 1.976612675202973e-05,
      "loss": 0.3055,
      "step": 15470
    },
    {
      "epoch": 1.8386981826820288,
      "grad_norm": 0.7025518417358398,
      "learning_rate": 1.9745930443914852e-05,
      "loss": 0.116,
      "step": 15480
    },
    {
      "epoch": 1.839885972205725,
      "grad_norm": 27.3659610748291,
      "learning_rate": 1.9725734135799977e-05,
      "loss": 0.1438,
      "step": 15490
    },
    {
      "epoch": 1.8410737617294215,
      "grad_norm": 9.245842933654785,
      "learning_rate": 1.97055378276851e-05,
      "loss": 0.2236,
      "step": 15500
    },
    {
      "epoch": 1.842261551253118,
      "grad_norm": 0.2252853363752365,
      "learning_rate": 1.9685341519570225e-05,
      "loss": 0.1899,
      "step": 15510
    },
    {
      "epoch": 1.8434493407768144,
      "grad_norm": 21.966426849365234,
      "learning_rate": 1.9665145211455347e-05,
      "loss": 0.3288,
      "step": 15520
    },
    {
      "epoch": 1.844637130300511,
      "grad_norm": 27.694141387939453,
      "learning_rate": 1.9644948903340472e-05,
      "loss": 0.1473,
      "step": 15530
    },
    {
      "epoch": 1.8458249198242072,
      "grad_norm": 0.2502343952655792,
      "learning_rate": 1.9624752595225594e-05,
      "loss": 0.267,
      "step": 15540
    },
    {
      "epoch": 1.8470127093479034,
      "grad_norm": 11.234996795654297,
      "learning_rate": 1.9604556287110716e-05,
      "loss": 0.3373,
      "step": 15550
    },
    {
      "epoch": 1.8482004988715999,
      "grad_norm": 0.42687684297561646,
      "learning_rate": 1.958435997899584e-05,
      "loss": 0.0905,
      "step": 15560
    },
    {
      "epoch": 1.8493882883952963,
      "grad_norm": 9.056336402893066,
      "learning_rate": 1.9564163670880964e-05,
      "loss": 0.2888,
      "step": 15570
    },
    {
      "epoch": 1.8505760779189928,
      "grad_norm": 16.29376983642578,
      "learning_rate": 1.954396736276609e-05,
      "loss": 0.4132,
      "step": 15580
    },
    {
      "epoch": 1.8517638674426893,
      "grad_norm": 0.6978160738945007,
      "learning_rate": 1.952377105465121e-05,
      "loss": 0.3986,
      "step": 15590
    },
    {
      "epoch": 1.8529516569663855,
      "grad_norm": 35.88385772705078,
      "learning_rate": 1.9503574746536337e-05,
      "loss": 0.2663,
      "step": 15600
    },
    {
      "epoch": 1.854139446490082,
      "grad_norm": 3.38065242767334,
      "learning_rate": 1.9483378438421455e-05,
      "loss": 0.3183,
      "step": 15610
    },
    {
      "epoch": 1.8553272360137782,
      "grad_norm": 29.7296085357666,
      "learning_rate": 1.946318213030658e-05,
      "loss": 0.2748,
      "step": 15620
    },
    {
      "epoch": 1.8565150255374747,
      "grad_norm": 0.654832661151886,
      "learning_rate": 1.9442985822191703e-05,
      "loss": 0.2402,
      "step": 15630
    },
    {
      "epoch": 1.8577028150611712,
      "grad_norm": 26.771121978759766,
      "learning_rate": 1.9422789514076828e-05,
      "loss": 0.4469,
      "step": 15640
    },
    {
      "epoch": 1.8588906045848677,
      "grad_norm": 47.14453887939453,
      "learning_rate": 1.940259320596195e-05,
      "loss": 0.2941,
      "step": 15650
    },
    {
      "epoch": 1.8600783941085641,
      "grad_norm": 39.1800422668457,
      "learning_rate": 1.9382396897847076e-05,
      "loss": 0.3859,
      "step": 15660
    },
    {
      "epoch": 1.8612661836322604,
      "grad_norm": 0.20109805464744568,
      "learning_rate": 1.9362200589732198e-05,
      "loss": 0.2116,
      "step": 15670
    },
    {
      "epoch": 1.8624539731559566,
      "grad_norm": 2.36057186126709,
      "learning_rate": 1.934200428161732e-05,
      "loss": 0.182,
      "step": 15680
    },
    {
      "epoch": 1.863641762679653,
      "grad_norm": 40.106170654296875,
      "learning_rate": 1.9321807973502445e-05,
      "loss": 0.3429,
      "step": 15690
    },
    {
      "epoch": 1.8648295522033496,
      "grad_norm": 25.17957305908203,
      "learning_rate": 1.9301611665387567e-05,
      "loss": 0.3997,
      "step": 15700
    },
    {
      "epoch": 1.866017341727046,
      "grad_norm": 4.590366840362549,
      "learning_rate": 1.9281415357272692e-05,
      "loss": 0.2996,
      "step": 15710
    },
    {
      "epoch": 1.8672051312507425,
      "grad_norm": 9.886308670043945,
      "learning_rate": 1.9261219049157814e-05,
      "loss": 0.4596,
      "step": 15720
    },
    {
      "epoch": 1.8683929207744387,
      "grad_norm": 14.60071849822998,
      "learning_rate": 1.924102274104294e-05,
      "loss": 0.2897,
      "step": 15730
    },
    {
      "epoch": 1.8695807102981352,
      "grad_norm": 2.2663161754608154,
      "learning_rate": 1.9220826432928062e-05,
      "loss": 0.1644,
      "step": 15740
    },
    {
      "epoch": 1.8707684998218315,
      "grad_norm": 3.2839033603668213,
      "learning_rate": 1.9200630124813184e-05,
      "loss": 0.2659,
      "step": 15750
    },
    {
      "epoch": 1.871956289345528,
      "grad_norm": 1.8465121984481812,
      "learning_rate": 1.918043381669831e-05,
      "loss": 0.2934,
      "step": 15760
    },
    {
      "epoch": 1.8731440788692244,
      "grad_norm": 10.046259880065918,
      "learning_rate": 1.916023750858343e-05,
      "loss": 0.2955,
      "step": 15770
    },
    {
      "epoch": 1.8743318683929209,
      "grad_norm": 0.1475881040096283,
      "learning_rate": 1.9140041200468557e-05,
      "loss": 0.2151,
      "step": 15780
    },
    {
      "epoch": 1.8755196579166171,
      "grad_norm": 12.03223991394043,
      "learning_rate": 1.911984489235368e-05,
      "loss": 0.196,
      "step": 15790
    },
    {
      "epoch": 1.8767074474403136,
      "grad_norm": 4.09650993347168,
      "learning_rate": 1.90996485842388e-05,
      "loss": 0.2262,
      "step": 15800
    },
    {
      "epoch": 1.8778952369640098,
      "grad_norm": 1.7524662017822266,
      "learning_rate": 1.9079452276123923e-05,
      "loss": 0.2532,
      "step": 15810
    },
    {
      "epoch": 1.8790830264877063,
      "grad_norm": 12.199525833129883,
      "learning_rate": 1.9059255968009048e-05,
      "loss": 0.2956,
      "step": 15820
    },
    {
      "epoch": 1.8802708160114028,
      "grad_norm": 37.11639404296875,
      "learning_rate": 1.9039059659894174e-05,
      "loss": 0.5039,
      "step": 15830
    },
    {
      "epoch": 1.8814586055350992,
      "grad_norm": 39.041297912597656,
      "learning_rate": 1.9018863351779296e-05,
      "loss": 0.2785,
      "step": 15840
    },
    {
      "epoch": 1.8826463950587957,
      "grad_norm": 20.802942276000977,
      "learning_rate": 1.899866704366442e-05,
      "loss": 0.2972,
      "step": 15850
    },
    {
      "epoch": 1.883834184582492,
      "grad_norm": 0.5263732075691223,
      "learning_rate": 1.8978470735549543e-05,
      "loss": 0.121,
      "step": 15860
    },
    {
      "epoch": 1.8850219741061884,
      "grad_norm": 27.127437591552734,
      "learning_rate": 1.8958274427434665e-05,
      "loss": 0.2062,
      "step": 15870
    },
    {
      "epoch": 1.8862097636298847,
      "grad_norm": 18.71335220336914,
      "learning_rate": 1.8938078119319787e-05,
      "loss": 0.3099,
      "step": 15880
    },
    {
      "epoch": 1.8873975531535812,
      "grad_norm": 49.714447021484375,
      "learning_rate": 1.8917881811204912e-05,
      "loss": 0.349,
      "step": 15890
    },
    {
      "epoch": 1.8885853426772776,
      "grad_norm": 0.24169571697711945,
      "learning_rate": 1.8897685503090038e-05,
      "loss": 0.32,
      "step": 15900
    },
    {
      "epoch": 1.889773132200974,
      "grad_norm": 7.706589698791504,
      "learning_rate": 1.887748919497516e-05,
      "loss": 0.4405,
      "step": 15910
    },
    {
      "epoch": 1.8909609217246703,
      "grad_norm": 22.328527450561523,
      "learning_rate": 1.8857292886860285e-05,
      "loss": 0.1836,
      "step": 15920
    },
    {
      "epoch": 1.8921487112483668,
      "grad_norm": 14.202587127685547,
      "learning_rate": 1.8837096578745407e-05,
      "loss": 0.3861,
      "step": 15930
    },
    {
      "epoch": 1.893336500772063,
      "grad_norm": 3.6924376487731934,
      "learning_rate": 1.881690027063053e-05,
      "loss": 0.2285,
      "step": 15940
    },
    {
      "epoch": 1.8945242902957595,
      "grad_norm": 8.773077011108398,
      "learning_rate": 1.879670396251565e-05,
      "loss": 0.2788,
      "step": 15950
    },
    {
      "epoch": 1.895712079819456,
      "grad_norm": 0.3175797760486603,
      "learning_rate": 1.8776507654400777e-05,
      "loss": 0.2195,
      "step": 15960
    },
    {
      "epoch": 1.8968998693431525,
      "grad_norm": 7.312729358673096,
      "learning_rate": 1.87563113462859e-05,
      "loss": 0.355,
      "step": 15970
    },
    {
      "epoch": 1.898087658866849,
      "grad_norm": 1.0230584144592285,
      "learning_rate": 1.8736115038171024e-05,
      "loss": 0.3853,
      "step": 15980
    },
    {
      "epoch": 1.8992754483905452,
      "grad_norm": 4.293715000152588,
      "learning_rate": 1.8715918730056146e-05,
      "loss": 0.3266,
      "step": 15990
    },
    {
      "epoch": 1.9004632379142414,
      "grad_norm": 13.481009483337402,
      "learning_rate": 1.8695722421941268e-05,
      "loss": 0.309,
      "step": 16000
    },
    {
      "epoch": 1.901651027437938,
      "grad_norm": 0.2017102837562561,
      "learning_rate": 1.8675526113826394e-05,
      "loss": 0.4579,
      "step": 16010
    },
    {
      "epoch": 1.9028388169616344,
      "grad_norm": 23.637535095214844,
      "learning_rate": 1.8655329805711516e-05,
      "loss": 0.2397,
      "step": 16020
    },
    {
      "epoch": 1.9040266064853308,
      "grad_norm": 8.644454002380371,
      "learning_rate": 1.863513349759664e-05,
      "loss": 0.2191,
      "step": 16030
    },
    {
      "epoch": 1.9052143960090273,
      "grad_norm": 4.221837997436523,
      "learning_rate": 1.8614937189481763e-05,
      "loss": 0.3499,
      "step": 16040
    },
    {
      "epoch": 1.9064021855327236,
      "grad_norm": 10.502230644226074,
      "learning_rate": 1.859474088136689e-05,
      "loss": 0.2108,
      "step": 16050
    },
    {
      "epoch": 1.90758997505642,
      "grad_norm": 5.608504772186279,
      "learning_rate": 1.857454457325201e-05,
      "loss": 0.4429,
      "step": 16060
    },
    {
      "epoch": 1.9087777645801163,
      "grad_norm": 4.396934509277344,
      "learning_rate": 1.8554348265137133e-05,
      "loss": 0.0287,
      "step": 16070
    },
    {
      "epoch": 1.9099655541038127,
      "grad_norm": 6.366587162017822,
      "learning_rate": 1.8534151957022258e-05,
      "loss": 0.4629,
      "step": 16080
    },
    {
      "epoch": 1.9111533436275092,
      "grad_norm": 2.318875789642334,
      "learning_rate": 1.851395564890738e-05,
      "loss": 0.2655,
      "step": 16090
    },
    {
      "epoch": 1.9123411331512057,
      "grad_norm": 28.765958786010742,
      "learning_rate": 1.8493759340792505e-05,
      "loss": 0.2552,
      "step": 16100
    },
    {
      "epoch": 1.9135289226749022,
      "grad_norm": 24.127729415893555,
      "learning_rate": 1.8473563032677627e-05,
      "loss": 0.3738,
      "step": 16110
    },
    {
      "epoch": 1.9147167121985984,
      "grad_norm": 8.758345603942871,
      "learning_rate": 1.8453366724562753e-05,
      "loss": 0.4391,
      "step": 16120
    },
    {
      "epoch": 1.9159045017222947,
      "grad_norm": 0.6288900971412659,
      "learning_rate": 1.843317041644787e-05,
      "loss": 0.2367,
      "step": 16130
    },
    {
      "epoch": 1.9170922912459911,
      "grad_norm": 30.080768585205078,
      "learning_rate": 1.8412974108332997e-05,
      "loss": 0.2248,
      "step": 16140
    },
    {
      "epoch": 1.9182800807696876,
      "grad_norm": 2.398242950439453,
      "learning_rate": 1.8392777800218122e-05,
      "loss": 0.1724,
      "step": 16150
    },
    {
      "epoch": 1.919467870293384,
      "grad_norm": 1.6821235418319702,
      "learning_rate": 1.8372581492103244e-05,
      "loss": 0.2232,
      "step": 16160
    },
    {
      "epoch": 1.9206556598170805,
      "grad_norm": 0.5767159461975098,
      "learning_rate": 1.835238518398837e-05,
      "loss": 0.2932,
      "step": 16170
    },
    {
      "epoch": 1.9218434493407768,
      "grad_norm": 13.75768756866455,
      "learning_rate": 1.8332188875873492e-05,
      "loss": 0.2616,
      "step": 16180
    },
    {
      "epoch": 1.9230312388644732,
      "grad_norm": 22.95037841796875,
      "learning_rate": 1.8311992567758614e-05,
      "loss": 0.3559,
      "step": 16190
    },
    {
      "epoch": 1.9242190283881695,
      "grad_norm": 0.6336414217948914,
      "learning_rate": 1.8291796259643736e-05,
      "loss": 0.2076,
      "step": 16200
    },
    {
      "epoch": 1.925406817911866,
      "grad_norm": 0.9053276181221008,
      "learning_rate": 1.827159995152886e-05,
      "loss": 0.3095,
      "step": 16210
    },
    {
      "epoch": 1.9265946074355624,
      "grad_norm": 3.423809051513672,
      "learning_rate": 1.8251403643413983e-05,
      "loss": 0.3816,
      "step": 16220
    },
    {
      "epoch": 1.927782396959259,
      "grad_norm": 2.690134286880493,
      "learning_rate": 1.823120733529911e-05,
      "loss": 0.3824,
      "step": 16230
    },
    {
      "epoch": 1.9289701864829554,
      "grad_norm": 46.12049102783203,
      "learning_rate": 1.8211011027184234e-05,
      "loss": 0.1785,
      "step": 16240
    },
    {
      "epoch": 1.9301579760066516,
      "grad_norm": 0.2749311923980713,
      "learning_rate": 1.8190814719069356e-05,
      "loss": 0.1603,
      "step": 16250
    },
    {
      "epoch": 1.9313457655303479,
      "grad_norm": 1.1488959789276123,
      "learning_rate": 1.8170618410954478e-05,
      "loss": 0.4104,
      "step": 16260
    },
    {
      "epoch": 1.9325335550540443,
      "grad_norm": 28.701562881469727,
      "learning_rate": 1.81504221028396e-05,
      "loss": 0.1356,
      "step": 16270
    },
    {
      "epoch": 1.9337213445777408,
      "grad_norm": 15.80793571472168,
      "learning_rate": 1.8130225794724725e-05,
      "loss": 0.2064,
      "step": 16280
    },
    {
      "epoch": 1.9349091341014373,
      "grad_norm": 27.875160217285156,
      "learning_rate": 1.8110029486609847e-05,
      "loss": 0.2221,
      "step": 16290
    },
    {
      "epoch": 1.9360969236251337,
      "grad_norm": 3.7136969566345215,
      "learning_rate": 1.8089833178494973e-05,
      "loss": 0.1921,
      "step": 16300
    },
    {
      "epoch": 1.93728471314883,
      "grad_norm": 13.437288284301758,
      "learning_rate": 1.8069636870380098e-05,
      "loss": 0.5083,
      "step": 16310
    },
    {
      "epoch": 1.9384725026725265,
      "grad_norm": 5.4058732986450195,
      "learning_rate": 1.8049440562265217e-05,
      "loss": 0.256,
      "step": 16320
    },
    {
      "epoch": 1.9396602921962227,
      "grad_norm": 41.112117767333984,
      "learning_rate": 1.8029244254150342e-05,
      "loss": 0.4113,
      "step": 16330
    },
    {
      "epoch": 1.9408480817199192,
      "grad_norm": 6.197804927825928,
      "learning_rate": 1.8009047946035464e-05,
      "loss": 0.2128,
      "step": 16340
    },
    {
      "epoch": 1.9420358712436157,
      "grad_norm": 7.518253326416016,
      "learning_rate": 1.798885163792059e-05,
      "loss": 0.2996,
      "step": 16350
    },
    {
      "epoch": 1.9432236607673121,
      "grad_norm": 21.731828689575195,
      "learning_rate": 1.7968655329805712e-05,
      "loss": 0.3589,
      "step": 16360
    },
    {
      "epoch": 1.9444114502910086,
      "grad_norm": 10.06676959991455,
      "learning_rate": 1.7948459021690837e-05,
      "loss": 0.2337,
      "step": 16370
    },
    {
      "epoch": 1.9455992398147048,
      "grad_norm": 17.371124267578125,
      "learning_rate": 1.792826271357596e-05,
      "loss": 0.2729,
      "step": 16380
    },
    {
      "epoch": 1.946787029338401,
      "grad_norm": 1.2204294204711914,
      "learning_rate": 1.790806640546108e-05,
      "loss": 0.2199,
      "step": 16390
    },
    {
      "epoch": 1.9479748188620976,
      "grad_norm": 32.050262451171875,
      "learning_rate": 1.7887870097346207e-05,
      "loss": 0.2776,
      "step": 16400
    },
    {
      "epoch": 1.949162608385794,
      "grad_norm": 0.3384898006916046,
      "learning_rate": 1.786767378923133e-05,
      "loss": 0.2719,
      "step": 16410
    },
    {
      "epoch": 1.9503503979094905,
      "grad_norm": 2.7864291667938232,
      "learning_rate": 1.7847477481116454e-05,
      "loss": 0.105,
      "step": 16420
    },
    {
      "epoch": 1.951538187433187,
      "grad_norm": 38.37187576293945,
      "learning_rate": 1.7827281173001576e-05,
      "loss": 0.3361,
      "step": 16430
    },
    {
      "epoch": 1.9527259769568832,
      "grad_norm": 23.507308959960938,
      "learning_rate": 1.78070848648867e-05,
      "loss": 0.2474,
      "step": 16440
    },
    {
      "epoch": 1.9539137664805797,
      "grad_norm": 22.35782241821289,
      "learning_rate": 1.7786888556771824e-05,
      "loss": 0.161,
      "step": 16450
    },
    {
      "epoch": 1.955101556004276,
      "grad_norm": 12.120247840881348,
      "learning_rate": 1.7766692248656946e-05,
      "loss": 0.3307,
      "step": 16460
    },
    {
      "epoch": 1.9562893455279724,
      "grad_norm": 17.77745819091797,
      "learning_rate": 1.774649594054207e-05,
      "loss": 0.2695,
      "step": 16470
    },
    {
      "epoch": 1.9574771350516689,
      "grad_norm": 47.1956672668457,
      "learning_rate": 1.7726299632427193e-05,
      "loss": 0.2808,
      "step": 16480
    },
    {
      "epoch": 1.9586649245753653,
      "grad_norm": 0.5662845373153687,
      "learning_rate": 1.770610332431232e-05,
      "loss": 0.2553,
      "step": 16490
    },
    {
      "epoch": 1.9598527140990618,
      "grad_norm": 20.391103744506836,
      "learning_rate": 1.768590701619744e-05,
      "loss": 0.3385,
      "step": 16500
    },
    {
      "epoch": 1.961040503622758,
      "grad_norm": 0.20267635583877563,
      "learning_rate": 1.7665710708082562e-05,
      "loss": 0.1953,
      "step": 16510
    },
    {
      "epoch": 1.9622282931464543,
      "grad_norm": 7.034079074859619,
      "learning_rate": 1.7645514399967684e-05,
      "loss": 0.3164,
      "step": 16520
    },
    {
      "epoch": 1.9634160826701508,
      "grad_norm": 18.018068313598633,
      "learning_rate": 1.762531809185281e-05,
      "loss": 0.4194,
      "step": 16530
    },
    {
      "epoch": 1.9646038721938472,
      "grad_norm": 15.835687637329102,
      "learning_rate": 1.7605121783737932e-05,
      "loss": 0.2699,
      "step": 16540
    },
    {
      "epoch": 1.9657916617175437,
      "grad_norm": 2.0192337036132812,
      "learning_rate": 1.7584925475623057e-05,
      "loss": 0.2205,
      "step": 16550
    },
    {
      "epoch": 1.9669794512412402,
      "grad_norm": 0.5575593113899231,
      "learning_rate": 1.7564729167508183e-05,
      "loss": 0.2849,
      "step": 16560
    },
    {
      "epoch": 1.9681672407649364,
      "grad_norm": 4.683979034423828,
      "learning_rate": 1.7544532859393305e-05,
      "loss": 0.3187,
      "step": 16570
    },
    {
      "epoch": 1.969355030288633,
      "grad_norm": 22.007598876953125,
      "learning_rate": 1.7524336551278427e-05,
      "loss": 0.3109,
      "step": 16580
    },
    {
      "epoch": 1.9705428198123291,
      "grad_norm": 12.276445388793945,
      "learning_rate": 1.750414024316355e-05,
      "loss": 0.3112,
      "step": 16590
    },
    {
      "epoch": 1.9717306093360256,
      "grad_norm": 11.316635131835938,
      "learning_rate": 1.7483943935048674e-05,
      "loss": 0.4908,
      "step": 16600
    },
    {
      "epoch": 1.972918398859722,
      "grad_norm": 1.0756585597991943,
      "learning_rate": 1.7463747626933796e-05,
      "loss": 0.3258,
      "step": 16610
    },
    {
      "epoch": 1.9741061883834186,
      "grad_norm": 0.7979865074157715,
      "learning_rate": 1.744355131881892e-05,
      "loss": 0.3581,
      "step": 16620
    },
    {
      "epoch": 1.9752939779071148,
      "grad_norm": 3.689089059829712,
      "learning_rate": 1.7423355010704047e-05,
      "loss": 0.4323,
      "step": 16630
    },
    {
      "epoch": 1.9764817674308113,
      "grad_norm": 0.18239228427410126,
      "learning_rate": 1.740315870258917e-05,
      "loss": 0.2297,
      "step": 16640
    },
    {
      "epoch": 1.9776695569545075,
      "grad_norm": 36.77470779418945,
      "learning_rate": 1.738296239447429e-05,
      "loss": 0.3466,
      "step": 16650
    },
    {
      "epoch": 1.978857346478204,
      "grad_norm": 24.62274742126465,
      "learning_rate": 1.7362766086359413e-05,
      "loss": 0.2282,
      "step": 16660
    },
    {
      "epoch": 1.9800451360019005,
      "grad_norm": 0.3692851662635803,
      "learning_rate": 1.734256977824454e-05,
      "loss": 0.3675,
      "step": 16670
    },
    {
      "epoch": 1.981232925525597,
      "grad_norm": 40.394248962402344,
      "learning_rate": 1.732237347012966e-05,
      "loss": 0.1939,
      "step": 16680
    },
    {
      "epoch": 1.9824207150492934,
      "grad_norm": 8.3699369430542,
      "learning_rate": 1.7302177162014786e-05,
      "loss": 0.1691,
      "step": 16690
    },
    {
      "epoch": 1.9836085045729897,
      "grad_norm": 28.58039093017578,
      "learning_rate": 1.7281980853899908e-05,
      "loss": 0.2597,
      "step": 16700
    },
    {
      "epoch": 1.9847962940966861,
      "grad_norm": 4.86740255355835,
      "learning_rate": 1.726178454578503e-05,
      "loss": 0.2711,
      "step": 16710
    },
    {
      "epoch": 1.9859840836203824,
      "grad_norm": 92.42256927490234,
      "learning_rate": 1.7241588237670155e-05,
      "loss": 0.3744,
      "step": 16720
    },
    {
      "epoch": 1.9871718731440788,
      "grad_norm": 2.491976499557495,
      "learning_rate": 1.7221391929555277e-05,
      "loss": 0.3491,
      "step": 16730
    },
    {
      "epoch": 1.9883596626677753,
      "grad_norm": 19.362009048461914,
      "learning_rate": 1.7201195621440403e-05,
      "loss": 0.2357,
      "step": 16740
    },
    {
      "epoch": 1.9895474521914718,
      "grad_norm": 0.32600677013397217,
      "learning_rate": 1.7180999313325525e-05,
      "loss": 0.2847,
      "step": 16750
    },
    {
      "epoch": 1.990735241715168,
      "grad_norm": 22.77388572692871,
      "learning_rate": 1.716080300521065e-05,
      "loss": 0.2391,
      "step": 16760
    },
    {
      "epoch": 1.9919230312388645,
      "grad_norm": 13.241528511047363,
      "learning_rate": 1.7140606697095772e-05,
      "loss": 0.2635,
      "step": 16770
    },
    {
      "epoch": 1.9931108207625607,
      "grad_norm": 3.187145948410034,
      "learning_rate": 1.7120410388980894e-05,
      "loss": 0.1221,
      "step": 16780
    },
    {
      "epoch": 1.9942986102862572,
      "grad_norm": 3.6383068561553955,
      "learning_rate": 1.7100214080866016e-05,
      "loss": 0.2488,
      "step": 16790
    },
    {
      "epoch": 1.9954863998099537,
      "grad_norm": 38.946258544921875,
      "learning_rate": 1.708001777275114e-05,
      "loss": 0.2961,
      "step": 16800
    },
    {
      "epoch": 1.9966741893336502,
      "grad_norm": 29.41539192199707,
      "learning_rate": 1.7059821464636267e-05,
      "loss": 0.1072,
      "step": 16810
    },
    {
      "epoch": 1.9978619788573466,
      "grad_norm": 17.366182327270508,
      "learning_rate": 1.703962515652139e-05,
      "loss": 0.4083,
      "step": 16820
    },
    {
      "epoch": 1.9990497683810429,
      "grad_norm": 0.8284398317337036,
      "learning_rate": 1.7019428848406514e-05,
      "loss": 0.312,
      "step": 16830
    },
    {
      "epoch": 2.000237557904739,
      "grad_norm": 23.67687225341797,
      "learning_rate": 1.6999232540291633e-05,
      "loss": 0.2355,
      "step": 16840
    },
    {
      "epoch": 2.0014253474284356,
      "grad_norm": 0.4815215468406677,
      "learning_rate": 1.697903623217676e-05,
      "loss": 0.3502,
      "step": 16850
    },
    {
      "epoch": 2.002613136952132,
      "grad_norm": 7.967929840087891,
      "learning_rate": 1.695883992406188e-05,
      "loss": 0.2499,
      "step": 16860
    },
    {
      "epoch": 2.0038009264758285,
      "grad_norm": 12.891929626464844,
      "learning_rate": 1.6938643615947006e-05,
      "loss": 0.1347,
      "step": 16870
    },
    {
      "epoch": 2.004988715999525,
      "grad_norm": 15.301307678222656,
      "learning_rate": 1.691844730783213e-05,
      "loss": 0.0683,
      "step": 16880
    },
    {
      "epoch": 2.0061765055232215,
      "grad_norm": 17.83814811706543,
      "learning_rate": 1.6898250999717253e-05,
      "loss": 0.1495,
      "step": 16890
    },
    {
      "epoch": 2.0073642950469175,
      "grad_norm": 12.384598731994629,
      "learning_rate": 1.6878054691602375e-05,
      "loss": 0.296,
      "step": 16900
    },
    {
      "epoch": 2.008552084570614,
      "grad_norm": 12.580221176147461,
      "learning_rate": 1.6857858383487497e-05,
      "loss": 0.4321,
      "step": 16910
    },
    {
      "epoch": 2.0097398740943104,
      "grad_norm": 0.7952609658241272,
      "learning_rate": 1.6837662075372623e-05,
      "loss": 0.2689,
      "step": 16920
    },
    {
      "epoch": 2.010927663618007,
      "grad_norm": 44.97052764892578,
      "learning_rate": 1.6817465767257745e-05,
      "loss": 0.123,
      "step": 16930
    },
    {
      "epoch": 2.0121154531417034,
      "grad_norm": 0.4752625823020935,
      "learning_rate": 1.679726945914287e-05,
      "loss": 0.1643,
      "step": 16940
    },
    {
      "epoch": 2.0133032426654,
      "grad_norm": 14.7500638961792,
      "learning_rate": 1.6777073151027992e-05,
      "loss": 0.1871,
      "step": 16950
    },
    {
      "epoch": 2.0144910321890963,
      "grad_norm": 23.636402130126953,
      "learning_rate": 1.6756876842913118e-05,
      "loss": 0.3008,
      "step": 16960
    },
    {
      "epoch": 2.0156788217127923,
      "grad_norm": 9.672300338745117,
      "learning_rate": 1.673668053479824e-05,
      "loss": 0.1254,
      "step": 16970
    },
    {
      "epoch": 2.016866611236489,
      "grad_norm": 20.04844093322754,
      "learning_rate": 1.6716484226683362e-05,
      "loss": 0.3026,
      "step": 16980
    },
    {
      "epoch": 2.0180544007601853,
      "grad_norm": 24.602561950683594,
      "learning_rate": 1.6696287918568487e-05,
      "loss": 0.2362,
      "step": 16990
    },
    {
      "epoch": 2.0192421902838817,
      "grad_norm": 2.293455123901367,
      "learning_rate": 1.667609161045361e-05,
      "loss": 0.2069,
      "step": 17000
    },
    {
      "epoch": 2.020429979807578,
      "grad_norm": 0.21729879081249237,
      "learning_rate": 1.6655895302338735e-05,
      "loss": 0.3833,
      "step": 17010
    },
    {
      "epoch": 2.0216177693312747,
      "grad_norm": 0.2599814534187317,
      "learning_rate": 1.6635698994223857e-05,
      "loss": 0.2853,
      "step": 17020
    },
    {
      "epoch": 2.0228055588549707,
      "grad_norm": 0.5140913724899292,
      "learning_rate": 1.661550268610898e-05,
      "loss": 0.2091,
      "step": 17030
    },
    {
      "epoch": 2.023993348378667,
      "grad_norm": 19.075620651245117,
      "learning_rate": 1.6595306377994104e-05,
      "loss": 0.4061,
      "step": 17040
    },
    {
      "epoch": 2.0251811379023636,
      "grad_norm": 29.343154907226562,
      "learning_rate": 1.6575110069879226e-05,
      "loss": 0.2076,
      "step": 17050
    },
    {
      "epoch": 2.02636892742606,
      "grad_norm": 0.26081815361976624,
      "learning_rate": 1.655491376176435e-05,
      "loss": 0.2453,
      "step": 17060
    },
    {
      "epoch": 2.0275567169497566,
      "grad_norm": 13.377197265625,
      "learning_rate": 1.6534717453649473e-05,
      "loss": 0.2804,
      "step": 17070
    },
    {
      "epoch": 2.028744506473453,
      "grad_norm": 7.26608419418335,
      "learning_rate": 1.65145211455346e-05,
      "loss": 0.2611,
      "step": 17080
    },
    {
      "epoch": 2.029932295997149,
      "grad_norm": 37.615135192871094,
      "learning_rate": 1.649432483741972e-05,
      "loss": 0.1228,
      "step": 17090
    },
    {
      "epoch": 2.0311200855208456,
      "grad_norm": 14.791521072387695,
      "learning_rate": 1.6474128529304843e-05,
      "loss": 0.3257,
      "step": 17100
    },
    {
      "epoch": 2.032307875044542,
      "grad_norm": 2.005068063735962,
      "learning_rate": 1.6453932221189965e-05,
      "loss": 0.1619,
      "step": 17110
    },
    {
      "epoch": 2.0334956645682385,
      "grad_norm": 24.623546600341797,
      "learning_rate": 1.643373591307509e-05,
      "loss": 0.323,
      "step": 17120
    },
    {
      "epoch": 2.034683454091935,
      "grad_norm": 0.4796103537082672,
      "learning_rate": 1.6413539604960216e-05,
      "loss": 0.2692,
      "step": 17130
    },
    {
      "epoch": 2.0358712436156314,
      "grad_norm": 12.4771146774292,
      "learning_rate": 1.6393343296845338e-05,
      "loss": 0.3382,
      "step": 17140
    },
    {
      "epoch": 2.037059033139328,
      "grad_norm": 23.66362190246582,
      "learning_rate": 1.6373146988730463e-05,
      "loss": 0.4262,
      "step": 17150
    },
    {
      "epoch": 2.038246822663024,
      "grad_norm": 26.01572608947754,
      "learning_rate": 1.6352950680615585e-05,
      "loss": 0.1214,
      "step": 17160
    },
    {
      "epoch": 2.0394346121867204,
      "grad_norm": 4.358129501342773,
      "learning_rate": 1.6332754372500707e-05,
      "loss": 0.2025,
      "step": 17170
    },
    {
      "epoch": 2.040622401710417,
      "grad_norm": 0.21702435612678528,
      "learning_rate": 1.631255806438583e-05,
      "loss": 0.1745,
      "step": 17180
    },
    {
      "epoch": 2.0418101912341133,
      "grad_norm": 13.466519355773926,
      "learning_rate": 1.6292361756270955e-05,
      "loss": 0.3923,
      "step": 17190
    },
    {
      "epoch": 2.04299798075781,
      "grad_norm": 0.9444805979728699,
      "learning_rate": 1.6272165448156077e-05,
      "loss": 0.26,
      "step": 17200
    },
    {
      "epoch": 2.0441857702815063,
      "grad_norm": 0.6489682793617249,
      "learning_rate": 1.6251969140041202e-05,
      "loss": 0.1934,
      "step": 17210
    },
    {
      "epoch": 2.0453735598052023,
      "grad_norm": 1.1527361869812012,
      "learning_rate": 1.6231772831926324e-05,
      "loss": 0.2734,
      "step": 17220
    },
    {
      "epoch": 2.0465613493288988,
      "grad_norm": 0.2725457549095154,
      "learning_rate": 1.6211576523811446e-05,
      "loss": 0.1133,
      "step": 17230
    },
    {
      "epoch": 2.0477491388525952,
      "grad_norm": 24.20442008972168,
      "learning_rate": 1.619138021569657e-05,
      "loss": 0.1893,
      "step": 17240
    },
    {
      "epoch": 2.0489369283762917,
      "grad_norm": 3.8792543411254883,
      "learning_rate": 1.6171183907581694e-05,
      "loss": 0.2008,
      "step": 17250
    },
    {
      "epoch": 2.050124717899988,
      "grad_norm": 8.678817749023438,
      "learning_rate": 1.615098759946682e-05,
      "loss": 0.3536,
      "step": 17260
    },
    {
      "epoch": 2.0513125074236847,
      "grad_norm": 28.4821834564209,
      "learning_rate": 1.613079129135194e-05,
      "loss": 0.3603,
      "step": 17270
    },
    {
      "epoch": 2.052500296947381,
      "grad_norm": 11.285533905029297,
      "learning_rate": 1.6110594983237066e-05,
      "loss": 0.1006,
      "step": 17280
    },
    {
      "epoch": 2.053688086471077,
      "grad_norm": 0.26971447467803955,
      "learning_rate": 1.609039867512219e-05,
      "loss": 0.1023,
      "step": 17290
    },
    {
      "epoch": 2.0548758759947736,
      "grad_norm": 0.11072520166635513,
      "learning_rate": 1.607020236700731e-05,
      "loss": 0.1151,
      "step": 17300
    },
    {
      "epoch": 2.05606366551847,
      "grad_norm": 37.87809371948242,
      "learning_rate": 1.6050006058892436e-05,
      "loss": 0.2784,
      "step": 17310
    },
    {
      "epoch": 2.0572514550421666,
      "grad_norm": 37.44047546386719,
      "learning_rate": 1.6029809750777558e-05,
      "loss": 0.2391,
      "step": 17320
    },
    {
      "epoch": 2.058439244565863,
      "grad_norm": 19.899703979492188,
      "learning_rate": 1.6009613442662683e-05,
      "loss": 0.2493,
      "step": 17330
    },
    {
      "epoch": 2.0596270340895595,
      "grad_norm": 3.330348253250122,
      "learning_rate": 1.5989417134547805e-05,
      "loss": 0.1088,
      "step": 17340
    },
    {
      "epoch": 2.0608148236132555,
      "grad_norm": 9.847396850585938,
      "learning_rate": 1.596922082643293e-05,
      "loss": 0.2913,
      "step": 17350
    },
    {
      "epoch": 2.062002613136952,
      "grad_norm": 0.14656567573547363,
      "learning_rate": 1.594902451831805e-05,
      "loss": 0.2303,
      "step": 17360
    },
    {
      "epoch": 2.0631904026606485,
      "grad_norm": 11.264479637145996,
      "learning_rate": 1.5928828210203175e-05,
      "loss": 0.4039,
      "step": 17370
    },
    {
      "epoch": 2.064378192184345,
      "grad_norm": 28.30702018737793,
      "learning_rate": 1.59086319020883e-05,
      "loss": 0.3609,
      "step": 17380
    },
    {
      "epoch": 2.0655659817080414,
      "grad_norm": 23.945064544677734,
      "learning_rate": 1.5888435593973422e-05,
      "loss": 0.2054,
      "step": 17390
    },
    {
      "epoch": 2.066753771231738,
      "grad_norm": 9.45655345916748,
      "learning_rate": 1.5868239285858548e-05,
      "loss": 0.3677,
      "step": 17400
    },
    {
      "epoch": 2.0679415607554343,
      "grad_norm": 20.73699951171875,
      "learning_rate": 1.584804297774367e-05,
      "loss": 0.2313,
      "step": 17410
    },
    {
      "epoch": 2.0691293502791304,
      "grad_norm": 0.49452725052833557,
      "learning_rate": 1.582784666962879e-05,
      "loss": 0.4506,
      "step": 17420
    },
    {
      "epoch": 2.070317139802827,
      "grad_norm": 8.524974822998047,
      "learning_rate": 1.5807650361513914e-05,
      "loss": 0.1025,
      "step": 17430
    },
    {
      "epoch": 2.0715049293265233,
      "grad_norm": 17.644880294799805,
      "learning_rate": 1.578745405339904e-05,
      "loss": 0.2804,
      "step": 17440
    },
    {
      "epoch": 2.0726927188502198,
      "grad_norm": 0.35014408826828003,
      "learning_rate": 1.5767257745284164e-05,
      "loss": 0.1653,
      "step": 17450
    },
    {
      "epoch": 2.0738805083739162,
      "grad_norm": 12.649246215820312,
      "learning_rate": 1.5747061437169286e-05,
      "loss": 0.3459,
      "step": 17460
    },
    {
      "epoch": 2.0750682978976127,
      "grad_norm": 1.236975073814392,
      "learning_rate": 1.5726865129054412e-05,
      "loss": 0.2501,
      "step": 17470
    },
    {
      "epoch": 2.0762560874213087,
      "grad_norm": 20.880573272705078,
      "learning_rate": 1.5706668820939534e-05,
      "loss": 0.1324,
      "step": 17480
    },
    {
      "epoch": 2.077443876945005,
      "grad_norm": 4.421359539031982,
      "learning_rate": 1.5686472512824656e-05,
      "loss": 0.3115,
      "step": 17490
    },
    {
      "epoch": 2.0786316664687017,
      "grad_norm": 0.5168424248695374,
      "learning_rate": 1.5666276204709778e-05,
      "loss": 0.3654,
      "step": 17500
    },
    {
      "epoch": 2.079819455992398,
      "grad_norm": 3.858973979949951,
      "learning_rate": 1.5646079896594903e-05,
      "loss": 0.5107,
      "step": 17510
    },
    {
      "epoch": 2.0810072455160946,
      "grad_norm": 20.089460372924805,
      "learning_rate": 1.5625883588480025e-05,
      "loss": 0.2216,
      "step": 17520
    },
    {
      "epoch": 2.082195035039791,
      "grad_norm": 24.334447860717773,
      "learning_rate": 1.560568728036515e-05,
      "loss": 0.3395,
      "step": 17530
    },
    {
      "epoch": 2.0833828245634876,
      "grad_norm": 27.665390014648438,
      "learning_rate": 1.5585490972250276e-05,
      "loss": 0.477,
      "step": 17540
    },
    {
      "epoch": 2.0845706140871836,
      "grad_norm": 30.81547737121582,
      "learning_rate": 1.5565294664135395e-05,
      "loss": 0.228,
      "step": 17550
    },
    {
      "epoch": 2.08575840361088,
      "grad_norm": 22.876453399658203,
      "learning_rate": 1.554509835602052e-05,
      "loss": 0.1658,
      "step": 17560
    },
    {
      "epoch": 2.0869461931345765,
      "grad_norm": 22.54420280456543,
      "learning_rate": 1.5524902047905642e-05,
      "loss": 0.3711,
      "step": 17570
    },
    {
      "epoch": 2.088133982658273,
      "grad_norm": 0.1997186541557312,
      "learning_rate": 1.5504705739790768e-05,
      "loss": 0.1558,
      "step": 17580
    },
    {
      "epoch": 2.0893217721819695,
      "grad_norm": 2.1732749938964844,
      "learning_rate": 1.548450943167589e-05,
      "loss": 0.2712,
      "step": 17590
    },
    {
      "epoch": 2.090509561705666,
      "grad_norm": 0.4868405759334564,
      "learning_rate": 1.5464313123561015e-05,
      "loss": 0.2977,
      "step": 17600
    },
    {
      "epoch": 2.091697351229362,
      "grad_norm": 3.508435010910034,
      "learning_rate": 1.5444116815446137e-05,
      "loss": 0.105,
      "step": 17610
    },
    {
      "epoch": 2.0928851407530584,
      "grad_norm": 0.6545740365982056,
      "learning_rate": 1.542392050733126e-05,
      "loss": 0.3302,
      "step": 17620
    },
    {
      "epoch": 2.094072930276755,
      "grad_norm": 0.6700893044471741,
      "learning_rate": 1.5403724199216385e-05,
      "loss": 0.3855,
      "step": 17630
    },
    {
      "epoch": 2.0952607198004514,
      "grad_norm": 0.26483362913131714,
      "learning_rate": 1.5383527891101507e-05,
      "loss": 0.22,
      "step": 17640
    },
    {
      "epoch": 2.096448509324148,
      "grad_norm": 26.94625473022461,
      "learning_rate": 1.5363331582986632e-05,
      "loss": 0.3331,
      "step": 17650
    },
    {
      "epoch": 2.0976362988478443,
      "grad_norm": 23.710237503051758,
      "learning_rate": 1.5343135274871754e-05,
      "loss": 0.2613,
      "step": 17660
    },
    {
      "epoch": 2.0988240883715408,
      "grad_norm": 3.523019313812256,
      "learning_rate": 1.532293896675688e-05,
      "loss": 0.3875,
      "step": 17670
    },
    {
      "epoch": 2.100011877895237,
      "grad_norm": 21.099592208862305,
      "learning_rate": 1.5302742658642e-05,
      "loss": 0.1242,
      "step": 17680
    },
    {
      "epoch": 2.1011996674189333,
      "grad_norm": 40.88451385498047,
      "learning_rate": 1.5282546350527123e-05,
      "loss": 0.1739,
      "step": 17690
    },
    {
      "epoch": 2.1023874569426297,
      "grad_norm": 1.4616698026657104,
      "learning_rate": 1.526235004241225e-05,
      "loss": 0.3513,
      "step": 17700
    },
    {
      "epoch": 2.103575246466326,
      "grad_norm": 0.3493228554725647,
      "learning_rate": 1.5242153734297371e-05,
      "loss": 0.3864,
      "step": 17710
    },
    {
      "epoch": 2.1047630359900227,
      "grad_norm": 9.532140731811523,
      "learning_rate": 1.5221957426182496e-05,
      "loss": 0.262,
      "step": 17720
    },
    {
      "epoch": 2.105950825513719,
      "grad_norm": 13.593402862548828,
      "learning_rate": 1.5201761118067617e-05,
      "loss": 0.2971,
      "step": 17730
    },
    {
      "epoch": 2.107138615037415,
      "grad_norm": 0.3431885838508606,
      "learning_rate": 1.5181564809952742e-05,
      "loss": 0.1689,
      "step": 17740
    },
    {
      "epoch": 2.1083264045611116,
      "grad_norm": 12.85537338256836,
      "learning_rate": 1.5161368501837864e-05,
      "loss": 0.2259,
      "step": 17750
    },
    {
      "epoch": 2.109514194084808,
      "grad_norm": 40.88088607788086,
      "learning_rate": 1.5141172193722988e-05,
      "loss": 0.2963,
      "step": 17760
    },
    {
      "epoch": 2.1107019836085046,
      "grad_norm": 6.869485378265381,
      "learning_rate": 1.512097588560811e-05,
      "loss": 0.2755,
      "step": 17770
    },
    {
      "epoch": 2.111889773132201,
      "grad_norm": 42.389808654785156,
      "learning_rate": 1.5100779577493235e-05,
      "loss": 0.2388,
      "step": 17780
    },
    {
      "epoch": 2.1130775626558975,
      "grad_norm": 35.85186004638672,
      "learning_rate": 1.5080583269378359e-05,
      "loss": 0.0975,
      "step": 17790
    },
    {
      "epoch": 2.1142653521795935,
      "grad_norm": 0.25752371549606323,
      "learning_rate": 1.5060386961263481e-05,
      "loss": 0.1822,
      "step": 17800
    },
    {
      "epoch": 2.11545314170329,
      "grad_norm": 25.736583709716797,
      "learning_rate": 1.5040190653148606e-05,
      "loss": 0.3222,
      "step": 17810
    },
    {
      "epoch": 2.1166409312269865,
      "grad_norm": 1.5885860919952393,
      "learning_rate": 1.5019994345033728e-05,
      "loss": 0.1656,
      "step": 17820
    },
    {
      "epoch": 2.117828720750683,
      "grad_norm": 0.8251957893371582,
      "learning_rate": 1.4999798036918852e-05,
      "loss": 0.2314,
      "step": 17830
    },
    {
      "epoch": 2.1190165102743794,
      "grad_norm": 23.524757385253906,
      "learning_rate": 1.4979601728803974e-05,
      "loss": 0.2278,
      "step": 17840
    },
    {
      "epoch": 2.120204299798076,
      "grad_norm": 12.618879318237305,
      "learning_rate": 1.49594054206891e-05,
      "loss": 0.2685,
      "step": 17850
    },
    {
      "epoch": 2.1213920893217724,
      "grad_norm": 12.917116165161133,
      "learning_rate": 1.4939209112574223e-05,
      "loss": 0.324,
      "step": 17860
    },
    {
      "epoch": 2.1225798788454684,
      "grad_norm": 1.7680916786193848,
      "learning_rate": 1.4919012804459345e-05,
      "loss": 0.3446,
      "step": 17870
    },
    {
      "epoch": 2.123767668369165,
      "grad_norm": 14.891660690307617,
      "learning_rate": 1.489881649634447e-05,
      "loss": 0.3015,
      "step": 17880
    },
    {
      "epoch": 2.1249554578928613,
      "grad_norm": 1.8604626655578613,
      "learning_rate": 1.4878620188229591e-05,
      "loss": 0.2009,
      "step": 17890
    },
    {
      "epoch": 2.126143247416558,
      "grad_norm": 27.84136962890625,
      "learning_rate": 1.4858423880114716e-05,
      "loss": 0.1875,
      "step": 17900
    },
    {
      "epoch": 2.1273310369402543,
      "grad_norm": 51.97134017944336,
      "learning_rate": 1.4838227571999838e-05,
      "loss": 0.1684,
      "step": 17910
    },
    {
      "epoch": 2.1285188264639507,
      "grad_norm": 0.622061550617218,
      "learning_rate": 1.4818031263884962e-05,
      "loss": 0.0959,
      "step": 17920
    },
    {
      "epoch": 2.129706615987647,
      "grad_norm": 26.822002410888672,
      "learning_rate": 1.4797834955770084e-05,
      "loss": 0.4948,
      "step": 17930
    },
    {
      "epoch": 2.1308944055113432,
      "grad_norm": 22.26250457763672,
      "learning_rate": 1.477763864765521e-05,
      "loss": 0.3126,
      "step": 17940
    },
    {
      "epoch": 2.1320821950350397,
      "grad_norm": 15.729860305786133,
      "learning_rate": 1.4757442339540333e-05,
      "loss": 0.2905,
      "step": 17950
    },
    {
      "epoch": 2.133269984558736,
      "grad_norm": 8.642502784729004,
      "learning_rate": 1.4737246031425455e-05,
      "loss": 0.1628,
      "step": 17960
    },
    {
      "epoch": 2.1344577740824326,
      "grad_norm": 0.5387636423110962,
      "learning_rate": 1.471704972331058e-05,
      "loss": 0.285,
      "step": 17970
    },
    {
      "epoch": 2.135645563606129,
      "grad_norm": 18.985353469848633,
      "learning_rate": 1.4696853415195703e-05,
      "loss": 0.2918,
      "step": 17980
    },
    {
      "epoch": 2.1368333531298256,
      "grad_norm": 5.487133026123047,
      "learning_rate": 1.4676657107080826e-05,
      "loss": 0.4285,
      "step": 17990
    },
    {
      "epoch": 2.1380211426535216,
      "grad_norm": 35.5609245300293,
      "learning_rate": 1.4656460798965948e-05,
      "loss": 0.1865,
      "step": 18000
    },
    {
      "epoch": 2.139208932177218,
      "grad_norm": 34.15936279296875,
      "learning_rate": 1.4636264490851074e-05,
      "loss": 0.3922,
      "step": 18010
    },
    {
      "epoch": 2.1403967217009146,
      "grad_norm": 4.913477897644043,
      "learning_rate": 1.4616068182736198e-05,
      "loss": 0.2454,
      "step": 18020
    },
    {
      "epoch": 2.141584511224611,
      "grad_norm": 15.841703414916992,
      "learning_rate": 1.459587187462132e-05,
      "loss": 0.125,
      "step": 18030
    },
    {
      "epoch": 2.1427723007483075,
      "grad_norm": 0.3212136924266815,
      "learning_rate": 1.4575675566506445e-05,
      "loss": 0.0938,
      "step": 18040
    },
    {
      "epoch": 2.143960090272004,
      "grad_norm": 6.5294904708862305,
      "learning_rate": 1.4555479258391565e-05,
      "loss": 0.157,
      "step": 18050
    },
    {
      "epoch": 2.1451478797957,
      "grad_norm": 1.090331792831421,
      "learning_rate": 1.453528295027669e-05,
      "loss": 0.1722,
      "step": 18060
    },
    {
      "epoch": 2.1463356693193965,
      "grad_norm": 11.244518280029297,
      "learning_rate": 1.4515086642161813e-05,
      "loss": 0.1287,
      "step": 18070
    },
    {
      "epoch": 2.147523458843093,
      "grad_norm": 4.175096035003662,
      "learning_rate": 1.4494890334046936e-05,
      "loss": 0.467,
      "step": 18080
    },
    {
      "epoch": 2.1487112483667894,
      "grad_norm": 15.459733963012695,
      "learning_rate": 1.4474694025932058e-05,
      "loss": 0.2015,
      "step": 18090
    },
    {
      "epoch": 2.149899037890486,
      "grad_norm": 4.877472877502441,
      "learning_rate": 1.4454497717817184e-05,
      "loss": 0.2377,
      "step": 18100
    },
    {
      "epoch": 2.1510868274141823,
      "grad_norm": 0.2081201821565628,
      "learning_rate": 1.4434301409702308e-05,
      "loss": 0.264,
      "step": 18110
    },
    {
      "epoch": 2.152274616937879,
      "grad_norm": 1.0935792922973633,
      "learning_rate": 1.441410510158743e-05,
      "loss": 0.2515,
      "step": 18120
    },
    {
      "epoch": 2.153462406461575,
      "grad_norm": 2.9430880546569824,
      "learning_rate": 1.4393908793472555e-05,
      "loss": 0.1534,
      "step": 18130
    },
    {
      "epoch": 2.1546501959852713,
      "grad_norm": 2.6026432514190674,
      "learning_rate": 1.4373712485357677e-05,
      "loss": 0.2113,
      "step": 18140
    },
    {
      "epoch": 2.1558379855089678,
      "grad_norm": 29.25360107421875,
      "learning_rate": 1.43535161772428e-05,
      "loss": 0.3435,
      "step": 18150
    },
    {
      "epoch": 2.1570257750326642,
      "grad_norm": 1.2167932987213135,
      "learning_rate": 1.4333319869127923e-05,
      "loss": 0.2119,
      "step": 18160
    },
    {
      "epoch": 2.1582135645563607,
      "grad_norm": 9.400140762329102,
      "learning_rate": 1.4313123561013048e-05,
      "loss": 0.258,
      "step": 18170
    },
    {
      "epoch": 2.159401354080057,
      "grad_norm": 5.05551815032959,
      "learning_rate": 1.4292927252898172e-05,
      "loss": 0.2715,
      "step": 18180
    },
    {
      "epoch": 2.1605891436037536,
      "grad_norm": 37.0262336730957,
      "learning_rate": 1.4272730944783294e-05,
      "loss": 0.2672,
      "step": 18190
    },
    {
      "epoch": 2.1617769331274497,
      "grad_norm": 23.512502670288086,
      "learning_rate": 1.425253463666842e-05,
      "loss": 0.2325,
      "step": 18200
    },
    {
      "epoch": 2.162964722651146,
      "grad_norm": 23.77011489868164,
      "learning_rate": 1.4232338328553541e-05,
      "loss": 0.4327,
      "step": 18210
    },
    {
      "epoch": 2.1641525121748426,
      "grad_norm": 36.44865417480469,
      "learning_rate": 1.4212142020438665e-05,
      "loss": 0.4633,
      "step": 18220
    },
    {
      "epoch": 2.165340301698539,
      "grad_norm": 16.108745574951172,
      "learning_rate": 1.4191945712323787e-05,
      "loss": 0.3134,
      "step": 18230
    },
    {
      "epoch": 2.1665280912222356,
      "grad_norm": 3.5260138511657715,
      "learning_rate": 1.417174940420891e-05,
      "loss": 0.2298,
      "step": 18240
    },
    {
      "epoch": 2.167715880745932,
      "grad_norm": 9.358013153076172,
      "learning_rate": 1.4151553096094033e-05,
      "loss": 0.247,
      "step": 18250
    },
    {
      "epoch": 2.168903670269628,
      "grad_norm": 23.028968811035156,
      "learning_rate": 1.4131356787979158e-05,
      "loss": 0.4163,
      "step": 18260
    },
    {
      "epoch": 2.1700914597933245,
      "grad_norm": 0.7948910593986511,
      "learning_rate": 1.4111160479864282e-05,
      "loss": 0.252,
      "step": 18270
    },
    {
      "epoch": 2.171279249317021,
      "grad_norm": 1.465453028678894,
      "learning_rate": 1.4090964171749404e-05,
      "loss": 0.2764,
      "step": 18280
    },
    {
      "epoch": 2.1724670388407175,
      "grad_norm": 33.743221282958984,
      "learning_rate": 1.407076786363453e-05,
      "loss": 0.3929,
      "step": 18290
    },
    {
      "epoch": 2.173654828364414,
      "grad_norm": 0.21439728140830994,
      "learning_rate": 1.4050571555519651e-05,
      "loss": 0.1646,
      "step": 18300
    },
    {
      "epoch": 2.1748426178881104,
      "grad_norm": 45.05598449707031,
      "learning_rate": 1.4030375247404775e-05,
      "loss": 0.3652,
      "step": 18310
    },
    {
      "epoch": 2.1760304074118064,
      "grad_norm": 31.414775848388672,
      "learning_rate": 1.4010178939289897e-05,
      "loss": 0.1158,
      "step": 18320
    },
    {
      "epoch": 2.177218196935503,
      "grad_norm": 3.6275954246520996,
      "learning_rate": 1.3989982631175023e-05,
      "loss": 0.2641,
      "step": 18330
    },
    {
      "epoch": 2.1784059864591994,
      "grad_norm": 4.352685451507568,
      "learning_rate": 1.3969786323060145e-05,
      "loss": 0.2519,
      "step": 18340
    },
    {
      "epoch": 2.179593775982896,
      "grad_norm": 15.614667892456055,
      "learning_rate": 1.3949590014945268e-05,
      "loss": 0.2724,
      "step": 18350
    },
    {
      "epoch": 2.1807815655065923,
      "grad_norm": 9.284287452697754,
      "learning_rate": 1.3929393706830394e-05,
      "loss": 0.2173,
      "step": 18360
    },
    {
      "epoch": 2.1819693550302888,
      "grad_norm": 5.306188583374023,
      "learning_rate": 1.3909197398715516e-05,
      "loss": 0.1916,
      "step": 18370
    },
    {
      "epoch": 2.1831571445539852,
      "grad_norm": 4.089293956756592,
      "learning_rate": 1.388900109060064e-05,
      "loss": 0.2036,
      "step": 18380
    },
    {
      "epoch": 2.1843449340776813,
      "grad_norm": 9.394627571105957,
      "learning_rate": 1.3868804782485761e-05,
      "loss": 0.0994,
      "step": 18390
    },
    {
      "epoch": 2.1855327236013777,
      "grad_norm": 21.321807861328125,
      "learning_rate": 1.3848608474370887e-05,
      "loss": 0.5044,
      "step": 18400
    },
    {
      "epoch": 2.186720513125074,
      "grad_norm": 6.323584079742432,
      "learning_rate": 1.3828412166256007e-05,
      "loss": 0.5109,
      "step": 18410
    },
    {
      "epoch": 2.1879083026487707,
      "grad_norm": 0.14445485174655914,
      "learning_rate": 1.3808215858141133e-05,
      "loss": 0.2115,
      "step": 18420
    },
    {
      "epoch": 2.189096092172467,
      "grad_norm": 4.338544845581055,
      "learning_rate": 1.3788019550026258e-05,
      "loss": 0.2409,
      "step": 18430
    },
    {
      "epoch": 2.1902838816961636,
      "grad_norm": 22.665145874023438,
      "learning_rate": 1.3767823241911378e-05,
      "loss": 0.2294,
      "step": 18440
    },
    {
      "epoch": 2.1914716712198596,
      "grad_norm": 1.272746205329895,
      "learning_rate": 1.3747626933796504e-05,
      "loss": 0.2258,
      "step": 18450
    },
    {
      "epoch": 2.192659460743556,
      "grad_norm": 5.289102554321289,
      "learning_rate": 1.3727430625681626e-05,
      "loss": 0.164,
      "step": 18460
    },
    {
      "epoch": 2.1938472502672526,
      "grad_norm": 10.591286659240723,
      "learning_rate": 1.370723431756675e-05,
      "loss": 0.3339,
      "step": 18470
    },
    {
      "epoch": 2.195035039790949,
      "grad_norm": 0.793326735496521,
      "learning_rate": 1.3687038009451871e-05,
      "loss": 0.2846,
      "step": 18480
    },
    {
      "epoch": 2.1962228293146455,
      "grad_norm": 2.5353758335113525,
      "learning_rate": 1.3666841701336997e-05,
      "loss": 0.206,
      "step": 18490
    },
    {
      "epoch": 2.197410618838342,
      "grad_norm": 25.97654914855957,
      "learning_rate": 1.3646645393222119e-05,
      "loss": 0.2266,
      "step": 18500
    },
    {
      "epoch": 2.198598408362038,
      "grad_norm": 16.501684188842773,
      "learning_rate": 1.3626449085107243e-05,
      "loss": 0.3184,
      "step": 18510
    },
    {
      "epoch": 2.1997861978857345,
      "grad_norm": 4.616901397705078,
      "learning_rate": 1.3606252776992368e-05,
      "loss": 0.1687,
      "step": 18520
    },
    {
      "epoch": 2.200973987409431,
      "grad_norm": 0.7403237819671631,
      "learning_rate": 1.358605646887749e-05,
      "loss": 0.2117,
      "step": 18530
    },
    {
      "epoch": 2.2021617769331274,
      "grad_norm": 12.470521926879883,
      "learning_rate": 1.3565860160762614e-05,
      "loss": 0.3868,
      "step": 18540
    },
    {
      "epoch": 2.203349566456824,
      "grad_norm": 0.342876672744751,
      "learning_rate": 1.3545663852647736e-05,
      "loss": 0.4677,
      "step": 18550
    },
    {
      "epoch": 2.2045373559805204,
      "grad_norm": 9.180778503417969,
      "learning_rate": 1.3525467544532861e-05,
      "loss": 0.2768,
      "step": 18560
    },
    {
      "epoch": 2.205725145504217,
      "grad_norm": 0.11416734755039215,
      "learning_rate": 1.3505271236417981e-05,
      "loss": 0.2843,
      "step": 18570
    },
    {
      "epoch": 2.206912935027913,
      "grad_norm": 24.361221313476562,
      "learning_rate": 1.3485074928303107e-05,
      "loss": 0.2149,
      "step": 18580
    },
    {
      "epoch": 2.2081007245516093,
      "grad_norm": 0.3087146580219269,
      "learning_rate": 1.3464878620188232e-05,
      "loss": 0.1587,
      "step": 18590
    },
    {
      "epoch": 2.209288514075306,
      "grad_norm": 1.907121181488037,
      "learning_rate": 1.3444682312073353e-05,
      "loss": 0.2977,
      "step": 18600
    },
    {
      "epoch": 2.2104763035990023,
      "grad_norm": 46.0949592590332,
      "learning_rate": 1.3424486003958478e-05,
      "loss": 0.3693,
      "step": 18610
    },
    {
      "epoch": 2.2116640931226987,
      "grad_norm": 15.455679893493652,
      "learning_rate": 1.34042896958436e-05,
      "loss": 0.2293,
      "step": 18620
    },
    {
      "epoch": 2.212851882646395,
      "grad_norm": 18.567317962646484,
      "learning_rate": 1.3384093387728724e-05,
      "loss": 0.2577,
      "step": 18630
    },
    {
      "epoch": 2.2140396721700917,
      "grad_norm": 1.2567025423049927,
      "learning_rate": 1.3363897079613846e-05,
      "loss": 0.1584,
      "step": 18640
    },
    {
      "epoch": 2.2152274616937877,
      "grad_norm": 1.8961942195892334,
      "learning_rate": 1.3343700771498971e-05,
      "loss": 0.1424,
      "step": 18650
    },
    {
      "epoch": 2.216415251217484,
      "grad_norm": 6.235821723937988,
      "learning_rate": 1.3323504463384093e-05,
      "loss": 0.2972,
      "step": 18660
    },
    {
      "epoch": 2.2176030407411806,
      "grad_norm": 13.09544563293457,
      "learning_rate": 1.3303308155269217e-05,
      "loss": 0.3253,
      "step": 18670
    },
    {
      "epoch": 2.218790830264877,
      "grad_norm": 11.850042343139648,
      "learning_rate": 1.3283111847154342e-05,
      "loss": 0.1705,
      "step": 18680
    },
    {
      "epoch": 2.2199786197885736,
      "grad_norm": 0.26749110221862793,
      "learning_rate": 1.3262915539039464e-05,
      "loss": 0.1305,
      "step": 18690
    },
    {
      "epoch": 2.22116640931227,
      "grad_norm": 35.15482711791992,
      "learning_rate": 1.3242719230924588e-05,
      "loss": 0.4326,
      "step": 18700
    },
    {
      "epoch": 2.222354198835966,
      "grad_norm": 0.1865004152059555,
      "learning_rate": 1.322252292280971e-05,
      "loss": 0.2079,
      "step": 18710
    },
    {
      "epoch": 2.2235419883596625,
      "grad_norm": 7.188834190368652,
      "learning_rate": 1.3202326614694836e-05,
      "loss": 0.2768,
      "step": 18720
    },
    {
      "epoch": 2.224729777883359,
      "grad_norm": 1.6020995378494263,
      "learning_rate": 1.3182130306579958e-05,
      "loss": 0.3894,
      "step": 18730
    },
    {
      "epoch": 2.2259175674070555,
      "grad_norm": 2.7537214756011963,
      "learning_rate": 1.3161933998465081e-05,
      "loss": 0.2214,
      "step": 18740
    },
    {
      "epoch": 2.227105356930752,
      "grad_norm": 30.429851531982422,
      "learning_rate": 1.3141737690350207e-05,
      "loss": 0.2698,
      "step": 18750
    },
    {
      "epoch": 2.2282931464544484,
      "grad_norm": 0.5654230713844299,
      "learning_rate": 1.3121541382235327e-05,
      "loss": 0.2451,
      "step": 18760
    },
    {
      "epoch": 2.2294809359781445,
      "grad_norm": 2.8909735679626465,
      "learning_rate": 1.3101345074120452e-05,
      "loss": 0.2152,
      "step": 18770
    },
    {
      "epoch": 2.230668725501841,
      "grad_norm": 4.30385684967041,
      "learning_rate": 1.3081148766005574e-05,
      "loss": 0.2146,
      "step": 18780
    },
    {
      "epoch": 2.2318565150255374,
      "grad_norm": 8.161816596984863,
      "learning_rate": 1.3060952457890698e-05,
      "loss": 0.2624,
      "step": 18790
    },
    {
      "epoch": 2.233044304549234,
      "grad_norm": 15.790103912353516,
      "learning_rate": 1.304075614977582e-05,
      "loss": 0.1538,
      "step": 18800
    },
    {
      "epoch": 2.2342320940729303,
      "grad_norm": 16.57968521118164,
      "learning_rate": 1.3020559841660946e-05,
      "loss": 0.3878,
      "step": 18810
    },
    {
      "epoch": 2.235419883596627,
      "grad_norm": 0.27628234028816223,
      "learning_rate": 1.3000363533546068e-05,
      "loss": 0.0485,
      "step": 18820
    },
    {
      "epoch": 2.2366076731203233,
      "grad_norm": 9.454571723937988,
      "learning_rate": 1.2980167225431191e-05,
      "loss": 0.3536,
      "step": 18830
    },
    {
      "epoch": 2.2377954626440193,
      "grad_norm": 6.9235100746154785,
      "learning_rate": 1.2959970917316317e-05,
      "loss": 0.3035,
      "step": 18840
    },
    {
      "epoch": 2.2389832521677158,
      "grad_norm": 0.12186333537101746,
      "learning_rate": 1.2939774609201439e-05,
      "loss": 0.1707,
      "step": 18850
    },
    {
      "epoch": 2.2401710416914122,
      "grad_norm": 7.537413120269775,
      "learning_rate": 1.2919578301086562e-05,
      "loss": 0.2785,
      "step": 18860
    },
    {
      "epoch": 2.2413588312151087,
      "grad_norm": 0.11827971786260605,
      "learning_rate": 1.2899381992971684e-05,
      "loss": 0.3139,
      "step": 18870
    },
    {
      "epoch": 2.242546620738805,
      "grad_norm": 29.921218872070312,
      "learning_rate": 1.287918568485681e-05,
      "loss": 0.1969,
      "step": 18880
    },
    {
      "epoch": 2.2437344102625016,
      "grad_norm": 45.95028305053711,
      "learning_rate": 1.2858989376741932e-05,
      "loss": 0.2896,
      "step": 18890
    },
    {
      "epoch": 2.244922199786198,
      "grad_norm": 5.59206485748291,
      "learning_rate": 1.2838793068627056e-05,
      "loss": 0.3361,
      "step": 18900
    },
    {
      "epoch": 2.246109989309894,
      "grad_norm": 23.33449935913086,
      "learning_rate": 1.2818596760512178e-05,
      "loss": 0.114,
      "step": 18910
    },
    {
      "epoch": 2.2472977788335906,
      "grad_norm": 0.15963906049728394,
      "learning_rate": 1.2798400452397303e-05,
      "loss": 0.2307,
      "step": 18920
    },
    {
      "epoch": 2.248485568357287,
      "grad_norm": 41.22528076171875,
      "learning_rate": 1.2778204144282427e-05,
      "loss": 0.2776,
      "step": 18930
    },
    {
      "epoch": 2.2496733578809835,
      "grad_norm": 0.490613728761673,
      "learning_rate": 1.2758007836167549e-05,
      "loss": 0.2392,
      "step": 18940
    },
    {
      "epoch": 2.25086114740468,
      "grad_norm": 20.86943244934082,
      "learning_rate": 1.2737811528052672e-05,
      "loss": 0.3528,
      "step": 18950
    },
    {
      "epoch": 2.252048936928376,
      "grad_norm": 0.2590350806713104,
      "learning_rate": 1.2717615219937794e-05,
      "loss": 0.1711,
      "step": 18960
    },
    {
      "epoch": 2.2532367264520725,
      "grad_norm": 1.4668716192245483,
      "learning_rate": 1.269741891182292e-05,
      "loss": 0.4061,
      "step": 18970
    },
    {
      "epoch": 2.254424515975769,
      "grad_norm": 26.043346405029297,
      "learning_rate": 1.2677222603708042e-05,
      "loss": 0.2006,
      "step": 18980
    },
    {
      "epoch": 2.2556123054994655,
      "grad_norm": 27.28192710876465,
      "learning_rate": 1.2657026295593166e-05,
      "loss": 0.1787,
      "step": 18990
    },
    {
      "epoch": 2.256800095023162,
      "grad_norm": 0.936762273311615,
      "learning_rate": 1.2636829987478291e-05,
      "loss": 0.3677,
      "step": 19000
    },
    {
      "epoch": 2.2579878845468584,
      "grad_norm": 19.51786994934082,
      "learning_rate": 1.2616633679363413e-05,
      "loss": 0.4613,
      "step": 19010
    },
    {
      "epoch": 2.259175674070555,
      "grad_norm": 5.768764019012451,
      "learning_rate": 1.2596437371248537e-05,
      "loss": 0.3392,
      "step": 19020
    },
    {
      "epoch": 2.260363463594251,
      "grad_norm": 14.612381935119629,
      "learning_rate": 1.2576241063133659e-05,
      "loss": 0.3431,
      "step": 19030
    },
    {
      "epoch": 2.2615512531179474,
      "grad_norm": 0.16004323959350586,
      "learning_rate": 1.2556044755018784e-05,
      "loss": 0.2049,
      "step": 19040
    },
    {
      "epoch": 2.262739042641644,
      "grad_norm": 34.8299674987793,
      "learning_rate": 1.2535848446903906e-05,
      "loss": 0.1666,
      "step": 19050
    },
    {
      "epoch": 2.2639268321653403,
      "grad_norm": 30.54157257080078,
      "learning_rate": 1.251565213878903e-05,
      "loss": 0.2575,
      "step": 19060
    },
    {
      "epoch": 2.2651146216890368,
      "grad_norm": 4.176830768585205,
      "learning_rate": 1.2495455830674154e-05,
      "loss": 0.1061,
      "step": 19070
    },
    {
      "epoch": 2.2663024112127332,
      "grad_norm": 6.445268630981445,
      "learning_rate": 1.2475259522559277e-05,
      "loss": 0.3106,
      "step": 19080
    },
    {
      "epoch": 2.2674902007364297,
      "grad_norm": 32.8765869140625,
      "learning_rate": 1.24550632144444e-05,
      "loss": 0.1506,
      "step": 19090
    },
    {
      "epoch": 2.2686779902601257,
      "grad_norm": 15.309796333312988,
      "learning_rate": 1.2434866906329523e-05,
      "loss": 0.4564,
      "step": 19100
    },
    {
      "epoch": 2.269865779783822,
      "grad_norm": 12.680850982666016,
      "learning_rate": 1.2414670598214647e-05,
      "loss": 0.1204,
      "step": 19110
    },
    {
      "epoch": 2.2710535693075187,
      "grad_norm": 8.416094779968262,
      "learning_rate": 1.239447429009977e-05,
      "loss": 0.3936,
      "step": 19120
    },
    {
      "epoch": 2.272241358831215,
      "grad_norm": 6.550002574920654,
      "learning_rate": 1.2374277981984894e-05,
      "loss": 0.2168,
      "step": 19130
    },
    {
      "epoch": 2.2734291483549116,
      "grad_norm": 20.049989700317383,
      "learning_rate": 1.2354081673870018e-05,
      "loss": 0.2237,
      "step": 19140
    },
    {
      "epoch": 2.274616937878608,
      "grad_norm": 2.393876075744629,
      "learning_rate": 1.233388536575514e-05,
      "loss": 0.3555,
      "step": 19150
    },
    {
      "epoch": 2.2758047274023046,
      "grad_norm": 1.4628268480300903,
      "learning_rate": 1.2313689057640264e-05,
      "loss": 0.1565,
      "step": 19160
    },
    {
      "epoch": 2.2769925169260006,
      "grad_norm": 1.377953052520752,
      "learning_rate": 1.2293492749525387e-05,
      "loss": 0.1058,
      "step": 19170
    },
    {
      "epoch": 2.278180306449697,
      "grad_norm": 3.4901938438415527,
      "learning_rate": 1.2273296441410511e-05,
      "loss": 0.2753,
      "step": 19180
    },
    {
      "epoch": 2.2793680959733935,
      "grad_norm": 3.0557219982147217,
      "learning_rate": 1.2253100133295633e-05,
      "loss": 0.3762,
      "step": 19190
    },
    {
      "epoch": 2.28055588549709,
      "grad_norm": 21.24626350402832,
      "learning_rate": 1.2232903825180759e-05,
      "loss": 0.044,
      "step": 19200
    },
    {
      "epoch": 2.2817436750207865,
      "grad_norm": 30.67205238342285,
      "learning_rate": 1.221270751706588e-05,
      "loss": 0.1617,
      "step": 19210
    },
    {
      "epoch": 2.2829314645444825,
      "grad_norm": 1.223630428314209,
      "learning_rate": 1.2192511208951004e-05,
      "loss": 0.1156,
      "step": 19220
    },
    {
      "epoch": 2.284119254068179,
      "grad_norm": 2.188135862350464,
      "learning_rate": 1.2172314900836128e-05,
      "loss": 0.1167,
      "step": 19230
    },
    {
      "epoch": 2.2853070435918754,
      "grad_norm": 14.470979690551758,
      "learning_rate": 1.2152118592721252e-05,
      "loss": 0.2112,
      "step": 19240
    },
    {
      "epoch": 2.286494833115572,
      "grad_norm": 12.732115745544434,
      "learning_rate": 1.2131922284606374e-05,
      "loss": 0.3343,
      "step": 19250
    },
    {
      "epoch": 2.2876826226392684,
      "grad_norm": 0.1445237696170807,
      "learning_rate": 1.2111725976491497e-05,
      "loss": 0.3313,
      "step": 19260
    },
    {
      "epoch": 2.288870412162965,
      "grad_norm": 0.1150258481502533,
      "learning_rate": 1.2091529668376621e-05,
      "loss": 0.2366,
      "step": 19270
    },
    {
      "epoch": 2.2900582016866613,
      "grad_norm": 9.964406967163086,
      "learning_rate": 1.2071333360261745e-05,
      "loss": 0.4871,
      "step": 19280
    },
    {
      "epoch": 2.2912459912103573,
      "grad_norm": 0.11342205107212067,
      "learning_rate": 1.2051137052146869e-05,
      "loss": 0.1409,
      "step": 19290
    },
    {
      "epoch": 2.292433780734054,
      "grad_norm": 12.259047508239746,
      "learning_rate": 1.2030940744031992e-05,
      "loss": 0.341,
      "step": 19300
    },
    {
      "epoch": 2.2936215702577503,
      "grad_norm": 5.688560485839844,
      "learning_rate": 1.2010744435917114e-05,
      "loss": 0.2833,
      "step": 19310
    },
    {
      "epoch": 2.2948093597814467,
      "grad_norm": 0.32697296142578125,
      "learning_rate": 1.1990548127802238e-05,
      "loss": 0.1821,
      "step": 19320
    },
    {
      "epoch": 2.295997149305143,
      "grad_norm": 1.7079713344573975,
      "learning_rate": 1.1970351819687362e-05,
      "loss": 0.3014,
      "step": 19330
    },
    {
      "epoch": 2.2971849388288397,
      "grad_norm": 8.986563682556152,
      "learning_rate": 1.1950155511572485e-05,
      "loss": 0.3359,
      "step": 19340
    },
    {
      "epoch": 2.298372728352536,
      "grad_norm": 19.03383445739746,
      "learning_rate": 1.1929959203457607e-05,
      "loss": 0.2226,
      "step": 19350
    },
    {
      "epoch": 2.299560517876232,
      "grad_norm": 5.1887359619140625,
      "learning_rate": 1.1909762895342733e-05,
      "loss": 0.247,
      "step": 19360
    },
    {
      "epoch": 2.3007483073999286,
      "grad_norm": 1.6429543495178223,
      "learning_rate": 1.1889566587227857e-05,
      "loss": 0.3109,
      "step": 19370
    },
    {
      "epoch": 2.301936096923625,
      "grad_norm": 28.2377872467041,
      "learning_rate": 1.1869370279112979e-05,
      "loss": 0.4636,
      "step": 19380
    },
    {
      "epoch": 2.3031238864473216,
      "grad_norm": 0.25961387157440186,
      "learning_rate": 1.1849173970998102e-05,
      "loss": 0.276,
      "step": 19390
    },
    {
      "epoch": 2.304311675971018,
      "grad_norm": 21.607892990112305,
      "learning_rate": 1.1828977662883226e-05,
      "loss": 0.3874,
      "step": 19400
    },
    {
      "epoch": 2.3054994654947145,
      "grad_norm": 34.77399826049805,
      "learning_rate": 1.1808781354768348e-05,
      "loss": 0.2425,
      "step": 19410
    },
    {
      "epoch": 2.306687255018411,
      "grad_norm": 7.584720611572266,
      "learning_rate": 1.1788585046653472e-05,
      "loss": 0.2529,
      "step": 19420
    },
    {
      "epoch": 2.307875044542107,
      "grad_norm": 14.208844184875488,
      "learning_rate": 1.1768388738538596e-05,
      "loss": 0.1765,
      "step": 19430
    },
    {
      "epoch": 2.3090628340658035,
      "grad_norm": 0.68325275182724,
      "learning_rate": 1.174819243042372e-05,
      "loss": 0.1577,
      "step": 19440
    },
    {
      "epoch": 2.3102506235895,
      "grad_norm": 0.5625746250152588,
      "learning_rate": 1.1727996122308843e-05,
      "loss": 0.1399,
      "step": 19450
    },
    {
      "epoch": 2.3114384131131964,
      "grad_norm": 0.42865613102912903,
      "learning_rate": 1.1707799814193967e-05,
      "loss": 0.292,
      "step": 19460
    },
    {
      "epoch": 2.312626202636893,
      "grad_norm": 17.442352294921875,
      "learning_rate": 1.1687603506079089e-05,
      "loss": 0.1067,
      "step": 19470
    },
    {
      "epoch": 2.313813992160589,
      "grad_norm": 15.173373222351074,
      "learning_rate": 1.1667407197964212e-05,
      "loss": 0.206,
      "step": 19480
    },
    {
      "epoch": 2.3150017816842854,
      "grad_norm": 34.20460510253906,
      "learning_rate": 1.1647210889849336e-05,
      "loss": 0.2686,
      "step": 19490
    },
    {
      "epoch": 2.316189571207982,
      "grad_norm": 4.5407867431640625,
      "learning_rate": 1.162701458173446e-05,
      "loss": 0.3012,
      "step": 19500
    },
    {
      "epoch": 2.3173773607316783,
      "grad_norm": 5.688418388366699,
      "learning_rate": 1.1606818273619582e-05,
      "loss": 0.218,
      "step": 19510
    },
    {
      "epoch": 2.318565150255375,
      "grad_norm": 27.68494987487793,
      "learning_rate": 1.1586621965504706e-05,
      "loss": 0.2982,
      "step": 19520
    },
    {
      "epoch": 2.3197529397790713,
      "grad_norm": 2.3937108516693115,
      "learning_rate": 1.1566425657389831e-05,
      "loss": 0.1212,
      "step": 19530
    },
    {
      "epoch": 2.3209407293027677,
      "grad_norm": 58.40338897705078,
      "learning_rate": 1.1546229349274953e-05,
      "loss": 0.2066,
      "step": 19540
    },
    {
      "epoch": 2.3221285188264638,
      "grad_norm": 6.942726135253906,
      "learning_rate": 1.1526033041160077e-05,
      "loss": 0.6144,
      "step": 19550
    },
    {
      "epoch": 2.3233163083501602,
      "grad_norm": 8.549827575683594,
      "learning_rate": 1.15058367330452e-05,
      "loss": 0.3407,
      "step": 19560
    },
    {
      "epoch": 2.3245040978738567,
      "grad_norm": 2.3196330070495605,
      "learning_rate": 1.1485640424930322e-05,
      "loss": 0.3033,
      "step": 19570
    },
    {
      "epoch": 2.325691887397553,
      "grad_norm": 9.453864097595215,
      "learning_rate": 1.1465444116815446e-05,
      "loss": 0.4258,
      "step": 19580
    },
    {
      "epoch": 2.3268796769212496,
      "grad_norm": 30.654216766357422,
      "learning_rate": 1.144524780870057e-05,
      "loss": 0.1686,
      "step": 19590
    },
    {
      "epoch": 2.328067466444946,
      "grad_norm": 52.30833053588867,
      "learning_rate": 1.1425051500585694e-05,
      "loss": 0.3327,
      "step": 19600
    },
    {
      "epoch": 2.3292552559686426,
      "grad_norm": 0.2311868518590927,
      "learning_rate": 1.1404855192470817e-05,
      "loss": 0.2308,
      "step": 19610
    },
    {
      "epoch": 2.3304430454923386,
      "grad_norm": 0.17834827303886414,
      "learning_rate": 1.1384658884355941e-05,
      "loss": 0.3641,
      "step": 19620
    },
    {
      "epoch": 2.331630835016035,
      "grad_norm": 71.99403381347656,
      "learning_rate": 1.1364462576241065e-05,
      "loss": 0.1979,
      "step": 19630
    },
    {
      "epoch": 2.3328186245397315,
      "grad_norm": 13.827702522277832,
      "learning_rate": 1.1344266268126187e-05,
      "loss": 0.1556,
      "step": 19640
    },
    {
      "epoch": 2.334006414063428,
      "grad_norm": 24.51753807067871,
      "learning_rate": 1.132406996001131e-05,
      "loss": 0.2247,
      "step": 19650
    },
    {
      "epoch": 2.3351942035871245,
      "grad_norm": 5.950389862060547,
      "learning_rate": 1.1303873651896434e-05,
      "loss": 0.2003,
      "step": 19660
    },
    {
      "epoch": 2.336381993110821,
      "grad_norm": 17.089160919189453,
      "learning_rate": 1.1283677343781556e-05,
      "loss": 0.3233,
      "step": 19670
    },
    {
      "epoch": 2.337569782634517,
      "grad_norm": 0.694957435131073,
      "learning_rate": 1.126348103566668e-05,
      "loss": 0.2417,
      "step": 19680
    },
    {
      "epoch": 2.3387575721582134,
      "grad_norm": 9.697473526000977,
      "learning_rate": 1.1243284727551805e-05,
      "loss": 0.2124,
      "step": 19690
    },
    {
      "epoch": 2.33994536168191,
      "grad_norm": 0.6734458208084106,
      "learning_rate": 1.1223088419436927e-05,
      "loss": 0.3105,
      "step": 19700
    },
    {
      "epoch": 2.3411331512056064,
      "grad_norm": 2.5806431770324707,
      "learning_rate": 1.1202892111322051e-05,
      "loss": 0.3706,
      "step": 19710
    },
    {
      "epoch": 2.342320940729303,
      "grad_norm": 9.39913272857666,
      "learning_rate": 1.1182695803207175e-05,
      "loss": 0.3113,
      "step": 19720
    },
    {
      "epoch": 2.3435087302529993,
      "grad_norm": 49.686431884765625,
      "learning_rate": 1.1162499495092297e-05,
      "loss": 0.2331,
      "step": 19730
    },
    {
      "epoch": 2.3446965197766954,
      "grad_norm": 5.425255298614502,
      "learning_rate": 1.114230318697742e-05,
      "loss": 0.2532,
      "step": 19740
    },
    {
      "epoch": 2.345884309300392,
      "grad_norm": 13.006214141845703,
      "learning_rate": 1.1122106878862544e-05,
      "loss": 0.2021,
      "step": 19750
    },
    {
      "epoch": 2.3470720988240883,
      "grad_norm": 42.61048126220703,
      "learning_rate": 1.1101910570747668e-05,
      "loss": 0.1033,
      "step": 19760
    },
    {
      "epoch": 2.3482598883477848,
      "grad_norm": 34.12245559692383,
      "learning_rate": 1.1081714262632792e-05,
      "loss": 0.3193,
      "step": 19770
    },
    {
      "epoch": 2.3494476778714812,
      "grad_norm": 0.824579656124115,
      "learning_rate": 1.1061517954517915e-05,
      "loss": 0.2945,
      "step": 19780
    },
    {
      "epoch": 2.3506354673951777,
      "grad_norm": 20.98785400390625,
      "learning_rate": 1.1041321646403039e-05,
      "loss": 0.1198,
      "step": 19790
    },
    {
      "epoch": 2.351823256918874,
      "grad_norm": 1.2120513916015625,
      "learning_rate": 1.1021125338288161e-05,
      "loss": 0.1764,
      "step": 19800
    },
    {
      "epoch": 2.35301104644257,
      "grad_norm": 0.6793908476829529,
      "learning_rate": 1.1000929030173285e-05,
      "loss": 0.2891,
      "step": 19810
    },
    {
      "epoch": 2.3541988359662667,
      "grad_norm": 26.90534782409668,
      "learning_rate": 1.0980732722058408e-05,
      "loss": 0.2253,
      "step": 19820
    },
    {
      "epoch": 2.355386625489963,
      "grad_norm": 8.183271408081055,
      "learning_rate": 1.096053641394353e-05,
      "loss": 0.3312,
      "step": 19830
    },
    {
      "epoch": 2.3565744150136596,
      "grad_norm": 7.440435886383057,
      "learning_rate": 1.0940340105828654e-05,
      "loss": 0.3567,
      "step": 19840
    },
    {
      "epoch": 2.357762204537356,
      "grad_norm": 44.92765808105469,
      "learning_rate": 1.092014379771378e-05,
      "loss": 0.1902,
      "step": 19850
    },
    {
      "epoch": 2.3589499940610525,
      "grad_norm": 9.962613105773926,
      "learning_rate": 1.0899947489598902e-05,
      "loss": 0.2107,
      "step": 19860
    },
    {
      "epoch": 2.360137783584749,
      "grad_norm": 1.1123995780944824,
      "learning_rate": 1.0879751181484025e-05,
      "loss": 0.1717,
      "step": 19870
    },
    {
      "epoch": 2.361325573108445,
      "grad_norm": 0.22320079803466797,
      "learning_rate": 1.0859554873369149e-05,
      "loss": 0.1537,
      "step": 19880
    },
    {
      "epoch": 2.3625133626321415,
      "grad_norm": 0.1517174392938614,
      "learning_rate": 1.0839358565254273e-05,
      "loss": 0.1379,
      "step": 19890
    },
    {
      "epoch": 2.363701152155838,
      "grad_norm": 6.457262992858887,
      "learning_rate": 1.0819162257139395e-05,
      "loss": 0.0939,
      "step": 19900
    },
    {
      "epoch": 2.3648889416795345,
      "grad_norm": 0.20956872403621674,
      "learning_rate": 1.0798965949024519e-05,
      "loss": 0.2577,
      "step": 19910
    },
    {
      "epoch": 2.366076731203231,
      "grad_norm": 0.19969342648983002,
      "learning_rate": 1.0778769640909642e-05,
      "loss": 0.4127,
      "step": 19920
    },
    {
      "epoch": 2.367264520726927,
      "grad_norm": 0.39169538021087646,
      "learning_rate": 1.0758573332794766e-05,
      "loss": 0.3181,
      "step": 19930
    },
    {
      "epoch": 2.3684523102506234,
      "grad_norm": 0.7438188195228577,
      "learning_rate": 1.073837702467989e-05,
      "loss": 0.4407,
      "step": 19940
    },
    {
      "epoch": 2.36964009977432,
      "grad_norm": 47.147422790527344,
      "learning_rate": 1.0718180716565013e-05,
      "loss": 0.3899,
      "step": 19950
    },
    {
      "epoch": 2.3708278892980164,
      "grad_norm": 28.52608871459961,
      "learning_rate": 1.0697984408450135e-05,
      "loss": 0.165,
      "step": 19960
    },
    {
      "epoch": 2.372015678821713,
      "grad_norm": 18.015098571777344,
      "learning_rate": 1.0677788100335259e-05,
      "loss": 0.3417,
      "step": 19970
    },
    {
      "epoch": 2.3732034683454093,
      "grad_norm": 4.195011615753174,
      "learning_rate": 1.0657591792220383e-05,
      "loss": 0.1734,
      "step": 19980
    },
    {
      "epoch": 2.3743912578691058,
      "grad_norm": 0.10098586976528168,
      "learning_rate": 1.0637395484105505e-05,
      "loss": 0.3176,
      "step": 19990
    },
    {
      "epoch": 2.375579047392802,
      "grad_norm": 40.99687957763672,
      "learning_rate": 1.0617199175990629e-05,
      "loss": 0.2933,
      "step": 20000
    },
    {
      "epoch": 2.3767668369164983,
      "grad_norm": 28.908872604370117,
      "learning_rate": 1.0597002867875752e-05,
      "loss": 0.2332,
      "step": 20010
    },
    {
      "epoch": 2.3779546264401947,
      "grad_norm": 0.23421213030815125,
      "learning_rate": 1.0576806559760876e-05,
      "loss": 0.1341,
      "step": 20020
    },
    {
      "epoch": 2.379142415963891,
      "grad_norm": 0.346237450838089,
      "learning_rate": 1.0556610251646e-05,
      "loss": 0.1587,
      "step": 20030
    },
    {
      "epoch": 2.3803302054875877,
      "grad_norm": 40.92670822143555,
      "learning_rate": 1.0536413943531123e-05,
      "loss": 0.3374,
      "step": 20040
    },
    {
      "epoch": 2.381517995011284,
      "grad_norm": 0.5192292928695679,
      "learning_rate": 1.0516217635416247e-05,
      "loss": 0.0155,
      "step": 20050
    },
    {
      "epoch": 2.3827057845349806,
      "grad_norm": 1.3076363801956177,
      "learning_rate": 1.049602132730137e-05,
      "loss": 0.323,
      "step": 20060
    },
    {
      "epoch": 2.3838935740586766,
      "grad_norm": 18.54311180114746,
      "learning_rate": 1.0475825019186493e-05,
      "loss": 0.455,
      "step": 20070
    },
    {
      "epoch": 2.385081363582373,
      "grad_norm": 11.982905387878418,
      "learning_rate": 1.0455628711071617e-05,
      "loss": 0.2452,
      "step": 20080
    },
    {
      "epoch": 2.3862691531060696,
      "grad_norm": 0.1029905453324318,
      "learning_rate": 1.0435432402956739e-05,
      "loss": 0.2416,
      "step": 20090
    },
    {
      "epoch": 2.387456942629766,
      "grad_norm": 12.794647216796875,
      "learning_rate": 1.0415236094841864e-05,
      "loss": 0.4872,
      "step": 20100
    },
    {
      "epoch": 2.3886447321534625,
      "grad_norm": 0.5819867253303528,
      "learning_rate": 1.0395039786726988e-05,
      "loss": 0.1917,
      "step": 20110
    },
    {
      "epoch": 2.389832521677159,
      "grad_norm": 8.388579368591309,
      "learning_rate": 1.037484347861211e-05,
      "loss": 0.3524,
      "step": 20120
    },
    {
      "epoch": 2.3910203112008555,
      "grad_norm": 22.625289916992188,
      "learning_rate": 1.0354647170497233e-05,
      "loss": 0.385,
      "step": 20130
    },
    {
      "epoch": 2.3922081007245515,
      "grad_norm": 0.7409054040908813,
      "learning_rate": 1.0334450862382357e-05,
      "loss": 0.0896,
      "step": 20140
    },
    {
      "epoch": 2.393395890248248,
      "grad_norm": 38.843807220458984,
      "learning_rate": 1.0314254554267481e-05,
      "loss": 0.3773,
      "step": 20150
    },
    {
      "epoch": 2.3945836797719444,
      "grad_norm": 1.2302706241607666,
      "learning_rate": 1.0294058246152603e-05,
      "loss": 0.0849,
      "step": 20160
    },
    {
      "epoch": 2.395771469295641,
      "grad_norm": 1.8434563875198364,
      "learning_rate": 1.0273861938037727e-05,
      "loss": 0.328,
      "step": 20170
    },
    {
      "epoch": 2.3969592588193374,
      "grad_norm": 43.83435821533203,
      "learning_rate": 1.025366562992285e-05,
      "loss": 0.3472,
      "step": 20180
    },
    {
      "epoch": 2.3981470483430334,
      "grad_norm": 0.6674026846885681,
      "learning_rate": 1.0233469321807974e-05,
      "loss": 0.1058,
      "step": 20190
    },
    {
      "epoch": 2.39933483786673,
      "grad_norm": 0.2300107181072235,
      "learning_rate": 1.0213273013693098e-05,
      "loss": 0.0467,
      "step": 20200
    },
    {
      "epoch": 2.4005226273904263,
      "grad_norm": 87.1885757446289,
      "learning_rate": 1.0193076705578221e-05,
      "loss": 0.2706,
      "step": 20210
    },
    {
      "epoch": 2.401710416914123,
      "grad_norm": 11.367716789245605,
      "learning_rate": 1.0172880397463344e-05,
      "loss": 0.3193,
      "step": 20220
    },
    {
      "epoch": 2.4028982064378193,
      "grad_norm": 5.502234935760498,
      "learning_rate": 1.0152684089348467e-05,
      "loss": 0.343,
      "step": 20230
    },
    {
      "epoch": 2.4040859959615157,
      "grad_norm": 4.867067337036133,
      "learning_rate": 1.0132487781233591e-05,
      "loss": 0.2076,
      "step": 20240
    },
    {
      "epoch": 2.405273785485212,
      "grad_norm": 0.4711090624332428,
      "learning_rate": 1.0112291473118713e-05,
      "loss": 0.3776,
      "step": 20250
    },
    {
      "epoch": 2.4064615750089082,
      "grad_norm": 0.28772327303886414,
      "learning_rate": 1.0092095165003838e-05,
      "loss": 0.237,
      "step": 20260
    },
    {
      "epoch": 2.4076493645326047,
      "grad_norm": 19.253793716430664,
      "learning_rate": 1.0071898856888962e-05,
      "loss": 0.2195,
      "step": 20270
    },
    {
      "epoch": 2.408837154056301,
      "grad_norm": 0.9305568337440491,
      "learning_rate": 1.0051702548774084e-05,
      "loss": 0.3146,
      "step": 20280
    },
    {
      "epoch": 2.4100249435799976,
      "grad_norm": 1.3039957284927368,
      "learning_rate": 1.0031506240659208e-05,
      "loss": 0.3887,
      "step": 20290
    },
    {
      "epoch": 2.411212733103694,
      "grad_norm": 29.12022590637207,
      "learning_rate": 1.0011309932544332e-05,
      "loss": 0.2803,
      "step": 20300
    },
    {
      "epoch": 2.4124005226273906,
      "grad_norm": 0.3120113015174866,
      "learning_rate": 9.991113624429455e-06,
      "loss": 0.3865,
      "step": 20310
    },
    {
      "epoch": 2.413588312151087,
      "grad_norm": 31.425230026245117,
      "learning_rate": 9.970917316314577e-06,
      "loss": 0.2958,
      "step": 20320
    },
    {
      "epoch": 2.414776101674783,
      "grad_norm": 0.569456160068512,
      "learning_rate": 9.950721008199701e-06,
      "loss": 0.2644,
      "step": 20330
    },
    {
      "epoch": 2.4159638911984795,
      "grad_norm": 0.19935429096221924,
      "learning_rate": 9.930524700084826e-06,
      "loss": 0.3137,
      "step": 20340
    },
    {
      "epoch": 2.417151680722176,
      "grad_norm": 3.4014742374420166,
      "learning_rate": 9.910328391969948e-06,
      "loss": 0.3198,
      "step": 20350
    },
    {
      "epoch": 2.4183394702458725,
      "grad_norm": 33.767845153808594,
      "learning_rate": 9.890132083855072e-06,
      "loss": 0.2737,
      "step": 20360
    },
    {
      "epoch": 2.419527259769569,
      "grad_norm": 12.722652435302734,
      "learning_rate": 9.869935775740196e-06,
      "loss": 0.2435,
      "step": 20370
    },
    {
      "epoch": 2.4207150492932654,
      "grad_norm": 3.418532371520996,
      "learning_rate": 9.849739467625318e-06,
      "loss": 0.2475,
      "step": 20380
    },
    {
      "epoch": 2.4219028388169614,
      "grad_norm": 0.3255085051059723,
      "learning_rate": 9.829543159510442e-06,
      "loss": 0.2586,
      "step": 20390
    },
    {
      "epoch": 2.423090628340658,
      "grad_norm": 9.577975273132324,
      "learning_rate": 9.809346851395565e-06,
      "loss": 0.2507,
      "step": 20400
    },
    {
      "epoch": 2.4242784178643544,
      "grad_norm": 23.212230682373047,
      "learning_rate": 9.789150543280689e-06,
      "loss": 0.1854,
      "step": 20410
    },
    {
      "epoch": 2.425466207388051,
      "grad_norm": 35.230247497558594,
      "learning_rate": 9.768954235165813e-06,
      "loss": 0.1944,
      "step": 20420
    },
    {
      "epoch": 2.4266539969117473,
      "grad_norm": 3.546691417694092,
      "learning_rate": 9.748757927050936e-06,
      "loss": 0.5506,
      "step": 20430
    },
    {
      "epoch": 2.427841786435444,
      "grad_norm": 1.0851647853851318,
      "learning_rate": 9.728561618936058e-06,
      "loss": 0.2271,
      "step": 20440
    },
    {
      "epoch": 2.42902957595914,
      "grad_norm": 40.844600677490234,
      "learning_rate": 9.708365310821182e-06,
      "loss": 0.4439,
      "step": 20450
    },
    {
      "epoch": 2.4302173654828363,
      "grad_norm": 12.187166213989258,
      "learning_rate": 9.688169002706306e-06,
      "loss": 0.2943,
      "step": 20460
    },
    {
      "epoch": 2.4314051550065328,
      "grad_norm": 1.2366602420806885,
      "learning_rate": 9.66797269459143e-06,
      "loss": 0.1864,
      "step": 20470
    },
    {
      "epoch": 2.4325929445302292,
      "grad_norm": 53.903297424316406,
      "learning_rate": 9.647776386476552e-06,
      "loss": 0.1749,
      "step": 20480
    },
    {
      "epoch": 2.4337807340539257,
      "grad_norm": 0.08921337127685547,
      "learning_rate": 9.627580078361675e-06,
      "loss": 0.2689,
      "step": 20490
    },
    {
      "epoch": 2.434968523577622,
      "grad_norm": 0.5336560606956482,
      "learning_rate": 9.6073837702468e-06,
      "loss": 0.0675,
      "step": 20500
    },
    {
      "epoch": 2.4361563131013186,
      "grad_norm": 10.487906455993652,
      "learning_rate": 9.587187462131923e-06,
      "loss": 0.2154,
      "step": 20510
    },
    {
      "epoch": 2.4373441026250147,
      "grad_norm": 18.519001007080078,
      "learning_rate": 9.566991154017046e-06,
      "loss": 0.0445,
      "step": 20520
    },
    {
      "epoch": 2.438531892148711,
      "grad_norm": 19.983596801757812,
      "learning_rate": 9.54679484590217e-06,
      "loss": 0.2193,
      "step": 20530
    },
    {
      "epoch": 2.4397196816724076,
      "grad_norm": 0.7100101113319397,
      "learning_rate": 9.526598537787292e-06,
      "loss": 0.1223,
      "step": 20540
    },
    {
      "epoch": 2.440907471196104,
      "grad_norm": 0.13704124093055725,
      "learning_rate": 9.506402229672416e-06,
      "loss": 0.1742,
      "step": 20550
    },
    {
      "epoch": 2.4420952607198005,
      "grad_norm": 0.07087361812591553,
      "learning_rate": 9.48620592155754e-06,
      "loss": 0.2792,
      "step": 20560
    },
    {
      "epoch": 2.443283050243497,
      "grad_norm": 15.849068641662598,
      "learning_rate": 9.466009613442663e-06,
      "loss": 0.37,
      "step": 20570
    },
    {
      "epoch": 2.4444708397671935,
      "grad_norm": 12.537331581115723,
      "learning_rate": 9.445813305327785e-06,
      "loss": 0.3896,
      "step": 20580
    },
    {
      "epoch": 2.4456586292908895,
      "grad_norm": 43.36946487426758,
      "learning_rate": 9.42561699721291e-06,
      "loss": 0.4066,
      "step": 20590
    },
    {
      "epoch": 2.446846418814586,
      "grad_norm": 2.7064459323883057,
      "learning_rate": 9.405420689098034e-06,
      "loss": 0.3195,
      "step": 20600
    },
    {
      "epoch": 2.4480342083382824,
      "grad_norm": 17.056285858154297,
      "learning_rate": 9.385224380983157e-06,
      "loss": 0.1855,
      "step": 20610
    },
    {
      "epoch": 2.449221997861979,
      "grad_norm": 0.1191861554980278,
      "learning_rate": 9.36502807286828e-06,
      "loss": 0.151,
      "step": 20620
    },
    {
      "epoch": 2.4504097873856754,
      "grad_norm": 0.9421234726905823,
      "learning_rate": 9.344831764753404e-06,
      "loss": 0.1707,
      "step": 20630
    },
    {
      "epoch": 2.4515975769093714,
      "grad_norm": 0.0830710306763649,
      "learning_rate": 9.324635456638526e-06,
      "loss": 0.6299,
      "step": 20640
    },
    {
      "epoch": 2.452785366433068,
      "grad_norm": 0.192732572555542,
      "learning_rate": 9.30443914852365e-06,
      "loss": 0.2263,
      "step": 20650
    },
    {
      "epoch": 2.4539731559567644,
      "grad_norm": 43.36323547363281,
      "learning_rate": 9.284242840408773e-06,
      "loss": 0.3965,
      "step": 20660
    },
    {
      "epoch": 2.455160945480461,
      "grad_norm": 18.431337356567383,
      "learning_rate": 9.264046532293897e-06,
      "loss": 0.1548,
      "step": 20670
    },
    {
      "epoch": 2.4563487350041573,
      "grad_norm": 22.65616226196289,
      "learning_rate": 9.24385022417902e-06,
      "loss": 0.1825,
      "step": 20680
    },
    {
      "epoch": 2.4575365245278538,
      "grad_norm": 29.42365264892578,
      "learning_rate": 9.223653916064145e-06,
      "loss": 0.3145,
      "step": 20690
    },
    {
      "epoch": 2.4587243140515502,
      "grad_norm": 17.627405166625977,
      "learning_rate": 9.203457607949267e-06,
      "loss": 0.1321,
      "step": 20700
    },
    {
      "epoch": 2.4599121035752463,
      "grad_norm": 0.26245248317718506,
      "learning_rate": 9.18326129983439e-06,
      "loss": 0.2321,
      "step": 20710
    },
    {
      "epoch": 2.4610998930989427,
      "grad_norm": 37.37030029296875,
      "learning_rate": 9.163064991719514e-06,
      "loss": 0.3164,
      "step": 20720
    },
    {
      "epoch": 2.462287682622639,
      "grad_norm": 39.21908950805664,
      "learning_rate": 9.142868683604638e-06,
      "loss": 0.3051,
      "step": 20730
    },
    {
      "epoch": 2.4634754721463357,
      "grad_norm": 2.828207492828369,
      "learning_rate": 9.12267237548976e-06,
      "loss": 0.2097,
      "step": 20740
    },
    {
      "epoch": 2.464663261670032,
      "grad_norm": 3.8895649909973145,
      "learning_rate": 9.102476067374885e-06,
      "loss": 0.1966,
      "step": 20750
    },
    {
      "epoch": 2.4658510511937286,
      "grad_norm": 0.9588091969490051,
      "learning_rate": 9.082279759260009e-06,
      "loss": 0.2684,
      "step": 20760
    },
    {
      "epoch": 2.467038840717425,
      "grad_norm": 0.4220936894416809,
      "learning_rate": 9.062083451145131e-06,
      "loss": 0.156,
      "step": 20770
    },
    {
      "epoch": 2.468226630241121,
      "grad_norm": 29.840293884277344,
      "learning_rate": 9.041887143030255e-06,
      "loss": 0.3243,
      "step": 20780
    },
    {
      "epoch": 2.4694144197648176,
      "grad_norm": 25.843257904052734,
      "learning_rate": 9.021690834915378e-06,
      "loss": 0.2607,
      "step": 20790
    },
    {
      "epoch": 2.470602209288514,
      "grad_norm": 41.78141784667969,
      "learning_rate": 9.0014945268005e-06,
      "loss": 0.3797,
      "step": 20800
    },
    {
      "epoch": 2.4717899988122105,
      "grad_norm": 18.486160278320312,
      "learning_rate": 8.981298218685624e-06,
      "loss": 0.1016,
      "step": 20810
    },
    {
      "epoch": 2.472977788335907,
      "grad_norm": 20.534847259521484,
      "learning_rate": 8.961101910570748e-06,
      "loss": 0.3033,
      "step": 20820
    },
    {
      "epoch": 2.4741655778596034,
      "grad_norm": 19.047170639038086,
      "learning_rate": 8.940905602455871e-06,
      "loss": 0.3835,
      "step": 20830
    },
    {
      "epoch": 2.4753533673833,
      "grad_norm": 39.88243103027344,
      "learning_rate": 8.920709294340995e-06,
      "loss": 0.282,
      "step": 20840
    },
    {
      "epoch": 2.476541156906996,
      "grad_norm": 0.2654571235179901,
      "learning_rate": 8.900512986226119e-06,
      "loss": 0.1244,
      "step": 20850
    },
    {
      "epoch": 2.4777289464306924,
      "grad_norm": 22.542724609375,
      "learning_rate": 8.880316678111243e-06,
      "loss": 0.2971,
      "step": 20860
    },
    {
      "epoch": 2.478916735954389,
      "grad_norm": 0.2763228714466095,
      "learning_rate": 8.860120369996365e-06,
      "loss": 0.2663,
      "step": 20870
    },
    {
      "epoch": 2.4801045254780854,
      "grad_norm": 0.3000686466693878,
      "learning_rate": 8.839924061881488e-06,
      "loss": 0.2429,
      "step": 20880
    },
    {
      "epoch": 2.481292315001782,
      "grad_norm": 36.69810104370117,
      "learning_rate": 8.819727753766612e-06,
      "loss": 0.2171,
      "step": 20890
    },
    {
      "epoch": 2.482480104525478,
      "grad_norm": 4.784483909606934,
      "learning_rate": 8.799531445651734e-06,
      "loss": 0.2991,
      "step": 20900
    },
    {
      "epoch": 2.4836678940491743,
      "grad_norm": 20.443138122558594,
      "learning_rate": 8.77933513753686e-06,
      "loss": 0.2382,
      "step": 20910
    },
    {
      "epoch": 2.484855683572871,
      "grad_norm": 0.3312906324863434,
      "learning_rate": 8.759138829421983e-06,
      "loss": 0.3126,
      "step": 20920
    },
    {
      "epoch": 2.4860434730965673,
      "grad_norm": 0.6684221625328064,
      "learning_rate": 8.738942521307105e-06,
      "loss": 0.1367,
      "step": 20930
    },
    {
      "epoch": 2.4872312626202637,
      "grad_norm": 2.2515039443969727,
      "learning_rate": 8.718746213192229e-06,
      "loss": 0.4333,
      "step": 20940
    },
    {
      "epoch": 2.48841905214396,
      "grad_norm": 9.567426681518555,
      "learning_rate": 8.698549905077353e-06,
      "loss": 0.1656,
      "step": 20950
    },
    {
      "epoch": 2.4896068416676567,
      "grad_norm": 60.35678482055664,
      "learning_rate": 8.678353596962475e-06,
      "loss": 0.1555,
      "step": 20960
    },
    {
      "epoch": 2.4907946311913527,
      "grad_norm": 9.892121315002441,
      "learning_rate": 8.658157288847598e-06,
      "loss": 0.3741,
      "step": 20970
    },
    {
      "epoch": 2.491982420715049,
      "grad_norm": 0.3715779185295105,
      "learning_rate": 8.637960980732722e-06,
      "loss": 0.188,
      "step": 20980
    },
    {
      "epoch": 2.4931702102387456,
      "grad_norm": 11.867918968200684,
      "learning_rate": 8.617764672617846e-06,
      "loss": 0.3083,
      "step": 20990
    },
    {
      "epoch": 2.494357999762442,
      "grad_norm": 5.1529388427734375,
      "learning_rate": 8.59756836450297e-06,
      "loss": 0.3543,
      "step": 21000
    },
    {
      "epoch": 2.4955457892861386,
      "grad_norm": 4.288818359375,
      "learning_rate": 8.577372056388093e-06,
      "loss": 0.2018,
      "step": 21010
    },
    {
      "epoch": 2.496733578809835,
      "grad_norm": 3.677661180496216,
      "learning_rate": 8.557175748273217e-06,
      "loss": 0.4393,
      "step": 21020
    },
    {
      "epoch": 2.4979213683335315,
      "grad_norm": 0.2661582827568054,
      "learning_rate": 8.536979440158339e-06,
      "loss": 0.1361,
      "step": 21030
    },
    {
      "epoch": 2.4991091578572275,
      "grad_norm": 0.42766422033309937,
      "learning_rate": 8.516783132043463e-06,
      "loss": 0.2739,
      "step": 21040
    },
    {
      "epoch": 2.500296947380924,
      "grad_norm": 0.6349933743476868,
      "learning_rate": 8.496586823928586e-06,
      "loss": 0.3103,
      "step": 21050
    },
    {
      "epoch": 2.5014847369046205,
      "grad_norm": 0.197748601436615,
      "learning_rate": 8.476390515813708e-06,
      "loss": 0.1488,
      "step": 21060
    },
    {
      "epoch": 2.502672526428317,
      "grad_norm": 4.428727149963379,
      "learning_rate": 8.456194207698834e-06,
      "loss": 0.2886,
      "step": 21070
    },
    {
      "epoch": 2.5038603159520134,
      "grad_norm": 0.6569837331771851,
      "learning_rate": 8.435997899583958e-06,
      "loss": 0.1787,
      "step": 21080
    },
    {
      "epoch": 2.5050481054757094,
      "grad_norm": 16.682703018188477,
      "learning_rate": 8.41580159146908e-06,
      "loss": 0.2139,
      "step": 21090
    },
    {
      "epoch": 2.5062358949994064,
      "grad_norm": 19.1800537109375,
      "learning_rate": 8.395605283354203e-06,
      "loss": 0.2026,
      "step": 21100
    },
    {
      "epoch": 2.5074236845231024,
      "grad_norm": 23.934303283691406,
      "learning_rate": 8.375408975239327e-06,
      "loss": 0.2893,
      "step": 21110
    },
    {
      "epoch": 2.508611474046799,
      "grad_norm": 15.617727279663086,
      "learning_rate": 8.35521266712445e-06,
      "loss": 0.3714,
      "step": 21120
    },
    {
      "epoch": 2.5097992635704953,
      "grad_norm": 0.17746488749980927,
      "learning_rate": 8.335016359009573e-06,
      "loss": 0.2164,
      "step": 21130
    },
    {
      "epoch": 2.510987053094192,
      "grad_norm": 10.37622356414795,
      "learning_rate": 8.314820050894696e-06,
      "loss": 0.3475,
      "step": 21140
    },
    {
      "epoch": 2.5121748426178883,
      "grad_norm": 1.5326135158538818,
      "learning_rate": 8.29462374277982e-06,
      "loss": 0.3388,
      "step": 21150
    },
    {
      "epoch": 2.5133626321415843,
      "grad_norm": 0.714333713054657,
      "learning_rate": 8.274427434664944e-06,
      "loss": 0.1814,
      "step": 21160
    },
    {
      "epoch": 2.5145504216652808,
      "grad_norm": 2.6649229526519775,
      "learning_rate": 8.254231126550068e-06,
      "loss": 0.1757,
      "step": 21170
    },
    {
      "epoch": 2.5157382111889772,
      "grad_norm": 0.16169406473636627,
      "learning_rate": 8.234034818435191e-06,
      "loss": 0.231,
      "step": 21180
    },
    {
      "epoch": 2.5169260007126737,
      "grad_norm": 18.907304763793945,
      "learning_rate": 8.213838510320313e-06,
      "loss": 0.4079,
      "step": 21190
    },
    {
      "epoch": 2.51811379023637,
      "grad_norm": 0.5043877363204956,
      "learning_rate": 8.193642202205437e-06,
      "loss": 0.1712,
      "step": 21200
    },
    {
      "epoch": 2.5193015797600666,
      "grad_norm": 0.3261859714984894,
      "learning_rate": 8.17344589409056e-06,
      "loss": 0.0854,
      "step": 21210
    },
    {
      "epoch": 2.520489369283763,
      "grad_norm": 4.0333251953125,
      "learning_rate": 8.153249585975683e-06,
      "loss": 0.2241,
      "step": 21220
    },
    {
      "epoch": 2.521677158807459,
      "grad_norm": 0.31473663449287415,
      "learning_rate": 8.133053277860806e-06,
      "loss": 0.3383,
      "step": 21230
    },
    {
      "epoch": 2.5228649483311556,
      "grad_norm": 3.1441335678100586,
      "learning_rate": 8.112856969745932e-06,
      "loss": 0.0935,
      "step": 21240
    },
    {
      "epoch": 2.524052737854852,
      "grad_norm": 6.464489936828613,
      "learning_rate": 8.092660661631054e-06,
      "loss": 0.3544,
      "step": 21250
    },
    {
      "epoch": 2.5252405273785485,
      "grad_norm": 13.020390510559082,
      "learning_rate": 8.072464353516178e-06,
      "loss": 0.2803,
      "step": 21260
    },
    {
      "epoch": 2.526428316902245,
      "grad_norm": 0.4056280553340912,
      "learning_rate": 8.052268045401301e-06,
      "loss": 0.0558,
      "step": 21270
    },
    {
      "epoch": 2.5276161064259415,
      "grad_norm": 8.99899959564209,
      "learning_rate": 8.032071737286425e-06,
      "loss": 0.2072,
      "step": 21280
    },
    {
      "epoch": 2.528803895949638,
      "grad_norm": 13.049626350402832,
      "learning_rate": 8.011875429171547e-06,
      "loss": 0.3115,
      "step": 21290
    },
    {
      "epoch": 2.529991685473334,
      "grad_norm": 2.5466885566711426,
      "learning_rate": 7.99167912105667e-06,
      "loss": 0.2807,
      "step": 21300
    },
    {
      "epoch": 2.5311794749970304,
      "grad_norm": 1.194979190826416,
      "learning_rate": 7.971482812941794e-06,
      "loss": 0.3831,
      "step": 21310
    },
    {
      "epoch": 2.532367264520727,
      "grad_norm": 53.37519836425781,
      "learning_rate": 7.951286504826918e-06,
      "loss": 0.3483,
      "step": 21320
    },
    {
      "epoch": 2.5335550540444234,
      "grad_norm": 41.20948028564453,
      "learning_rate": 7.931090196712042e-06,
      "loss": 0.2572,
      "step": 21330
    },
    {
      "epoch": 2.53474284356812,
      "grad_norm": 37.48074722290039,
      "learning_rate": 7.910893888597166e-06,
      "loss": 0.3455,
      "step": 21340
    },
    {
      "epoch": 2.535930633091816,
      "grad_norm": 2.9265520572662354,
      "learning_rate": 7.890697580482288e-06,
      "loss": 0.2363,
      "step": 21350
    },
    {
      "epoch": 2.537118422615513,
      "grad_norm": 20.736865997314453,
      "learning_rate": 7.870501272367411e-06,
      "loss": 0.2896,
      "step": 21360
    },
    {
      "epoch": 2.538306212139209,
      "grad_norm": 0.5826414823532104,
      "learning_rate": 7.850304964252535e-06,
      "loss": 0.0673,
      "step": 21370
    },
    {
      "epoch": 2.5394940016629053,
      "grad_norm": 6.496179580688477,
      "learning_rate": 7.830108656137659e-06,
      "loss": 0.1801,
      "step": 21380
    },
    {
      "epoch": 2.5406817911866018,
      "grad_norm": 42.172122955322266,
      "learning_rate": 7.80991234802278e-06,
      "loss": 0.3604,
      "step": 21390
    },
    {
      "epoch": 2.5418695807102982,
      "grad_norm": 0.40391749143600464,
      "learning_rate": 7.789716039907906e-06,
      "loss": 0.208,
      "step": 21400
    },
    {
      "epoch": 2.5430573702339947,
      "grad_norm": 1.321642518043518,
      "learning_rate": 7.769519731793028e-06,
      "loss": 0.0298,
      "step": 21410
    },
    {
      "epoch": 2.5442451597576907,
      "grad_norm": 26.016876220703125,
      "learning_rate": 7.749323423678152e-06,
      "loss": 0.2095,
      "step": 21420
    },
    {
      "epoch": 2.545432949281387,
      "grad_norm": 36.98671340942383,
      "learning_rate": 7.729127115563276e-06,
      "loss": 0.2889,
      "step": 21430
    },
    {
      "epoch": 2.5466207388050837,
      "grad_norm": 3.7710587978363037,
      "learning_rate": 7.7089308074484e-06,
      "loss": 0.3692,
      "step": 21440
    },
    {
      "epoch": 2.54780852832878,
      "grad_norm": 9.569299697875977,
      "learning_rate": 7.688734499333521e-06,
      "loss": 0.3436,
      "step": 21450
    },
    {
      "epoch": 2.5489963178524766,
      "grad_norm": 18.306861877441406,
      "learning_rate": 7.668538191218645e-06,
      "loss": 0.3767,
      "step": 21460
    },
    {
      "epoch": 2.550184107376173,
      "grad_norm": 4.894680023193359,
      "learning_rate": 7.648341883103769e-06,
      "loss": 0.3501,
      "step": 21470
    },
    {
      "epoch": 2.5513718968998695,
      "grad_norm": 41.608619689941406,
      "learning_rate": 7.628145574988893e-06,
      "loss": 0.3585,
      "step": 21480
    },
    {
      "epoch": 2.5525596864235656,
      "grad_norm": 11.445390701293945,
      "learning_rate": 7.607949266874016e-06,
      "loss": 0.3291,
      "step": 21490
    },
    {
      "epoch": 2.553747475947262,
      "grad_norm": 1.0579148530960083,
      "learning_rate": 7.587752958759139e-06,
      "loss": 0.1627,
      "step": 21500
    },
    {
      "epoch": 2.5549352654709585,
      "grad_norm": 14.725166320800781,
      "learning_rate": 7.567556650644263e-06,
      "loss": 0.325,
      "step": 21510
    },
    {
      "epoch": 2.556123054994655,
      "grad_norm": 47.60372543334961,
      "learning_rate": 7.547360342529386e-06,
      "loss": 0.2833,
      "step": 21520
    },
    {
      "epoch": 2.5573108445183514,
      "grad_norm": 22.614213943481445,
      "learning_rate": 7.5271640344145094e-06,
      "loss": 0.213,
      "step": 21530
    },
    {
      "epoch": 2.558498634042048,
      "grad_norm": 0.18001577258110046,
      "learning_rate": 7.506967726299632e-06,
      "loss": 0.1274,
      "step": 21540
    },
    {
      "epoch": 2.5596864235657444,
      "grad_norm": 2.7172179222106934,
      "learning_rate": 7.486771418184756e-06,
      "loss": 0.176,
      "step": 21550
    },
    {
      "epoch": 2.5608742130894404,
      "grad_norm": 22.85860252380371,
      "learning_rate": 7.4665751100698806e-06,
      "loss": 0.2568,
      "step": 21560
    },
    {
      "epoch": 2.562062002613137,
      "grad_norm": 5.235261917114258,
      "learning_rate": 7.4463788019550034e-06,
      "loss": 0.3203,
      "step": 21570
    },
    {
      "epoch": 2.5632497921368333,
      "grad_norm": 17.707992553710938,
      "learning_rate": 7.426182493840126e-06,
      "loss": 0.2521,
      "step": 21580
    },
    {
      "epoch": 2.56443758166053,
      "grad_norm": 28.2755069732666,
      "learning_rate": 7.40598618572525e-06,
      "loss": 0.3636,
      "step": 21590
    },
    {
      "epoch": 2.5656253711842263,
      "grad_norm": 15.371569633483887,
      "learning_rate": 7.385789877610373e-06,
      "loss": 0.1914,
      "step": 21600
    },
    {
      "epoch": 2.5668131607079223,
      "grad_norm": 0.556993842124939,
      "learning_rate": 7.365593569495497e-06,
      "loss": 0.2802,
      "step": 21610
    },
    {
      "epoch": 2.5680009502316192,
      "grad_norm": 36.694576263427734,
      "learning_rate": 7.3453972613806195e-06,
      "loss": 0.3353,
      "step": 21620
    },
    {
      "epoch": 2.5691887397553153,
      "grad_norm": 5.893807888031006,
      "learning_rate": 7.325200953265743e-06,
      "loss": 0.1804,
      "step": 21630
    },
    {
      "epoch": 2.5703765292790117,
      "grad_norm": 26.67521095275879,
      "learning_rate": 7.305004645150868e-06,
      "loss": 0.208,
      "step": 21640
    },
    {
      "epoch": 2.571564318802708,
      "grad_norm": 0.2268531620502472,
      "learning_rate": 7.284808337035991e-06,
      "loss": 0.1267,
      "step": 21650
    },
    {
      "epoch": 2.5727521083264047,
      "grad_norm": 16.12995147705078,
      "learning_rate": 7.264612028921114e-06,
      "loss": 0.3411,
      "step": 21660
    },
    {
      "epoch": 2.573939897850101,
      "grad_norm": 1.2859985828399658,
      "learning_rate": 7.244415720806237e-06,
      "loss": 0.3956,
      "step": 21670
    },
    {
      "epoch": 2.575127687373797,
      "grad_norm": 0.4487795829772949,
      "learning_rate": 7.22421941269136e-06,
      "loss": 0.1968,
      "step": 21680
    },
    {
      "epoch": 2.5763154768974936,
      "grad_norm": 0.33889666199684143,
      "learning_rate": 7.204023104576484e-06,
      "loss": 0.2101,
      "step": 21690
    },
    {
      "epoch": 2.57750326642119,
      "grad_norm": 33.731239318847656,
      "learning_rate": 7.183826796461607e-06,
      "loss": 0.3346,
      "step": 21700
    },
    {
      "epoch": 2.5786910559448866,
      "grad_norm": 24.8649845123291,
      "learning_rate": 7.16363048834673e-06,
      "loss": 0.2423,
      "step": 21710
    },
    {
      "epoch": 2.579878845468583,
      "grad_norm": 38.057090759277344,
      "learning_rate": 7.143434180231853e-06,
      "loss": 0.2429,
      "step": 21720
    },
    {
      "epoch": 2.5810666349922795,
      "grad_norm": 30.285934448242188,
      "learning_rate": 7.123237872116978e-06,
      "loss": 0.1837,
      "step": 21730
    },
    {
      "epoch": 2.582254424515976,
      "grad_norm": 12.776142120361328,
      "learning_rate": 7.1030415640021015e-06,
      "loss": 0.4152,
      "step": 21740
    },
    {
      "epoch": 2.583442214039672,
      "grad_norm": 1.5709128379821777,
      "learning_rate": 7.082845255887224e-06,
      "loss": 0.1658,
      "step": 21750
    },
    {
      "epoch": 2.5846300035633685,
      "grad_norm": 10.687834739685059,
      "learning_rate": 7.062648947772347e-06,
      "loss": 0.4458,
      "step": 21760
    },
    {
      "epoch": 2.585817793087065,
      "grad_norm": 0.3247615694999695,
      "learning_rate": 7.042452639657471e-06,
      "loss": 0.2514,
      "step": 21770
    },
    {
      "epoch": 2.5870055826107614,
      "grad_norm": 11.29732608795166,
      "learning_rate": 7.022256331542594e-06,
      "loss": 0.3132,
      "step": 21780
    },
    {
      "epoch": 2.588193372134458,
      "grad_norm": 20.827899932861328,
      "learning_rate": 7.0020600234277175e-06,
      "loss": 0.3386,
      "step": 21790
    },
    {
      "epoch": 2.589381161658154,
      "grad_norm": 33.75502395629883,
      "learning_rate": 6.98186371531284e-06,
      "loss": 0.2467,
      "step": 21800
    },
    {
      "epoch": 2.590568951181851,
      "grad_norm": 0.980866551399231,
      "learning_rate": 6.961667407197965e-06,
      "loss": 0.3155,
      "step": 21810
    },
    {
      "epoch": 2.591756740705547,
      "grad_norm": 13.576154708862305,
      "learning_rate": 6.941471099083089e-06,
      "loss": 0.3152,
      "step": 21820
    },
    {
      "epoch": 2.5929445302292433,
      "grad_norm": 21.355060577392578,
      "learning_rate": 6.9212747909682115e-06,
      "loss": 0.1975,
      "step": 21830
    },
    {
      "epoch": 2.59413231975294,
      "grad_norm": 0.6407454013824463,
      "learning_rate": 6.901078482853334e-06,
      "loss": 0.1558,
      "step": 21840
    },
    {
      "epoch": 2.5953201092766363,
      "grad_norm": 19.162824630737305,
      "learning_rate": 6.880882174738458e-06,
      "loss": 0.2034,
      "step": 21850
    },
    {
      "epoch": 2.5965078988003327,
      "grad_norm": 7.467435836791992,
      "learning_rate": 6.860685866623581e-06,
      "loss": 0.0954,
      "step": 21860
    },
    {
      "epoch": 2.5976956883240288,
      "grad_norm": 0.27533748745918274,
      "learning_rate": 6.840489558508705e-06,
      "loss": 0.373,
      "step": 21870
    },
    {
      "epoch": 2.598883477847725,
      "grad_norm": 0.2029283493757248,
      "learning_rate": 6.8202932503938276e-06,
      "loss": 0.2108,
      "step": 21880
    },
    {
      "epoch": 2.6000712673714217,
      "grad_norm": 3.3389837741851807,
      "learning_rate": 6.800096942278952e-06,
      "loss": 0.2231,
      "step": 21890
    },
    {
      "epoch": 2.601259056895118,
      "grad_norm": 0.08645222336053848,
      "learning_rate": 6.779900634164076e-06,
      "loss": 0.2468,
      "step": 21900
    },
    {
      "epoch": 2.6024468464188146,
      "grad_norm": 5.1275200843811035,
      "learning_rate": 6.759704326049199e-06,
      "loss": 0.292,
      "step": 21910
    },
    {
      "epoch": 2.603634635942511,
      "grad_norm": 3.364525556564331,
      "learning_rate": 6.7395080179343224e-06,
      "loss": 0.4652,
      "step": 21920
    },
    {
      "epoch": 2.6048224254662076,
      "grad_norm": 10.139036178588867,
      "learning_rate": 6.719311709819445e-06,
      "loss": 0.4068,
      "step": 21930
    },
    {
      "epoch": 2.6060102149899036,
      "grad_norm": 22.245113372802734,
      "learning_rate": 6.699115401704568e-06,
      "loss": 0.2673,
      "step": 21940
    },
    {
      "epoch": 2.6071980045136,
      "grad_norm": 37.534671783447266,
      "learning_rate": 6.678919093589692e-06,
      "loss": 0.337,
      "step": 21950
    },
    {
      "epoch": 2.6083857940372965,
      "grad_norm": 5.045158386230469,
      "learning_rate": 6.658722785474815e-06,
      "loss": 0.2153,
      "step": 21960
    },
    {
      "epoch": 2.609573583560993,
      "grad_norm": 2.003847599029541,
      "learning_rate": 6.638526477359939e-06,
      "loss": 0.1303,
      "step": 21970
    },
    {
      "epoch": 2.6107613730846895,
      "grad_norm": 22.80770492553711,
      "learning_rate": 6.618330169245063e-06,
      "loss": 0.3446,
      "step": 21980
    },
    {
      "epoch": 2.611949162608386,
      "grad_norm": 0.48278385400772095,
      "learning_rate": 6.598133861130186e-06,
      "loss": 0.2845,
      "step": 21990
    },
    {
      "epoch": 2.6131369521320824,
      "grad_norm": 0.0913890153169632,
      "learning_rate": 6.57793755301531e-06,
      "loss": 0.3381,
      "step": 22000
    },
    {
      "epoch": 2.6143247416557784,
      "grad_norm": 18.426986694335938,
      "learning_rate": 6.5577412449004325e-06,
      "loss": 0.1993,
      "step": 22010
    },
    {
      "epoch": 2.615512531179475,
      "grad_norm": 8.675639152526855,
      "learning_rate": 6.537544936785555e-06,
      "loss": 0.3039,
      "step": 22020
    },
    {
      "epoch": 2.6167003207031714,
      "grad_norm": 21.870643615722656,
      "learning_rate": 6.517348628670679e-06,
      "loss": 0.2581,
      "step": 22030
    },
    {
      "epoch": 2.617888110226868,
      "grad_norm": 22.00286102294922,
      "learning_rate": 6.497152320555802e-06,
      "loss": 0.2004,
      "step": 22040
    },
    {
      "epoch": 2.6190758997505643,
      "grad_norm": 13.359522819519043,
      "learning_rate": 6.4769560124409265e-06,
      "loss": 0.17,
      "step": 22050
    },
    {
      "epoch": 2.6202636892742603,
      "grad_norm": 36.998348236083984,
      "learning_rate": 6.45675970432605e-06,
      "loss": 0.2548,
      "step": 22060
    },
    {
      "epoch": 2.6214514787979573,
      "grad_norm": 63.23046112060547,
      "learning_rate": 6.436563396211173e-06,
      "loss": 0.4509,
      "step": 22070
    },
    {
      "epoch": 2.6226392683216533,
      "grad_norm": 0.13930431008338928,
      "learning_rate": 6.416367088096297e-06,
      "loss": 0.3326,
      "step": 22080
    },
    {
      "epoch": 2.6238270578453498,
      "grad_norm": 7.180211067199707,
      "learning_rate": 6.39617077998142e-06,
      "loss": 0.2246,
      "step": 22090
    },
    {
      "epoch": 2.6250148473690462,
      "grad_norm": 14.859911918640137,
      "learning_rate": 6.3759744718665425e-06,
      "loss": 0.4557,
      "step": 22100
    },
    {
      "epoch": 2.6262026368927427,
      "grad_norm": 29.153024673461914,
      "learning_rate": 6.355778163751666e-06,
      "loss": 0.2406,
      "step": 22110
    },
    {
      "epoch": 2.627390426416439,
      "grad_norm": 0.25614386796951294,
      "learning_rate": 6.335581855636789e-06,
      "loss": 0.3052,
      "step": 22120
    },
    {
      "epoch": 2.628578215940135,
      "grad_norm": 0.6125656366348267,
      "learning_rate": 6.315385547521914e-06,
      "loss": 0.3414,
      "step": 22130
    },
    {
      "epoch": 2.6297660054638317,
      "grad_norm": 25.79340362548828,
      "learning_rate": 6.295189239407037e-06,
      "loss": 0.3677,
      "step": 22140
    },
    {
      "epoch": 2.630953794987528,
      "grad_norm": 28.09299659729004,
      "learning_rate": 6.27499293129216e-06,
      "loss": 0.1358,
      "step": 22150
    },
    {
      "epoch": 2.6321415845112246,
      "grad_norm": 42.62725067138672,
      "learning_rate": 6.254796623177284e-06,
      "loss": 0.254,
      "step": 22160
    },
    {
      "epoch": 2.633329374034921,
      "grad_norm": 14.75197982788086,
      "learning_rate": 6.234600315062407e-06,
      "loss": 0.2237,
      "step": 22170
    },
    {
      "epoch": 2.6345171635586175,
      "grad_norm": 0.21498428285121918,
      "learning_rate": 6.2144040069475305e-06,
      "loss": 0.1924,
      "step": 22180
    },
    {
      "epoch": 2.635704953082314,
      "grad_norm": 2.0414204597473145,
      "learning_rate": 6.194207698832654e-06,
      "loss": 0.3746,
      "step": 22190
    },
    {
      "epoch": 2.63689274260601,
      "grad_norm": 12.979228973388672,
      "learning_rate": 6.174011390717777e-06,
      "loss": 0.1237,
      "step": 22200
    },
    {
      "epoch": 2.6380805321297065,
      "grad_norm": 51.248294830322266,
      "learning_rate": 6.153815082602901e-06,
      "loss": 0.3035,
      "step": 22210
    },
    {
      "epoch": 2.639268321653403,
      "grad_norm": 1.1115425825119019,
      "learning_rate": 6.133618774488024e-06,
      "loss": 0.0686,
      "step": 22220
    },
    {
      "epoch": 2.6404561111770994,
      "grad_norm": 24.111591339111328,
      "learning_rate": 6.1134224663731466e-06,
      "loss": 0.2775,
      "step": 22230
    },
    {
      "epoch": 2.641643900700796,
      "grad_norm": 48.90060806274414,
      "learning_rate": 6.093226158258271e-06,
      "loss": 0.3059,
      "step": 22240
    },
    {
      "epoch": 2.6428316902244924,
      "grad_norm": 0.3778512477874756,
      "learning_rate": 6.073029850143394e-06,
      "loss": 0.1191,
      "step": 22250
    },
    {
      "epoch": 2.644019479748189,
      "grad_norm": 14.034762382507324,
      "learning_rate": 6.052833542028518e-06,
      "loss": 0.4086,
      "step": 22260
    },
    {
      "epoch": 2.645207269271885,
      "grad_norm": 1.578760027885437,
      "learning_rate": 6.0326372339136406e-06,
      "loss": 0.309,
      "step": 22270
    },
    {
      "epoch": 2.6463950587955813,
      "grad_norm": 23.332969665527344,
      "learning_rate": 6.012440925798764e-06,
      "loss": 0.2953,
      "step": 22280
    },
    {
      "epoch": 2.647582848319278,
      "grad_norm": 0.633549690246582,
      "learning_rate": 5.992244617683888e-06,
      "loss": 0.4084,
      "step": 22290
    },
    {
      "epoch": 2.6487706378429743,
      "grad_norm": 33.62397384643555,
      "learning_rate": 5.972048309569011e-06,
      "loss": 0.1822,
      "step": 22300
    },
    {
      "epoch": 2.6499584273666708,
      "grad_norm": 57.954124450683594,
      "learning_rate": 5.951852001454135e-06,
      "loss": 0.331,
      "step": 22310
    },
    {
      "epoch": 2.651146216890367,
      "grad_norm": 0.529202938079834,
      "learning_rate": 5.931655693339258e-06,
      "loss": 0.24,
      "step": 22320
    },
    {
      "epoch": 2.6523340064140637,
      "grad_norm": 6.821034908294678,
      "learning_rate": 5.911459385224381e-06,
      "loss": 0.1356,
      "step": 22330
    },
    {
      "epoch": 2.6535217959377597,
      "grad_norm": 2.9958455562591553,
      "learning_rate": 5.891263077109505e-06,
      "loss": 0.4939,
      "step": 22340
    },
    {
      "epoch": 2.654709585461456,
      "grad_norm": 45.655242919921875,
      "learning_rate": 5.871066768994628e-06,
      "loss": 0.323,
      "step": 22350
    },
    {
      "epoch": 2.6558973749851527,
      "grad_norm": 10.271896362304688,
      "learning_rate": 5.8508704608797515e-06,
      "loss": 0.2344,
      "step": 22360
    },
    {
      "epoch": 2.657085164508849,
      "grad_norm": 7.595332622528076,
      "learning_rate": 5.830674152764875e-06,
      "loss": 0.4501,
      "step": 22370
    },
    {
      "epoch": 2.6582729540325456,
      "grad_norm": 0.2192307561635971,
      "learning_rate": 5.810477844649998e-06,
      "loss": 0.239,
      "step": 22380
    },
    {
      "epoch": 2.6594607435562416,
      "grad_norm": 33.26430130004883,
      "learning_rate": 5.790281536535122e-06,
      "loss": 0.2794,
      "step": 22390
    },
    {
      "epoch": 2.660648533079938,
      "grad_norm": 1.0568840503692627,
      "learning_rate": 5.7700852284202455e-06,
      "loss": 0.2588,
      "step": 22400
    },
    {
      "epoch": 2.6618363226036346,
      "grad_norm": 44.28517150878906,
      "learning_rate": 5.749888920305368e-06,
      "loss": 0.1989,
      "step": 22410
    },
    {
      "epoch": 2.663024112127331,
      "grad_norm": 16.187522888183594,
      "learning_rate": 5.729692612190492e-06,
      "loss": 0.4915,
      "step": 22420
    },
    {
      "epoch": 2.6642119016510275,
      "grad_norm": 32.654747009277344,
      "learning_rate": 5.709496304075615e-06,
      "loss": 0.3646,
      "step": 22430
    },
    {
      "epoch": 2.665399691174724,
      "grad_norm": 33.067684173583984,
      "learning_rate": 5.689299995960739e-06,
      "loss": 0.4592,
      "step": 22440
    },
    {
      "epoch": 2.6665874806984204,
      "grad_norm": 0.36297059059143066,
      "learning_rate": 5.669103687845862e-06,
      "loss": 0.2737,
      "step": 22450
    },
    {
      "epoch": 2.6677752702221165,
      "grad_norm": 3.5957653522491455,
      "learning_rate": 5.648907379730985e-06,
      "loss": 0.204,
      "step": 22460
    },
    {
      "epoch": 2.668963059745813,
      "grad_norm": 27.2843017578125,
      "learning_rate": 5.628711071616109e-06,
      "loss": 0.2304,
      "step": 22470
    },
    {
      "epoch": 2.6701508492695094,
      "grad_norm": 23.06884765625,
      "learning_rate": 5.608514763501233e-06,
      "loss": 0.2575,
      "step": 22480
    },
    {
      "epoch": 2.671338638793206,
      "grad_norm": 2.3073976039886475,
      "learning_rate": 5.5883184553863555e-06,
      "loss": 0.1841,
      "step": 22490
    },
    {
      "epoch": 2.6725264283169023,
      "grad_norm": 0.4689742624759674,
      "learning_rate": 5.568122147271479e-06,
      "loss": 0.1941,
      "step": 22500
    },
    {
      "epoch": 2.6737142178405984,
      "grad_norm": 30.54853057861328,
      "learning_rate": 5.547925839156602e-06,
      "loss": 0.1728,
      "step": 22510
    },
    {
      "epoch": 2.6749020073642953,
      "grad_norm": 7.752790927886963,
      "learning_rate": 5.527729531041726e-06,
      "loss": 0.2963,
      "step": 22520
    },
    {
      "epoch": 2.6760897968879913,
      "grad_norm": 5.561404705047607,
      "learning_rate": 5.5075332229268495e-06,
      "loss": 0.3366,
      "step": 22530
    },
    {
      "epoch": 2.677277586411688,
      "grad_norm": 11.823710441589355,
      "learning_rate": 5.487336914811972e-06,
      "loss": 0.2216,
      "step": 22540
    },
    {
      "epoch": 2.6784653759353843,
      "grad_norm": 14.82060718536377,
      "learning_rate": 5.467140606697096e-06,
      "loss": 0.5138,
      "step": 22550
    },
    {
      "epoch": 2.6796531654590807,
      "grad_norm": 35.52587890625,
      "learning_rate": 5.44694429858222e-06,
      "loss": 0.5724,
      "step": 22560
    },
    {
      "epoch": 2.680840954982777,
      "grad_norm": 37.13009262084961,
      "learning_rate": 5.426747990467343e-06,
      "loss": 0.2283,
      "step": 22570
    },
    {
      "epoch": 2.682028744506473,
      "grad_norm": 0.15514972805976868,
      "learning_rate": 5.406551682352466e-06,
      "loss": 0.0314,
      "step": 22580
    },
    {
      "epoch": 2.68321653403017,
      "grad_norm": 0.42345213890075684,
      "learning_rate": 5.386355374237589e-06,
      "loss": 0.3293,
      "step": 22590
    },
    {
      "epoch": 2.684404323553866,
      "grad_norm": 15.819881439208984,
      "learning_rate": 5.366159066122713e-06,
      "loss": 0.2036,
      "step": 22600
    },
    {
      "epoch": 2.6855921130775626,
      "grad_norm": 58.947994232177734,
      "learning_rate": 5.345962758007837e-06,
      "loss": 0.2482,
      "step": 22610
    },
    {
      "epoch": 2.686779902601259,
      "grad_norm": 17.232967376708984,
      "learning_rate": 5.3257664498929596e-06,
      "loss": 0.3613,
      "step": 22620
    },
    {
      "epoch": 2.6879676921249556,
      "grad_norm": 18.228376388549805,
      "learning_rate": 5.305570141778083e-06,
      "loss": 0.327,
      "step": 22630
    },
    {
      "epoch": 2.689155481648652,
      "grad_norm": 0.12196602672338486,
      "learning_rate": 5.285373833663207e-06,
      "loss": 0.3773,
      "step": 22640
    },
    {
      "epoch": 2.690343271172348,
      "grad_norm": 0.6631333231925964,
      "learning_rate": 5.26517752554833e-06,
      "loss": 0.179,
      "step": 22650
    },
    {
      "epoch": 2.6915310606960445,
      "grad_norm": 2.243129253387451,
      "learning_rate": 5.2449812174334536e-06,
      "loss": 0.3552,
      "step": 22660
    },
    {
      "epoch": 2.692718850219741,
      "grad_norm": 1.3294155597686768,
      "learning_rate": 5.2247849093185764e-06,
      "loss": 0.2563,
      "step": 22670
    },
    {
      "epoch": 2.6939066397434375,
      "grad_norm": 0.2373928278684616,
      "learning_rate": 5.2045886012037e-06,
      "loss": 0.2108,
      "step": 22680
    },
    {
      "epoch": 2.695094429267134,
      "grad_norm": 30.144079208374023,
      "learning_rate": 5.184392293088824e-06,
      "loss": 0.2525,
      "step": 22690
    },
    {
      "epoch": 2.6962822187908304,
      "grad_norm": 0.3967975378036499,
      "learning_rate": 5.164195984973947e-06,
      "loss": 0.3981,
      "step": 22700
    },
    {
      "epoch": 2.697470008314527,
      "grad_norm": 9.915297508239746,
      "learning_rate": 5.1439996768590704e-06,
      "loss": 0.4204,
      "step": 22710
    },
    {
      "epoch": 2.698657797838223,
      "grad_norm": 10.654267311096191,
      "learning_rate": 5.123803368744194e-06,
      "loss": 0.1628,
      "step": 22720
    },
    {
      "epoch": 2.6998455873619194,
      "grad_norm": 29.709880828857422,
      "learning_rate": 5.103607060629317e-06,
      "loss": 0.3195,
      "step": 22730
    },
    {
      "epoch": 2.701033376885616,
      "grad_norm": 31.203330993652344,
      "learning_rate": 5.083410752514441e-06,
      "loss": 0.1418,
      "step": 22740
    },
    {
      "epoch": 2.7022211664093123,
      "grad_norm": 36.78586196899414,
      "learning_rate": 5.063214444399564e-06,
      "loss": 0.2706,
      "step": 22750
    },
    {
      "epoch": 2.703408955933009,
      "grad_norm": 11.391508102416992,
      "learning_rate": 5.043018136284687e-06,
      "loss": 0.3095,
      "step": 22760
    },
    {
      "epoch": 2.704596745456705,
      "grad_norm": 55.70016098022461,
      "learning_rate": 5.022821828169811e-06,
      "loss": 0.1567,
      "step": 22770
    },
    {
      "epoch": 2.7057845349804017,
      "grad_norm": 29.153127670288086,
      "learning_rate": 5.002625520054934e-06,
      "loss": 0.1894,
      "step": 22780
    },
    {
      "epoch": 2.7069723245040977,
      "grad_norm": 0.22463810443878174,
      "learning_rate": 4.982429211940058e-06,
      "loss": 0.1536,
      "step": 22790
    },
    {
      "epoch": 2.708160114027794,
      "grad_norm": 13.713791847229004,
      "learning_rate": 4.9622329038251805e-06,
      "loss": 0.3181,
      "step": 22800
    },
    {
      "epoch": 2.7093479035514907,
      "grad_norm": 9.892661094665527,
      "learning_rate": 4.942036595710304e-06,
      "loss": 0.1305,
      "step": 22810
    },
    {
      "epoch": 2.710535693075187,
      "grad_norm": 10.21511459350586,
      "learning_rate": 4.921840287595428e-06,
      "loss": 0.1145,
      "step": 22820
    },
    {
      "epoch": 2.7117234825988836,
      "grad_norm": 1.3698800802230835,
      "learning_rate": 4.901643979480551e-06,
      "loss": 0.1373,
      "step": 22830
    },
    {
      "epoch": 2.7129112721225797,
      "grad_norm": 27.747333526611328,
      "learning_rate": 4.8814476713656745e-06,
      "loss": 0.2149,
      "step": 22840
    },
    {
      "epoch": 2.714099061646276,
      "grad_norm": 15.660444259643555,
      "learning_rate": 4.861251363250798e-06,
      "loss": 0.3448,
      "step": 22850
    },
    {
      "epoch": 2.7152868511699726,
      "grad_norm": 7.383707046508789,
      "learning_rate": 4.841055055135921e-06,
      "loss": 0.141,
      "step": 22860
    },
    {
      "epoch": 2.716474640693669,
      "grad_norm": 48.355873107910156,
      "learning_rate": 4.820858747021045e-06,
      "loss": 0.2063,
      "step": 22870
    },
    {
      "epoch": 2.7176624302173655,
      "grad_norm": 19.23916244506836,
      "learning_rate": 4.800662438906168e-06,
      "loss": 0.2576,
      "step": 22880
    },
    {
      "epoch": 2.718850219741062,
      "grad_norm": 6.867687225341797,
      "learning_rate": 4.780466130791292e-06,
      "loss": 0.3762,
      "step": 22890
    },
    {
      "epoch": 2.7200380092647585,
      "grad_norm": 25.03526496887207,
      "learning_rate": 4.760269822676415e-06,
      "loss": 0.1779,
      "step": 22900
    },
    {
      "epoch": 2.7212257987884545,
      "grad_norm": 2.4322307109832764,
      "learning_rate": 4.740073514561538e-06,
      "loss": 0.3068,
      "step": 22910
    },
    {
      "epoch": 2.722413588312151,
      "grad_norm": 0.7302562594413757,
      "learning_rate": 4.719877206446662e-06,
      "loss": 0.1928,
      "step": 22920
    },
    {
      "epoch": 2.7236013778358474,
      "grad_norm": 0.3302486836910248,
      "learning_rate": 4.699680898331785e-06,
      "loss": 0.1223,
      "step": 22930
    },
    {
      "epoch": 2.724789167359544,
      "grad_norm": 0.13954438269138336,
      "learning_rate": 4.679484590216908e-06,
      "loss": 0.2,
      "step": 22940
    },
    {
      "epoch": 2.7259769568832404,
      "grad_norm": 0.1473797857761383,
      "learning_rate": 4.659288282102032e-06,
      "loss": 0.3166,
      "step": 22950
    },
    {
      "epoch": 2.727164746406937,
      "grad_norm": 4.93083381652832,
      "learning_rate": 4.639091973987155e-06,
      "loss": 0.2053,
      "step": 22960
    },
    {
      "epoch": 2.7283525359306333,
      "grad_norm": 3.29622745513916,
      "learning_rate": 4.618895665872279e-06,
      "loss": 0.1814,
      "step": 22970
    },
    {
      "epoch": 2.7295403254543293,
      "grad_norm": 30.608028411865234,
      "learning_rate": 4.598699357757402e-06,
      "loss": 0.2963,
      "step": 22980
    },
    {
      "epoch": 2.730728114978026,
      "grad_norm": 16.12795639038086,
      "learning_rate": 4.578503049642525e-06,
      "loss": 0.1516,
      "step": 22990
    },
    {
      "epoch": 2.7319159045017223,
      "grad_norm": 0.46591293811798096,
      "learning_rate": 4.558306741527649e-06,
      "loss": 0.3327,
      "step": 23000
    }
  ],
  "logging_steps": 10,
  "max_steps": 25257,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 58440498109440.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
